{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42763507-e111-44d1-8948-613b806ccbd8",
   "metadata": {},
   "source": [
    "Import the necessary python modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3edc302e-94d5-4f0f-8772-3e2f8075bbba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import the necessary python modules\n",
    "import pandas as pd # v.1.4.3\n",
    "import numpy as np # v.1.23.0\n",
    "\n",
    "from tqdm import tqdm # v.4.65.0\n",
    "\n",
    "import math # python v.3.9.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a067bf57-2dab-41b0-b3e0-00cdaee938bb",
   "metadata": {},
   "source": [
    "# Cohort selection\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d280df3-9bcc-448a-9b07-adbfe47c7370",
   "metadata": {},
   "source": [
    "Selecting all ICU-stays that had Pulmonary Embolism (PE) as their main (APACHE) admission diagnosis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74ecc242-6812-4892-abc1-1a05fabbacb6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_pat_big = pd.read_csv(\"../../eICU_data/patient.csv\", low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b7b7933-6960-4c4d-9850-96d684506a50",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Embolus, pulmonary']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i for i in df_pat_big.apacheadmissiondx.value_counts().index.to_numpy() if \"Embolus\" in i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b75dde6-ecf8-48af-ae1b-be7346887a01",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1697"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pat_big_pe = df_pat_big[df_pat_big.apacheadmissiondx == \"Embolus, pulmonary\"].copy()\n",
    "lst_pat = df_pat_big_pe.patientunitstayid.to_list()\n",
    "len(lst_pat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "231f961d-06c4-4610-a2dd-81becb64ad84",
   "metadata": {},
   "source": [
    "&rarr; 1697 ICU-admissions with a primary diagnosis of PE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf5dc06-91c0-4cea-b9a8-e5e81a45fc6b",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Reducing the file-size\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c0c2e55-6350-44fe-9ce1-d3da6f7468ac",
   "metadata": {},
   "source": [
    "As the original file sizes are quite large, we take a copy of all files with just the information of our PE patients. This will speed up data extraction/calculations down the line"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5368e06-a0f1-431e-8c99-96098008d349",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d95b642f-685e-4163-b33e-86934d045022",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_reduced_files(import_path, export_path, notation, lst_ids):\n",
    "    \"\"\"\n",
    "    Takes an import path (folder where all the eICU files are), an export path, a \"notation\" (will be added behind the file name as an identifier) and a list of ids, and then returns the reduced\n",
    "    files of eICU for only that population (except for the hospital table).\n",
    "\n",
    "    :param import_path: String - Folder where all the eICU data is stored.\n",
    "    \n",
    "    :param export_path: String - Should only include the folder, not the filename, and should end with \"/\".\n",
    "\n",
    "    :param notation: String - Short notation that will be added to each file name for future identification.\n",
    "\n",
    "    :param lst_ids: List - List of target population patientunitstayids.\n",
    "\n",
    "    :return: Saves a list of abbreviated dataframes to the specified export_path.\n",
    "    \"\"\"\n",
    "\n",
    "    # List of all tables in the eICU database, except the hospital table as it is not connected to patientunitstayid\n",
    "    lst_tables = [\"admissionDrug\", \"admissionDx\", \"allergy\", \"apacheApsVar\", \"apachePatientResult\", \"apachePredVar\",\n",
    "                  \"carePlanCareProvider\", \"carePlanEOL\", \"carePlanGeneral\", \"carePlanGoal\", \"carePlanInfectiousDisease\", \"customLab\",\n",
    "                  \"diagnosis\", \"infusionDrug\", \"intakeOutput\", \"lab\", \"medication\", \"microLab\", \"note\",\n",
    "                  \"nurseAssessment\", \"nurseCare\", \"nurseCharting\", \"pastHistory\", \"patient\", \"physicalExam\",\n",
    "                  \"respiratoryCare\", \"respiratoryCharting\", \"treatment\", \"vitalAperiodic\", \"vitalPeriodic\"]\n",
    "\n",
    "    # Looping over all tables, selecting only the data pertaining to the cohort of interest and then saving these files in a specified location\n",
    "    for table in tqdm(lst_tables):\n",
    "        df_chunk = pd.read_csv(f\"{import_path}{table}.csv\", chunksize=100000, low_memory=False)\n",
    "        lst_dataframes = []\n",
    "        \n",
    "        for chunk in df_chunk:\n",
    "            df_temp = chunk[chunk[\"patientunitstayid\"].isin(lst_ids)]\n",
    "            lst_dataframes.append(df_temp)\n",
    "\n",
    "        df_small = pd.concat(lst_dataframes)\n",
    "        df_small.to_csv(f\"{export_path}{table}_{notation}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f39bbc1-300e-46e0-a076-785bc81c209e",
   "metadata": {},
   "source": [
    "## Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "67b6f822-9910-48c8-96f9-d4f8071eaa9f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 30/30 [07:43<00:00, 15.45s/it]\n"
     ]
    }
   ],
   "source": [
    "make_reduced_files(\n",
    "    import_path = \"../../eICU_data/\",\n",
    "    export_path = \"PE_data/\",\n",
    "    notation = \"PE\",\n",
    "    lst_ids = lst_pat\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de4d33b9-4e87-4979-a567-d50ae709238f",
   "metadata": {},
   "source": [
    "To make this code work in your environment, the complete unpacked eICU data has to be located at the relative path \"../../eICU_data/\" in your project.\n",
    "\n",
    "Now all of the data for our PE patients is in the folder at the relative path \"PE_data/\" and can be accessed from there.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f61b7b-8756-430d-a806-6ea02ab0abf6",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Data extraction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6757aced-9b5e-4bdb-8e36-5d6338422778",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "185069ca-c3cd-4bd2-9ac4-daea014cec5e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_basic_patient_info(df_pat, lst_ids):\n",
    "    \"\"\"\n",
    "    Takes the patient dataframe of the eICU database, a list of target patientunitstayids and\n",
    "    returns a dataframe with \"cleaned\" info per patientunitstayid.\n",
    "\n",
    "    :param df_pat: DataFrame - Patient dataframe of eICU (or abbreviated). \n",
    "\n",
    "    :param lst_ids: List - List of the population patientunitstayids.\n",
    "\n",
    "    :return: DataFrame with the information.\n",
    "    \"\"\"\n",
    "\n",
    "    lst_columns = [\"patientunitstayid\", \"uniquepid\", \"gender\", \"age\", \"ethnicity\", \"hospitalid\", \"wardid\",\n",
    "                   \"unittype\", \"apacheadmissiondx\", \"admissionheight\", \"admissionweight\", \"hospitaldischargestatus\",\n",
    "                   'hospitaladmittime24', \"hospitaladmitsource\", \"hospitaldischargelocation\", 'unitadmittime24',\n",
    "                   'unitadmitsource', 'unitstaytype', 'dischargeweight', 'unitdischargelocation', 'unitdischargestatus', \"unitvisitnumber\"]\n",
    "\n",
    "    # reducing the general pat_df to reduce the computational load\n",
    "    df_temp = df_pat.loc[df_pat[\"patientunitstayid\"].isin(lst_ids), lst_columns].copy()\n",
    "\n",
    "    # gender column\n",
    "    df_temp[\"gender\"] = df_temp[\"gender\"].replace({\"Unknown\": np.nan, \"Other\": np.nan})\n",
    "\n",
    "    # age column\n",
    "    df_temp[\"age\"] = df_temp[\"age\"].replace(\"> 89\", \"90\")\n",
    "    df_temp[\"age\"] = pd.to_numeric(df_temp[\"age\"])\n",
    "\n",
    "    # weight columns\n",
    "    df_temp.loc[(df_temp.admissionweight <= 20) | (df_temp.admissionweight >= 300), [\"admissionweight\"]] = np.nan\n",
    "    df_temp.loc[(df_temp.dischargeweight <= 20) | (df_temp.dischargeweight >= 300), [\"dischargeweight\"]] = np.nan\n",
    "\n",
    "    # admissionheight\n",
    "    df_temp.loc[(df_temp.admissionheight < 100) | (df_temp.admissionheight > 210), [\"admissionheight\"]] = np.nan\n",
    "    \n",
    "    # creating the BMI column\n",
    "    df_temp[\"BMI\"] = df_temp[\"admissionweight\"] / (df_temp[\"admissionheight\"] / 100) ** 2\n",
    "    df_temp.loc[(df_temp.BMI > 100) | (df_temp.BMI < 12), \"BMI\"] = np.nan\n",
    "    \n",
    "    df_final = df_temp[[\"patientunitstayid\", \"gender\", \"age\", \"ethnicity\", \"BMI\", \"hospitaldischargestatus\", \"unitdischargestatus\"]].copy()\n",
    "\n",
    "    return df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "67aecf61-edb4-4b25-b852-49e04c1e5a8e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def apply_group_pmh_subcat(x, df, clm_name):\n",
    "    df_one_id = df.loc[(df.patientunitstayid == x), [clm_name]]\n",
    "    lst_diagnoses = df_one_id[clm_name].unique().tolist()\n",
    "    final_string = \"|\".join(lst_diagnoses)\n",
    "    return final_string\n",
    "\n",
    "def apply_split_and_rejoin_for_output(str_pmh):\n",
    "    lst_strings = str_pmh.split(\"/\")\n",
    "    lst_final = lst_strings[6:]\n",
    "\n",
    "    if len(lst_final) == 1:\n",
    "        return lst_final[0]\n",
    "\n",
    "    if len(lst_final) > 1:\n",
    "        joined = \"/\".join(lst_final)\n",
    "        return joined\n",
    "\n",
    "def get_pastHistory(df_pmh, lst_ids):\n",
    "    \"\"\"\n",
    "    Receives the pastHistory Dataframe from eICU or abbreviated and a list of target patientunitstayids and returns\n",
    "    a kind of longformat dataframe with the most important categories/PMH.\n",
    "\n",
    "    :param df_pmh: DataFrame - pastHistory dataframe from eICU. \n",
    "\n",
    "    :param lst_ids: List - list of patientunitstayids from the target population.\n",
    "\n",
    "    :return: DataFrame with patientunitstayids as the index and columns for each category of PMH\n",
    "    \"\"\"\n",
    "    \n",
    "    # Dictionary of prospective column names (key) and the string keys to the PMH-string-path of each disease (values)\n",
    "    dict_subcat_clms = {\n",
    "        'pmh_HT_with_treatment': ['notes/Progress Notes/Past History/Organ Systems/Cardiovascular', 'Hypertension Requiring Treatment'],\n",
    "        'pmh_cancer': ['notes/Progress Notes/Past History/Organ Systems/Hematology-Oncology', 'Cancer'],\n",
    "        'pmh_non_insulin_dep_DM': ['notes/Progress Notes/Past History/Organ Systems/Endocrine', 'Non-Insulin Dependent Diabetes'],\n",
    "        'pmh_COPD': ['notes/Progress Notes/Past History/Organ Systems/Pulmonary', 'COPD'],\n",
    "        'pmh_CHF': ['notes/Progress Notes/Past History/Organ Systems/Cardiovascular', 'Congestive Heart Failure'],\n",
    "        'pmh_insulin_dep_DM': ['notes/Progress Notes/Past History/Organ Systems/Endocrine', 'Insulin Dependent Diabetes'],\n",
    "        'pmh_arrhythmias': ['notes/Progress Notes/Past History/Organ Systems/Cardiovascular', 'Arrhythmias'],\n",
    "        'pmh_hypothyroidism': ['notes/Progress Notes/Past History/Organ Systems/Endocrine', 'Hypothyroidism'],\n",
    "        'pmh_MI': ['notes/Progress Notes/Past History/Organ Systems/Cardiovascular', 'Myocardial Infarction'],\n",
    "        'pmh_strokes': ['notes/Progress Notes/Past History/Organ Systems/Neurologic', 'Strokes'],\n",
    "        'pmh_renal_insuff': ['notes/Progress Notes/Past History/Organ Systems/Renal', 'Renal Insufficiency'],\n",
    "        'pmh_PCI': ['notes/Progress Notes/Past History/Organ Systems/Cardiovascular', 'Procedural Coronary Intervention'],\n",
    "        'pmh_card_valvular': ['notes/Progress Notes/Past History/Organ Systems/Cardiovascular', 'Valve disease'],\n",
    "        'pmh_asthma': ['notes/Progress Notes/Past History/Organ Systems/Pulmonary', 'Asthma'],\n",
    "        'pmh_liver_cirrhosis': ['notes/Progress Notes/Past History/Organ Systems/Gastrointestinal', 'Cirrhosis'],\n",
    "        'pmh_renal_failure': ['notes/Progress Notes/Past History/Organ Systems/Renal', 'Renal Failure'],\n",
    "        'pmh_CA_bypass': ['notes/Progress Notes/Past History/Organ Systems/Cardiovascular', 'Coronary Artery Bypass'],\n",
    "        'pmh_seizures': ['notes/Progress Notes/Past History/Organ Systems/Neurologic', 'Seizures'],\n",
    "        'pmh_periph_vasc_disease': ['notes/Progress Notes/Past History/Organ Systems/Cardiovascular', 'Peripheral Vascular Disease'],\n",
    "        'pmh_home_o2': ['notes/Progress Notes/Past History/Organ Systems/Pulmonary', 'Home Oxygen'],\n",
    "        'pmh_venous_thrombosis': ['notes/Progress Notes/Past History/Organ Systems/Cardiovascular', 'Venous Thrombosis'],\n",
    "        'pmh_dementia': ['notes/Progress Notes/Past History/Organ Systems/Neurologic', 'Dementia'],\n",
    "        'pmh_pacemaker': ['notes/Progress Notes/Past History/Organ Systems/Cardiovascular', 'Pacemaker'],\n",
    "        'pmh_cancer_therapy': ['notes/Progress Notes/Past History/Organ Systems/Hematology-Oncology', 'Cancer Therapy'],\n",
    "        'pmh_angina': ['notes/Progress Notes/Past History/Organ Systems/Cardiovascular', 'Angina'],\n",
    "        'pmh_peptic_ulcer_disease': ['notes/Progress Notes/Past History/Organ Systems/Gastrointestinal', 'Peptic Ulcer Disease'],\n",
    "        'pmh_TIAs': ['notes/Progress Notes/Past History/Organ Systems/Neurologic', 'TIAs'],\n",
    "        'pmh_PFTs': ['notes/Progress Notes/Past History/Organ Systems/Pulmonary', 'Pulmonary Function Tests'],\n",
    "        'pmh_resp_failure': ['notes/Progress Notes/Past History/Organ Systems/Pulmonary', 'Respiratory Failure'],\n",
    "        'pmh_AICD': ['notes/Progress Notes/Past History/Organ Systems/Cardiovascular', 'AICD'],\n",
    "        'pmh_PE': ['notes/Progress Notes/Past History/Organ Systems/Cardiovascular', 'Pulmonary Embolism'],\n",
    "        'pmh_RA': ['notes/Progress Notes/Past History/Organ Systems/Rheumatic', 'Rheumatoid Arthritis'],\n",
    "        'pmh_mmunosuppression_last_6m': ['notes/Progress Notes/Past History/Organ Systems/Infectious Disease', 'Immunosuppression within past 6 months'],\n",
    "        'pmh_chronic_kidney_stones': ['notes/Progress Notes/Past History/Organ Systems/Renal', 'Chronic Stone Disease'],\n",
    "        'pmh_neuromusk_disease': ['notes/Progress Notes/Past History/Organ Systems/Neurologic', 'Neuromuscular Disease'],\n",
    "        'pmh_restrictive_lung_disease': ['notes/Progress Notes/Past History/Organ Systems/Pulmonary', 'Restrictive Disease'],\n",
    "        'pmh_s_p_NTx': ['notes/Progress Notes/Past History/Organ Systems/Renal', 's_p Renal Transplant'],\n",
    "        'pmh_HIV_only': ['notes/Progress Notes/Past History/Organ Systems/Infectious Disease', 'HIV only'],\n",
    "        'pmh_hemolytic _anemia': ['notes/Progress Notes/Past History/Organ Systems/Hematology-Oncology', 'Hemolytic Anemia'],\n",
    "        'pmh_SLE': ['notes/Progress Notes/Past History/Organ Systems/Rheumatic', 'SLE'],\n",
    "        'pmh_exercise_tolerance': ['notes/Progress Notes/Past History/Organ Systems/Cardiovascular', 'Exercise Tolerance'],\n",
    "        'pmh_intracranial_mass': ['notes/Progress Notes/Past History/Organ Systems/Neurologic', 'Intracranial Mass'],\n",
    "        'pmh_hyperthyroidism': ['notes/Progress Notes/Past History/Organ Systems/Endocrine', 'Hyperthyroidism'],\n",
    "        'pmh_recent_steroids_>10d': ['notes/Progress Notes/Past History/Organ Systems/Endocrine', 'Recent Steroid Use for > 10 days'],\n",
    "        'pmh__petite_mal_seizures': ['notes/Progress Notes/Past History/Organ Systems/Neurologic', 'Seizures_petite mal seizures'],\n",
    "        'pmh_s_p_LTx': ['notes/Progress Notes/Past History/Organ Systems/Gastrointestinal', 's_p Liver Transplant'],\n",
    "        'pmh_hypercoagulable_condition': ['notes/Progress Notes/Past History/Organ Systems/Hematology-Oncology', 'Hypercoagulable Condition'],\n",
    "        'pmh_ITP': ['notes/Progress Notes/Past History/Organ Systems/Hematology-Oncology', 'ITP'],\n",
    "        'pmh_neurogenic_bladder': ['notes/Progress Notes/Past History/Organ Systems/Renal ', 'Neurogenic Bladder'],\n",
    "        'pmh_sickle_cells': ['notes/Progress Notes/Past History/Organ Systems/Hematology-Oncology', 'Sickle Cell Disease'],\n",
    "        'pmh_clotting_disorder': ['notes/Progress Notes/Past History/Organ Systems/Hematology-Oncology', 'Clotting Disorder'],\n",
    "        'pmh_AIDS': ['notes/Progress Notes/Past History/Organ Systems/Infectious Disease', 'AIDS'],\n",
    "        'pmh_sarcoidosis': ['notes/Progress Notes/Past History/Organ Systems/Pulmonary', 'Sarcoidosis'],\n",
    "        'pmh_vasculitis': ['notes/Progress Notes/Past History/Organ Systems/Rheumatic', 'Vasculitis'],\n",
    "        'pmh_myeloproliferative_disease': ['notes/Progress Notes/Past History/Organ Systems/Hematology-Oncology', 'Myeloproliferative Disease'],\n",
    "        'pmh_s_p_HTx': ['notes/Progress Notes/Past History/Organ Systems/Cardiovascular', 's_p Heart Transplant'],\n",
    "        'pmh_aplastic_anemia': ['notes/Progress Notes/Past History/Organ Systems/Hematology-Oncology', 'Aplastic Anemia'],\n",
    "        'pmh_hypercalcemia': ['notes/Progress Notes/Past History/Organ Systems/Endocrine', 'Hypercalcemia'],\n",
    "        'pmh_hypersplenism': ['notes/Progress Notes/Past History/Organ Systems/Gastrointestinal', 'Hypersplenism'],\n",
    "        'pmh_scleroderma': ['notes/Progress Notes/Past History/Organ Systems/Rheumatic', 'Scleroderma'],\n",
    "        'pmh_RTA': ['notes/Progress Notes/Past History/Organ Systems/Renal', 'RTA'],\n",
    "        'pmh_s_p_lungTx': ['notes/Progress Notes/Past History/Organ Systems/Pulmonary', 's_p Lung Transplant'],\n",
    "        \"pmh_cushings\": [\"notes/Progress Notes/Past History/Organ Systems/Endocrine\", \"Cushing's Syndrome\"],\n",
    "        'pmh_dermato': ['notes/Progress Notes/Past History/Organ Systems/Rheumatic', 'Dermato']\n",
    "    }\n",
    "    \n",
    "    # reducing the general pastHistory df to reduce the computational load\n",
    "    df_temp = df_pmh.loc[df_pmh[\"patientunitstayid\"].isin(lst_ids), [\"patientunitstayid\", \"pasthistorypath\", \"pasthistoryvalue\"]].copy()\n",
    "\n",
    "    # Replace substrings in pasthistorypath (which would cause issues due to regex expressions later on)\n",
    "    df_temp[\"pasthistorypath\"] = df_temp[\"pasthistorypath\"].str.replace(\"Hematology/Oncology\", \"Hematology-Oncology\",\n",
    "                                                                        regex=True)\n",
    "\n",
    "    df_pmh[\"pasthistorypath\"] = df_pmh[\"pasthistorypath\"].str.replace(\"s/p\", \"s_p\",\n",
    "                                                                      regex=True)\n",
    "\n",
    "    df_pmh[\"pasthistorypath\"] = df_pmh[\"pasthistorypath\"].str.replace(\"TIA(s)\", \"TIAs\",\n",
    "                                                                      regex=True)\n",
    "\n",
    "    df_pmh[\"pasthistorypath\"] = df_pmh[\"pasthistorypath\"].str.replace(\"HIV (only)\", \"HIV only\",\n",
    "                                                                      regex=True)\n",
    "\n",
    "    df_pmh[\"pasthistorypath\"] = df_pmh[\"pasthistorypath\"].str.replace(\"Recent Steroid Use (for > 10 days)\", \"Recent Steroid Use for > 10 days\",\n",
    "                                                                      regex=True)\n",
    "\n",
    "    # list for the future columns\n",
    "    lst_columns = []\n",
    "\n",
    "    # Iterate over the individual diseases and check whether a patient has this PMH or not then saving this as a column to the list\n",
    "    for clm_name, key_phrases in tqdm(dict_subcat_clms.items()):\n",
    "        key1 = key_phrases[0]\n",
    "        key2 = key_phrases[1]\n",
    "\n",
    "        df_new_clm_raw = df_temp.loc[(df_temp['pasthistorypath'].str.contains(key1, na=False)) &\n",
    "                                     (df_temp['pasthistorypath'].str.contains(key2, na=False)), [\"patientunitstayid\", \"pasthistorypath\"]].copy().drop_duplicates()\n",
    "\n",
    "        df_new_clm_raw[\"output_pmh_path\"] = df_new_clm_raw[\"pasthistorypath\"].apply(lambda x: apply_split_and_rejoin_for_output(x))\n",
    "\n",
    "        df_new_clm_reference = df_new_clm_raw.copy()\n",
    "\n",
    "        df_new_clm_raw[clm_name] = df_new_clm_raw[\"patientunitstayid\"].apply(lambda x: apply_group_pmh_subcat(x, df_new_clm_reference, \"output_pmh_path\"))\n",
    "\n",
    "        df_pat_w_data = df_new_clm_raw.loc[:, [\"patientunitstayid\", clm_name]].copy().drop_duplicates()\n",
    "\n",
    "        lst_pat_w_data = list(df_new_clm_raw.patientunitstayid.unique())\n",
    "        lst_pat_no_data = [x for x in lst_ids if x not in lst_pat_w_data]\n",
    "\n",
    "        df_pat_without_data = pd.DataFrame(lst_pat_no_data, columns=['patientunitstayid'])\n",
    "        df_pat_without_data[clm_name] = 0\n",
    "\n",
    "        df_clm_final = pd.concat([df_pat_w_data, df_pat_without_data])\n",
    "        df_clm_final = df_clm_final.set_index(\"patientunitstayid\")\n",
    "\n",
    "        lst_columns.append(df_clm_final)\n",
    "\n",
    "    # Concatenate all the columns and export this with the ids as another column  \n",
    "    df_final = pd.concat(lst_columns, axis=1)\n",
    "    df_final = df_final.reset_index()\n",
    "    df_final = df_final[['patientunitstayid', 'pmh_HT_with_treatment', 'pmh_cancer',\n",
    "       'pmh_non_insulin_dep_DM', 'pmh_COPD', 'pmh_CHF', 'pmh_insulin_dep_DM',\n",
    "       'pmh_arrhythmias', 'pmh_MI', 'pmh_strokes', \"pmh_hypothyroidism\", \n",
    "       'pmh_renal_insuff', 'pmh_PCI', 'pmh_card_valvular', 'pmh_asthma',\n",
    "       'pmh_liver_cirrhosis', 'pmh_renal_failure', 'pmh_CA_bypass',\n",
    "       'pmh_seizures', 'pmh_periph_vasc_disease', 'pmh_home_o2',\n",
    "       'pmh_venous_thrombosis', 'pmh_dementia', 'pmh_pacemaker',\n",
    "       'pmh_cancer_therapy', 'pmh_angina', \n",
    "       'pmh_TIAs', 'pmh_resp_failure', 'pmh_AICD', 'pmh_PE',\n",
    "       'pmh_neuromusk_disease', 'pmh_restrictive_lung_disease', 'pmh_hemolytic _anemia', 'pmh_intracranial_mass',\n",
    "       'pmh_hyperthyroidism', 'pmh__petite_mal_seizures', 'pmh_hypercoagulable_condition', 'pmh_ITP', \n",
    "       'pmh_sickle_cells', 'pmh_clotting_disorder','pmh_aplastic_anemia', 'pmh_s_p_lungTx']]\n",
    "\n",
    "    return df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0dd7bd1b-a7a9-4e4b-9123-8d9abc252c87",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_and_initial_clean_apacheApsVar(df_apsVar, lst_ids):\n",
    "    \"\"\"\n",
    "    Receives the apacheApsVar Dataframe of the eICU database or abbreviated and a list of target patientunitstayids and\n",
    "    returns a dataframe with initially \"cleaned\" data: The -1 Values in several columns which denote for \"no data was\n",
    "    entered\" were set to np.nan. Additionally, a GCS column was added.\n",
    "\n",
    "    :param df_apsVar: DataFrame - apacheApsVar Dataframe from eICU or abreviated. \n",
    "\n",
    "    :param lst_ids: List - list of target patientunitstayids.\n",
    "\n",
    "    :return: DataFrame with patientunitstayid as the index and the data\n",
    "    \"\"\"\n",
    "   \n",
    "    # reducing the general df to reduce the computational load\n",
    "    df_temp = df_apsVar.loc[df_apsVar[\"patientunitstayid\"].isin(lst_ids), ['patientunitstayid', 'dialysis',\n",
    "                                 'eyes', 'motor', 'verbal', 'meds',  'temperature',\n",
    "                                 'respiratoryrate',  'heartrate', 'meanbp']].copy()\n",
    "    \n",
    "    # set the missing data to NaN\n",
    "    lst_clms = ['eyes', 'motor', 'verbal', 'meds', 'temperature',\n",
    "                'respiratoryrate',  'heartrate', 'meanbp']\n",
    "    for clm in lst_clms:\n",
    "        df_temp.loc[df_temp[clm] == -1, [clm]] = np.nan\n",
    "    \n",
    "    # create the GCS column\n",
    "    df_temp[\"GCS\"] = df_temp.eyes + df_temp.motor + df_temp.verbal\n",
    "\n",
    "    # add the patients that did not have any data at all \n",
    "    lst_pat_with_data = list(df_temp.patientunitstayid.unique())\n",
    "    lst_pat_without_data = [x for x in lst_ids if x not in lst_pat_with_data]\n",
    "    df_pat_without_data = pd.DataFrame(np.nan, index=[i for i in range(len(lst_pat_without_data))],\n",
    "                                       columns=[\"patientunitstayid\", 'dialysis',\n",
    "                                                'eyes', 'motor', 'verbal', 'meds', 'temperature',\n",
    "                                                'respiratoryrate', 'heartrate', 'meanbp', \"GCS\"])\n",
    "    df_pat_without_data['patientunitstayid'] = lst_pat_without_data\n",
    "    df_final = pd.concat([df_temp, df_pat_without_data])\n",
    "                       \n",
    "    # Rename columns\n",
    "    rename_clms = ['dialysis', 'eyes', 'motor', 'verbal', 'meds', 'temperature', 'respiratoryrate', 'heartrate', 'meanbp', \"GCS\"]\n",
    "    df_final = df_final.rename(columns={clm: \"aps_{}\".format(clm) for clm in rename_clms})\n",
    "\n",
    "    return df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e66c35f9-dcc2-465e-8ef2-e6952e6e1b20",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_cleaned_apachePredVar_basics(df_predvar, lst_ids):\n",
    "    \"\"\"\n",
    "    This function takes the apachePredVar Dataframe (or abbreviated) and a list of patientunitstayids and returns a \n",
    "    cleaned Dataframe with the information for those unitstays. The dataframe will have the ids as index.\n",
    "\n",
    "    :param df_predvar: DataFrame - apachePredVar Dataframe or abbreviated. \n",
    "\n",
    "    :param lst_ids: List - List of patientunitstayids of the target population.\n",
    "\n",
    "    :return: DataFrame with patientunitstayid as the index and the data\n",
    "    \"\"\"\n",
    "    \n",
    "    # reducing the general df to reduce the computational load\n",
    "    df_temp = df_predvar.loc[df_predvar[\"patientunitstayid\"].isin(lst_ids), ['patientunitstayid', 'thrombolytics',\n",
    "               'hepaticfailure', 'lymphoma', 'metastaticcancer', 'leukemia',\n",
    "               'midur', 'oobintubday1']].copy()\n",
    "    \n",
    "    # add the patients that did not have any data at all \n",
    "    lst_pat_with_data = list(df_temp.patientunitstayid.unique())\n",
    "    lst_pat_without_data = [x for x in lst_ids if x not in lst_pat_with_data]\n",
    "    df_pat_without_data = pd.DataFrame(np.nan, index=[i for i in range(len(lst_pat_without_data))],\n",
    "                                       columns=['patientunitstayid', 'thrombolytics',\n",
    "                                               'hepaticfailure', 'lymphoma', 'metastaticcancer', 'leukemia',\n",
    "                                               'midur', 'oobintubday1'])\n",
    "    df_pat_without_data['patientunitstayid'] = lst_pat_without_data\n",
    "    df_final = pd.concat([df_temp, df_pat_without_data])\n",
    "        \n",
    "    # Rename columns\n",
    "    rename_clms = ['thrombolytics','hepaticfailure', 'lymphoma', 'metastaticcancer', 'leukemia', 'midur', 'oobintubday1']\n",
    "    df_final = df_final.rename(columns={clm: \"pred_{}\".format(clm) for clm in rename_clms})\n",
    "\n",
    "    return df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5f324c04-81b6-4a31-8d1d-eaa11a570320",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_cleaned_apachePatientResult_basics(df_apacheresult, lst_ids):\n",
    "    \"\"\"\n",
    "    This function takes the apachePatientResult Dataframe (or abbreviated) and a list of patientunitstayids and returns a \n",
    "    cleaned Dataframe with the information for those unitstays. The dataframe will have the ids as index.\n",
    "\n",
    "    :param df_apacheresult: DataFrame - apachePatientResult Dataframe or abbreviated. \n",
    "\n",
    "    :param lst_ids: List - List of patientunitstayids of the target population.\n",
    "\n",
    "    :return: DataFrame with patientunitstayid as the index and the data\n",
    "    \"\"\"\n",
    "    \n",
    "    # reducing the general df to reduce the computational load\n",
    "    df_temp = df_apacheresult.loc[(df_apacheresult[\"apacheversion\"] == \"IVa\") & (df_apacheresult[\"patientunitstayid\"].isin(lst_ids)),\n",
    "                             ['patientunitstayid', 'acutephysiologyscore', 'apachescore','actualiculos', 'predictedhospitalmortality',\"predictedicumortality\", 'unabridgedhosplos']].copy()\n",
    "\n",
    "    # set the missing data to NaN\n",
    "    lst_minus_ones = ['acutephysiologyscore', 'apachescore',\"predictedicumortality\", 'predictedhospitalmortality']\n",
    "    for clm in lst_minus_ones:\n",
    "        df_temp.loc[df_temp[clm] == -1, [clm]] = np.nan\n",
    "\n",
    "    # add the patients that did not have any data at all \n",
    "    lst_pat_with_data = list(df_temp.patientunitstayid.unique())\n",
    "    lst_pat_without_data = [x for x in lst_ids if x not in lst_pat_with_data]\n",
    "    df_pat_without_data = pd.DataFrame(np.nan, index=[i for i in range(len(lst_pat_without_data))],\n",
    "                                       columns=['patientunitstayid', 'acutephysiologyscore', 'apachescore', 'actualiculos', 'predictedhospitalmortality', \"predictedicumortality\", 'unabridgedhosplos'])\n",
    "    df_pat_without_data['patientunitstayid'] = lst_pat_without_data\n",
    "    df_final = pd.concat([df_temp, df_pat_without_data])\n",
    "\n",
    "    return df_final\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "94f1a90d-f2bb-4434-832e-906700baec8f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_infusion_drugs(df_infusion, lst_ids, additional_dict=None, timeframe=(0, 1440)):\n",
    "    \"\"\"\n",
    "    This function returns a dataframe indicating whether patients received certain medication classes within a specified timeframe.\n",
    "\n",
    "    :param df_infusion: DataFrame - infusionDrug Dataframe from eICU. \n",
    "\n",
    "    :param lst_ids: List - List of patientunitstayids of the target population.\n",
    "\n",
    "    :param additional_dict: Dict - Additional/custom dictionary with the \"clm_name\": \"drugname|drugname|drugname\" format.\n",
    "\n",
    "    :param timeframe: Tuple, default is (0, 1440) - (lower offset, upper offset), offset bounds.\n",
    "\n",
    "    :return: DataFrame with the columns of who got which medication.\n",
    "    \"\"\"\n",
    "\n",
    "    lower_offset, upper_offset = timeframe\n",
    "\n",
    "    # reducing the general df to reduce the computational load\n",
    "    df_reduced = df_infusion.query(\"patientunitstayid in @lst_ids and @lower_offset <= infusionoffset <= @upper_offset\").copy()\n",
    "\n",
    "    df_reduced.drugname = df_reduced.drugname.str.lower()\n",
    "\n",
    "    dict_drugs = {\n",
    "        \"infusion_vaso_ino\": 'epinephrine|adrenaline|norepinephrine|levophed|dobutamine|dobutrex|vasopressin|isoprotenerol|isuprel|phenylephrine|neo-synephrine|dopamine|milrinone',\n",
    "        \"infusion_thrombolytic\": \"alteplase|activase|tpa|altaplase|altepase\"}\n",
    "\n",
    "    if additional_dict is not None:\n",
    "        dict_drugs.update(additional_dict)\n",
    "\n",
    "    lst_columns = []\n",
    "    \n",
    "    # loop over the the drug groups and look at whether patients received this as an infusion or not\n",
    "    for clm_name, drug_str in dict_drugs.items():\n",
    "\n",
    "        lst_pat_drug = df_reduced.loc[df_reduced.drugname.str.contains(drug_str), \"patientunitstayid\"].copy().unique().tolist()\n",
    "        lst_pat_wo_drug = [i for i in lst_ids if i not in lst_pat_drug]\n",
    "\n",
    "        df_pat_w_data = pd.DataFrame(lst_pat_drug, columns=['patientunitstayid'])\n",
    "        df_pat_w_data[clm_name] = 1\n",
    "\n",
    "        df_pat_without_data = pd.DataFrame(lst_pat_wo_drug, columns=['patientunitstayid'])\n",
    "        df_pat_without_data[clm_name] = 0\n",
    "\n",
    "        df_clm_final = pd.concat([df_pat_w_data, df_pat_without_data])\n",
    "        df_clm_final = df_clm_final.set_index(\"patientunitstayid\")\n",
    "\n",
    "        lst_columns.append(df_clm_final)\n",
    "\n",
    "    df_final = pd.concat(lst_columns, axis=1)\n",
    "\n",
    "    return df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e7332870-c363-4a02-8d9d-499952c349ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_infusion_drugs_relative_interval_from_start(df_infusion, lst_ids, additional_dict=None, overall_timeframe=(0, 1440), time_interval=360):\n",
    "    \"\"\"\n",
    "    This function returns a dataframe indicating whether patients received certain medication classes within a specified timeframe from the start. \n",
    "    More specifically, this function looks at the timeframe relative from the individual start of a patients data collection. This function is\n",
    "    meant for shorter timeframes where differences in the starting time of data-collection (e.g. starting at 5 minutes vs 65 minutes vs 92 minutes),.\n",
    "    e.g. induced by delayed data entry, has major impact. There will be no differences between this and the more general function for longer timeframes.\n",
    "\n",
    "    :param df_infusion: DataFrame - infusionDrug Dataframe from eICU. \n",
    "\n",
    "    :param lst_ids: List - List of patientunitstayids of the target population.\n",
    "\n",
    "    :param additional_dict: Dict - Additional/custom dictionary with the \"clm_name\": \"drugname|drugname|drugname\" format.\n",
    "\n",
    "    :param overall_timeframe: Tuple, default is (0, 1440) - (lower offset, upper offset), used to trim the data down to improve speed\n",
    "    \n",
    "    :param time_interval: Int, default is 360 - time in minutes from the start of data collection\n",
    "\n",
    "    :return: DataFrame with the columns of who got which medication.\n",
    "    \"\"\"\n",
    "\n",
    "    lower_overall_offset, upper_overall_offset = overall_timeframe\n",
    "    \n",
    "    # reducing the general df to reduce the computational load \n",
    "    df_in_icu = df_infusion.loc[(df_infusion.patientunitstayid.isin(lst_ids))\n",
    "                                 & (df_infusion.infusionoffset >= lower_overall_offset)\n",
    "                                 & (df_infusion.infusionoffset <= upper_overall_offset), :].copy()\n",
    "    \n",
    "\n",
    "    df_in_icu.drugname = df_in_icu.drugname.str.lower()\n",
    "\n",
    "    # calculate the starting time of the first point of data collection for the individual patients and then select only the intended time-interval\n",
    "    df_in_icu['first_observation'] = df_in_icu.groupby('patientunitstayid')['infusionoffset'].transform(min)\n",
    "    df_in_icu['group'] = ((df_in_icu['infusionoffset'] - df_in_icu['first_observation']) // (time_interval + 1)).astype(int)\n",
    "    df_in_icu = df_in_icu[df_in_icu['group'] == 0].copy()\n",
    "\n",
    "    dict_drugs = {\n",
    "        \"infusion_vaso_ino\": 'epinephrine|adrenaline|norepinephrine|levophed|dobutamine|dobutrex|vasopressin|isoprotenerol|isuprel|phenylephrine|neo-synephrine|dopamine|milrinone|isoproterenol',\n",
    "        \"infusion_thrombolytic\": \"alteplase|activase|tpa|altaplase|altepase\"}\n",
    "\n",
    "    if additional_dict is not None:\n",
    "        dict_drugs.update(additional_dict)\n",
    "\n",
    "    lst_columns = []\n",
    "    \n",
    "    # loop over the the drug groups and look at whether patients received this as an infusion or not\n",
    "    for clm_name, drug_str in dict_drugs.items():\n",
    "        \n",
    "        lst_pat_drug = df_in_icu.loc[df_in_icu.drugname.str.contains(drug_str), \"patientunitstayid\"].copy().unique().tolist()\n",
    "\n",
    "        lst_pat_wo_drug = [i for i in lst_ids if i not in lst_pat_drug]\n",
    "\n",
    "        df_pat_w_data = pd.DataFrame(lst_pat_drug, columns=['patientunitstayid'])\n",
    "        df_pat_w_data[clm_name] = 1\n",
    "\n",
    "        df_pat_without_data = pd.DataFrame(lst_pat_wo_drug, columns=['patientunitstayid'])\n",
    "        df_pat_without_data[clm_name] = 0\n",
    "\n",
    "        df_clm_final = pd.concat([df_pat_w_data, df_pat_without_data])\n",
    "        df_clm_final.set_index(\"patientunitstayid\", inplace=True)\n",
    "\n",
    "        lst_columns.append(df_clm_final)\n",
    "        \n",
    "    df_final = pd.concat(lst_columns, axis=1)\n",
    "\n",
    "    return df_final\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1a6242e3-7990-487b-bf38-8c879aba0e09",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_mechanically_ventilated_from_start_relative(df_resp_chart, df_resp_care, df_physical, df_nurse_chart, lst_ids,\n",
    "                                                 time_interval=360, overall_offset=(0, 1440)):\n",
    "    \"\"\"\n",
    "    This function returns, whether patients were mechanically ventilated during the given time from the start of admission/data collection.\n",
    "    More specifically, this function looks at the timeframe relative from the individual start of a patients data collection. This function is\n",
    "    meant for shorter timeframes where differences in the starting time of data-collection (e.g. starting at 5 minutes vs 65 minutes vs 92 minutes),\n",
    "    e.g. induced by delayed data entry, has major impact.\n",
    "    \n",
    "    :param df_resp_chart: Dataframe - respiratoryCharting dataframe from the eICU\n",
    "    :param df_resp_care: Dataframe - respiratoryCare dataframe from the eICU\n",
    "    :param df_physical: Dataframe - physicalExam dataframe from the eICU\n",
    "    :param df_nurse_chart: Dataframe - nurseCharting dataframe from the eICU\n",
    "    :param lst_ids: List - List of patientunitstayids of the target population.\n",
    "    :param time_interval: Int, default is 360 - time in minutes from the start of data collection\n",
    "    :param overall_offset: Tuple, default is (0, 1440) - (lower offset, upper offset), used to trim the data down to improve speed\n",
    "    :return: DataFrame with a column \"mech_vent_first_{time_interval}_min\" of who was mechanically ventilated at some point during this\n",
    "    timeframe from the start\n",
    "    \"\"\"\n",
    "\n",
    "    lower_offset, higher_offset = overall_offset\n",
    "    \n",
    "    # reducing the general df to reduce the computational load\n",
    "    df_pe_red = df_physical.loc[(df_physical.patientunitstayid.isin(lst_ids)) &\n",
    "                                (df_physical.physicalexamoffset >= lower_offset) &\n",
    "                                (df_physical.physicalexamoffset <= higher_offset), :].copy()\n",
    "\n",
    "    df_nc_red = df_nurse_chart.loc[(df_nurse_chart.patientunitstayid.isin(lst_ids)) &\n",
    "                                   (df_nurse_chart.nursingchartoffset >= lower_offset) &\n",
    "                                   (df_nurse_chart.nursingchartoffset <= higher_offset), :].copy()\n",
    "\n",
    "    df_rt_red = df_resp_chart.loc[(df_resp_chart.patientunitstayid.isin(lst_ids)) &\n",
    "                                   (df_resp_chart.respchartoffset >= lower_offset) &\n",
    "                                   (df_resp_chart.respchartoffset <= higher_offset), :].copy()\n",
    "\n",
    "    df_re_red = df_resp_care.loc[(df_resp_care.patientunitstayid.isin(lst_ids)), :].copy()\n",
    "\n",
    "    # get a dictionary with all the relative individual start times: dict_first_pe\n",
    "    # This is derived from the physicalExaminations table as of these 4, it is the most granular/usually has the first data entry\n",
    "    # If a ICU-admission cannot be found in the physicalExamination table, then it's relative starting time is set to 0 (conservatively)\n",
    "    df_initial_pe = df_pe_red.groupby('patientunitstayid')['physicalexamoffset'].min().reset_index()\n",
    "\n",
    "    dict_first_pe = dict(zip(df_initial_pe[\"patientunitstayid\"], df_initial_pe[\"physicalexamoffset\"]))\n",
    "\n",
    "    missing_ids_first_neuro = set(lst_ids) - set(dict_first_pe.keys())\n",
    "    dict_first_pe.update({id_number: 0 for id_number in missing_ids_first_neuro})\n",
    "\n",
    "    # add these initial start times to all the dataframes and sort for only values that are in the actual timeframe (or before)\n",
    "    df_pe_red['first_observation'] = df_pe_red.patientunitstayid.map(dict_first_pe)\n",
    "    df_pe_red['poss_before'] = (df_pe_red['physicalexamoffset'] - df_pe_red['first_observation']).astype(int)\n",
    "    df_pe_red['group'] = ((df_pe_red['physicalexamoffset'] - df_pe_red['first_observation']) // (time_interval + 1)).astype(int)\n",
    "    df_pe_red = df_pe_red[(df_pe_red['group'] == 0) | (df_pe_red['poss_before'] < -1)].copy()\n",
    "\n",
    "    df_nc_red['first_observation'] = df_nc_red.patientunitstayid.map(dict_first_pe)\n",
    "    df_nc_red['poss_before'] = (df_nc_red['nursingchartoffset'] - df_nc_red['first_observation']).astype(int)\n",
    "    df_nc_red['group'] = ((df_nc_red['nursingchartoffset'] - df_nc_red['first_observation']) // (time_interval + 1)).astype(int)\n",
    "    df_nc_red = df_nc_red[(df_nc_red['group'] == 0) | (df_nc_red['poss_before'] < -1)].copy()\n",
    "\n",
    "    df_rt_red['first_observation'] = df_rt_red.patientunitstayid.map(dict_first_pe)\n",
    "    df_rt_red['poss_before'] = (df_rt_red['respchartoffset'] - df_rt_red['first_observation']).astype(int)\n",
    "    df_rt_red['group'] = ((df_rt_red['respchartoffset'] - df_rt_red['first_observation']) // (time_interval + 1)).astype(int)\n",
    "    df_rt_red = df_rt_red[(df_rt_red['group'] == 0) | (df_rt_red['poss_before'] < -1)].copy()\n",
    "\n",
    "    # Rarely, the the vent-start time is entered as lower than the actual entry of the information, so we adjust for these vent-times preceding the \n",
    "    # target time-interval\n",
    "    df_re_red.loc[df_re_red.ventstartoffset != 0, 'respcarestatusoffset'] = df_re_red.loc[df_re_red.ventstartoffset != 0, ['respcarestatusoffset', 'ventstartoffset']].min(axis=1)\n",
    "    df_re_red['first_observation'] = df_re_red.patientunitstayid.map(dict_first_pe)\n",
    "    df_re_red['poss_before'] = (df_re_red['respcarestatusoffset'] - df_re_red['first_observation']).astype(int)\n",
    "    df_re_red['group'] = ((df_re_red['respcarestatusoffset'] - df_re_red['first_observation']) // (time_interval + 1)).astype(int)\n",
    "    df_re_red = df_re_red[(df_re_red['group'] == 0) | (df_re_red['poss_before'] < -1)].copy()\n",
    "\n",
    "    lst_all_vent_lsts = []\n",
    "\n",
    "    # get the ICU-admissions indicating mechanical ventilation from the nurseCharting table\n",
    "    df_nc_vent = df_nc_red.loc[\n",
    "                 ((df_nc_red.nursingchartcelltypevallabel == \"O2 Admin Device\") &\n",
    "                  (df_nc_red.nursingchartvalue.isin([\"ventilator\", \"trach collar\", \"vent\", \"VENT\", \"vented\", \"ac 10/400/40+5\", \"AC10 500 60 5\"]))) |\n",
    "                 (df_nc_red.nursingchartcelltypevallabel == \"End Tidal CO2\"), :].copy()\n",
    "    lst_nc_vent = list(df_nc_vent.patientunitstayid.unique())\n",
    "    lst_all_vent_lsts.append(lst_nc_vent)\n",
    "\n",
    "    # get the ICU-admissions indicating mechanical ventilation from the physicalExamination table\n",
    "    df_pe_vent = df_pe_red.loc[((df_pe_red.physicalexampath.str.contains(\"Pulmonary/Airway\", regex=False, case=False)) &\n",
    "                                (df_pe_red.physicalexamvalue.isin([\"intubated\", \"tracheostomy\"]))) |\n",
    "                               ((df_pe_red.physicalexampath.str.contains(\"Constitutional/Vital Sign and Physiological Data/Resp Mode/\", regex=False, case=False)) &\n",
    "                                (df_pe_red.physicalexamvalue == \"ventilated\")), :].copy()\n",
    "    lst_pe_vent = list(df_pe_vent.patientunitstayid.unique())\n",
    "    lst_all_vent_lsts.append(lst_pe_vent)\n",
    "\n",
    "    # get the ICU-admissions indicating mechanical ventilation from the respiratoryCare table\n",
    "    df_re_vent = df_re_red.loc[df_re_red.lowexhmvlimit.notna() |\n",
    "                               df_re_red.hiexhmvlimit.notna() |\n",
    "                               df_re_red.lowexhtvlimit.notna() |\n",
    "                               df_re_red.hipeakpreslimit.notna() |\n",
    "                               df_re_red.lowpeakpreslimit.notna() |\n",
    "                               df_re_red.hirespratelimit.notna() |\n",
    "                               df_re_red.lowrespratelimit.notna() |\n",
    "                               df_re_red.cuffpressure.notna() |\n",
    "                               df_re_red.airwaysize.notna() |\n",
    "                               df_re_red.airwayposition.notna() |\n",
    "                               df_re_red.airwaytype.isin([\"Oral ETT\", \"Tracheostomy\"]) , :].copy()\n",
    "    lst_re_vent = list(df_re_vent.patientunitstayid.unique())\n",
    "    lst_all_vent_lsts.append(lst_re_vent)\n",
    "\n",
    "    # get the ICU-admissions indicating mechanical ventilation from the respiratoryCharting table\n",
    "    df_rt_vent = df_rt_red.loc[\n",
    "                  ((df_rt_red.respcharttypecat == \"respFlowSettings\") &\n",
    "                   (df_rt_red.respchartvaluelabel.isin([\"TV/kg IBW\", \"Tidal Volume (set)\", \"Pressure Control\", \"PEEP\"]))) |\n",
    "                  ((df_rt_red.respcharttypecat == \"respFlowPtVentData\") &\n",
    "                   (df_rt_red.respchartvaluelabel.isin([\"Peak Insp. Pressure\", \"Mean Airway Pressure\", \"Exhaled MV\", \"Exhaled TV (machine)\", \"Plateau Pressure\", \"Compliance\"]))) |\n",
    "                  ((df_rt_red.respcharttypecat == \"respFlowCareData\") &\n",
    "                   (df_rt_red.respchartvaluelabel.isin(\n",
    "                       [\"Set Vt (Servo,LTV)\", \"Tidal Volume Observed (VT)\", \"Adult Con Setting Set RR\", \"Adult Con Setting Set Vt\", \"Secured at-ETT\", \"Adult Con Pt/Vent MinuteVentil\",\n",
    "                        \"Adult Con Pt/Vent InspiratorTV\", \"Adult Con Alarms Hi Press Alarm\", \"Endotracheal Tube Placement\", \"Tidal Volume, Delivered\",\n",
    "                        \"Set Fraction of Inspired Oxygen (FIO2)\", \"Mechanical Ventilator Compliance\", \"Mechanical Ventilation Slope\", \"Mechanical Ventilator Resistance\",\n",
    "                        \"Endotracheal Tube Placement Checked\", \"Mechanical Ventilator High Tidal Volume Alarm\", \"Mechanical Ventilator Mode\"]))) |\n",
    "                  ((df_rt_red.respcharttypecat == \"respFlowCareData\") & (df_rt_red.respchartvaluelabel == \"O2 Device\") &\n",
    "                   df_rt_red.respchartvalue.isin([\"Ventilator\", \"Trach mask/collar\", \"ETT\", \"Ambubag\"])), :].copy()\n",
    "    lst_rt_intub = list(df_rt_vent.patientunitstayid.unique())\n",
    "    lst_all_vent_lsts.append(lst_rt_intub)\n",
    "\n",
    "    # combine these lists to a binary column\n",
    "    lst_pat_intub = list({pat_id for sublist_ams in lst_all_vent_lsts for pat_id in sublist_ams})\n",
    "    lst_pat_wo_intub = [i for i in lst_ids if i not in lst_pat_intub]\n",
    "\n",
    "    final_clm_name = f\"mech_vent_first_{time_interval}_min\"\n",
    "\n",
    "    df_pat_intub = pd.DataFrame(lst_pat_intub, columns=['patientunitstayid'])\n",
    "    df_pat_intub[final_clm_name] = 1\n",
    "\n",
    "    df_pat_wo_intub = pd.DataFrame(lst_pat_wo_intub, columns=['patientunitstayid'])\n",
    "    df_pat_wo_intub[final_clm_name] = 0\n",
    "\n",
    "    df_final = pd.concat([df_pat_intub, df_pat_wo_intub], axis=0)\n",
    "\n",
    "    return df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "52bc3b6a-31c6-4aaf-82df-1fa31cbc554b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_AMS_from_start_relative(df_physical, df_nurse_chart, lst_ids, time_interval=360, overall_offset=(0, 1440)):\n",
    "    \"\"\"\n",
    "    This function returns, whether patients had AMS (defined as a GCS <5) during the given time from the start of admission/data collection.\n",
    "    More specifically, this function looks at the timeframe relative from the individual start of a patients data collection. This function is\n",
    "    meant for shorter timeframes where differences in the starting time of data-collection (e.g. starting at 5 minutes vs 65 minutes vs 92 minutes),\n",
    "    e.g. induced by delayed data entry, has major impact.\n",
    "    \n",
    "    :param df_physical: Dataframe - physicalExam dataframe from the eICU\n",
    "    :param df_nurse_chart: Dataframe - nurseCharting dataframe from the eICU\n",
    "    :param lst_ids: List - List of patientunitstayids of the target population.\n",
    "    :param time_interval: Int, default is 360 - time in minutes from the start of data collection\n",
    "    :param overall_offset: Tuple, default is (0, 1440) - (lower offset, upper offset), used to trim the data down to improve speed\n",
    "    :return: DataFrame with a column \"ams_first_{time_interval}_min\" of who had AMS at some point during this\n",
    "    timeframe from the start\n",
    "    \"\"\"\n",
    "    # reducing the general df to reduce the computational load\n",
    "    lower_offset, higher_offset = overall_offset\n",
    "\n",
    "    df_pe_red = df_physical.loc[(df_physical.patientunitstayid.isin(lst_ids)) &\n",
    "                                (df_physical.physicalexampath.str.contains(\"Neurologic/GCS/\")) &\n",
    "                                (df_physical.physicalexamoffset >= lower_offset) &\n",
    "                                (df_physical.physicalexamoffset <= higher_offset), :].copy()\n",
    "\n",
    "    df_nc_red = df_nurse_chart.loc[(df_nurse_chart.patientunitstayid.isin(lst_ids)) &\n",
    "                                 (df_nurse_chart.nursingchartoffset >= lower_offset) &\n",
    "                                 (df_nurse_chart.nursingchartoffset <= higher_offset), :].copy()\n",
    "\n",
    "    # get a dictionary with all the relative individual start times: dict_first_neuro_pe\n",
    "    df_pe_red['exampath'] = df_pe_red['physicalexampath'].str.replace(\n",
    "        \"notes/Progress Notes/Physical Exam/Physical Exam/\", \"\", 1)\n",
    "    df_initial_pe = df_pe_red.groupby('patientunitstayid')['physicalexamoffset'].min().reset_index()\n",
    "\n",
    "    dict_first_neuro_pe = dict(zip(df_initial_pe[\"patientunitstayid\"], df_initial_pe[\"physicalexamoffset\"]))\n",
    "\n",
    "    missing_ids_first_neuro = set(lst_ids) - set(dict_first_neuro_pe.keys())\n",
    "    dict_first_neuro_pe.update({id_number: 0 for id_number in missing_ids_first_neuro})\n",
    "\n",
    "    # add these initial start times to all the dataframes and sort for only values that are in the actual timeframe\n",
    "    df_pe_red['first_observation'] = df_pe_red.patientunitstayid.map(dict_first_neuro_pe)\n",
    "    df_pe_red['group'] = ((df_pe_red['physicalexamoffset'] - df_pe_red['first_observation']) // (time_interval + 1)).astype(int)\n",
    "    df_pe_red = df_pe_red[df_pe_red['group'] == 0].copy()\n",
    "\n",
    "    df_nc_red['first_observation'] = df_nc_red.patientunitstayid.map(dict_first_neuro_pe)\n",
    "    df_nc_red['group'] = ((df_nc_red['nursingchartoffset'] - df_nc_red['first_observation']) // (time_interval + 1)).astype(int)\n",
    "    df_nc_red = df_nc_red[df_nc_red['group'] == 0].copy()\n",
    "\n",
    "    lst_all_ams_lsts = []\n",
    "\n",
    "    # get the AMS patients from the physicalExam dataframe\n",
    "    df_pe_gcs = df_pe_red[df_pe_red.physicalexampath.str.contains(\"Neurologic/GCS/Verbal Score\", regex=False, case=False)].copy()\n",
    "    df_pe_gcs.physicalexamvalue = pd.to_numeric(df_pe_gcs.physicalexamvalue)\n",
    "    lst_pe_gcs_ams = list(df_pe_gcs[df_pe_gcs.physicalexamvalue <= 4].patientunitstayid.unique())\n",
    "    lst_all_ams_lsts.append(lst_pe_gcs_ams)\n",
    "    \n",
    "    # get the AMS patients from the nurseCharting dataframe\n",
    "    df_nc_gcs = df_nc_red[(df_nc_red.nursingchartcelltypevallabel == \"Glasgow coma score\") & (df_nc_red.nursingchartcelltypevalname == \"Verbal\")].copy()\n",
    "    df_nc_gcs.nursingchartvalue = pd.to_numeric(df_nc_gcs.nursingchartvalue)\n",
    "    lst_ns_gcs_ams = list(df_nc_gcs[df_nc_gcs.nursingchartvalue <= 4].patientunitstayid.unique())\n",
    "    lst_all_ams_lsts.append(lst_ns_gcs_ams)\n",
    "\n",
    "    df_nc_other_ams = df_nc_red.loc[((df_nc_red.nursingchartcelltypevallabel == \"Best Verbal Response\") & (df_nc_red.nursingchartvalue.str.contains(\"4|3|2|1|confused|intubated\", regex=True, case=False))), :].copy()\n",
    "    df_nc_other_ams = list(df_nc_other_ams.patientunitstayid.unique())\n",
    "    lst_all_ams_lsts.append(df_nc_other_ams)\n",
    "\n",
    "    # combine these lists to a binary column\n",
    "    lst_pat_w_ams = list({pat_id for sublist_ams in lst_all_ams_lsts for pat_id in sublist_ams})\n",
    "    lst_pat_wo_ams = [i for i in lst_ids if i not in lst_pat_w_ams]\n",
    "\n",
    "    ams_clm_name = f\"ams_first_{time_interval}_min\"\n",
    "\n",
    "    df_pat_w_ams = pd.DataFrame(lst_pat_w_ams, columns=['patientunitstayid'])\n",
    "    df_pat_w_ams[ams_clm_name] = 1\n",
    "\n",
    "    df_pat_without_ams = pd.DataFrame(lst_pat_wo_ams, columns=['patientunitstayid'])\n",
    "    df_pat_without_ams[ams_clm_name] = 0\n",
    "\n",
    "    df_final = pd.concat([df_pat_w_ams, df_pat_without_ams], axis=0)\n",
    "\n",
    "    return df_final\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ec9ef5fe-7f80-434e-9664-1a4b0922eeaf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fast_clean_data(array_vitals):\n",
    "    \"\"\"\n",
    "    Discard outliers that are > (median + 2 IQR) or < (median - 2 IQR)\n",
    "\n",
    "    :param lst_values: List - list of values (eg. mean BPs from a certain timeframe of a patient)\n",
    "\n",
    "    :return: Array - numpy array of cleaned values\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # to detect outliers for the patients own baseline:\n",
    "    q25, q50, q75 = np.percentile(array_vitals, [25, 50, 75])\n",
    "    iqr = q75 - q25\n",
    "\n",
    "    cleaned_array = array_vitals[(array_vitals >= (q50 - 2 * iqr)) & (array_vitals <= (q50 + 2 * iqr))].copy()\n",
    "\n",
    "    return cleaned_array\n",
    "\n",
    "\n",
    "def groupby_vitals_per_hour(x, agg_timeunit):\n",
    "    \"\"\"\n",
    "    Discard outliers (apply fast_clean_data function ()) and then summarize the data in this timeframe as a\n",
    "    single value per patient\n",
    "    \"\"\"\n",
    "    np_hourly_vitals = x.to_numpy()\n",
    "\n",
    "    cleaned_hourly = fast_clean_data(np_hourly_vitals)\n",
    "\n",
    "    if agg_timeunit == \"median\":\n",
    "        hour_vital = np.median(cleaned_hourly)\n",
    "    if agg_timeunit == \"max\":\n",
    "        hour_vital = np.max(cleaned_hourly)\n",
    "    if agg_timeunit == \"min\":\n",
    "        hour_vital = np.min(cleaned_hourly)\n",
    "\n",
    "    return hour_vital\n",
    "\n",
    "\n",
    "def groupby_vitals_total(x, agg_total):\n",
    "    \"\"\"\n",
    "    Summarize the data in this timeframe as a single value per patient\n",
    "    \"\"\"\n",
    "    np_total_vitals = x.to_numpy()\n",
    "\n",
    "    if agg_total == \"median\":\n",
    "        total_vital = np.median(np_total_vitals)\n",
    "    if agg_total == \"max\":\n",
    "        total_vital = np.max(np_total_vitals)\n",
    "    if agg_total == \"min\":\n",
    "        total_vital = np.min(np_total_vitals)\n",
    "\n",
    "    return total_vital\n",
    "\n",
    "\n",
    "def fast_vitals_periodic(df_periodic, lst_ids, vital_name, realistic_bounds, offset, agg_timeunit=\"median\",\n",
    "                         agg_total=\"median\", timeunit=60, temp_nurse_bool=False, temp_nursechart=None):\n",
    "    \"\"\"\n",
    "        Takes the vitalPeriodic table of eICU, target patientunitstayids as a list, offset bounds, and realistic bounds and a vitalname and\n",
    "        returns the aggregated and cleaned value for that offset timeframe. There are different options to choose from on how to aggregate that\n",
    "        value. If looking at the temperature, there is the option to include all temperature measurements from the nurses charting (which often \n",
    "        primarily includes the temperature values of a patient. Pulsepressure is calculated from the respective BP_sys - BP_dia. (will \n",
    "        automatically use 20/300 (systolic) and 10/200 (diastolic) as bounds)\n",
    "        Accepted vitalnames: temperature, sao2, heartrate, respiration, cvp, etco2, systemicsystolic, systemicdiastolic, systemicmean, pasystolic, \n",
    "        padiastolic, pamean, icp\n",
    "\n",
    "        :param df_periodic: Dataframe - abbreviated (! unless a lot of free RAM) Dataframe of the vitalPeriodic table of eICU\n",
    "\n",
    "        :param lst_ids: List - list of patientunitstayids of the target population\n",
    "\n",
    "        :param vital_name: String - Column name of the vital \n",
    "\n",
    "        :param realistic_bounds: Tuple - realistic values of the vital in the form of (lower bound, upper bound) eg. (20,100) for fio2\n",
    "\n",
    "        :param offset: Tuple - (lower time offest, upper time offset)\n",
    "\n",
    "        :param agg_timeunit: String, picklist, preset \"median\" - whether to use \"median\", \"max\" or \"min\" to aggregate the values per timeunit (if the\n",
    "                offset duration is longer than the timeunit)\n",
    "\n",
    "        :param agg_total: String, picklist, preset \"median\" - whether to use \"median\", \"max\" or \"min\" to aggregate the values to the final value\n",
    "        \n",
    "        :param timeunit: Int, preset 60 - Number of minutes for the timeunit\n",
    "        \n",
    "        :param temp_nurse_bool: Boolean, preset False - Whether to use the nurse charting for the temperature\n",
    "        \n",
    "        :param temp_nursechart: Dataframe - NurseCharting Dataframe of the eICU if the vital_name is temperature and temp_nurse_bool is True\n",
    "\n",
    "        :return: Dataframe \n",
    "        \"\"\"\n",
    "\n",
    "    # reducing the general df to reduce the computational load\n",
    "    df_reduced = df_periodic[df_periodic[\"patientunitstayid\"].isin(lst_ids)].copy()\n",
    "\n",
    "    # open the tuples of the bounds \n",
    "    lower_realistic_bound, upper_realistic_bound = realistic_bounds\n",
    "    lower_offset, upper_offset = offset\n",
    "\n",
    "    # next reduction, incorporating the big offset bounds and the realistic bounds\n",
    "    df_temp = df_reduced.loc[\n",
    "        (df_reduced[vital_name] >= lower_realistic_bound) & (df_reduced[vital_name] <= upper_realistic_bound) &\n",
    "        (df_reduced[\"observationoffset\"] >= lower_offset) & (df_reduced[\"observationoffset\"] <= upper_offset),\n",
    "        [\"patientunitstayid\", \"observationoffset\", vital_name]].copy().dropna()\n",
    "\n",
    "    # calculate the pulsepressure if this is selected; via systolic BP - diastolic BP\n",
    "    if vital_name == \"pulsepressure\":\n",
    "        df_temp_initial = df_reduced.loc[(df_reduced[\"systemicsystolic\"] >= 20) & (df_reduced[\"systemicsystolic\"] <= 300) &\n",
    "                                         (df_reduced[\"systemicdiastolic\"] >= 10) & (df_reduced[\"systemicdiastolic\"] <= 200) &\n",
    "                                         (df_reduced[\"observationoffset\"] >= lower_offset) & (\n",
    "                                                 df_reduced[\"observationoffset\"] <= upper_offset),\n",
    "                                         [\"patientunitstayid\", \"observationoffset\", \"systemicsystolic\", \"systemicdiastolic\"]].copy()\n",
    "\n",
    "        df_temp = (df_temp_initial.assign(pulsepressure=df_temp_initial[\"systemicsystolic\"] - df_temp_initial[\"systemicdiastolic\"])\n",
    "                   .drop(columns=[\"systemicsystolic\", \"systemicdiastolic\"])\n",
    "                   .dropna()\n",
    "                   )\n",
    "        \n",
    "    # add the temperature information from the nurse chart if temperature is selected and this feature is used\n",
    "    if vital_name == \"temperature\" and temp_nurse_bool:\n",
    "        # reduce the nurse charting to lessen the computational load\n",
    "        df_nursechart = temp_nursechart[temp_nursechart[\"patientunitstayid\"].isin(lst_ids)].copy()\n",
    "        df_n_char_red = df_nursechart.loc[(df_nursechart.nursingchartoffset <= upper_offset) &\n",
    "                                          (df_nursechart.nursingchartoffset >= lower_offset) &\n",
    "                                          (df_nursechart.nursingchartcelltypevallabel == \"Temperature\") &\n",
    "                                          (df_nursechart.nursingchartcelltypevalname.isin(\n",
    "                                              ['Temperature (C)', 'Temperature (F)'])),\n",
    "                                          [\"patientunitstayid\", \"nursingchartoffset\", \"nursingchartcelltypevalname\",\n",
    "                                           \"nursingchartvalue\"]].copy()\n",
    "        \n",
    "        # adjust for the fact that some values are taken as °F and some as °C\n",
    "        df_n_char_red.nursingchartvalue = df_n_char_red.nursingchartvalue.astype(float)\n",
    "        df_n_char_red[\"temperature\"] = df_n_char_red.apply(lambda x: ((x.nursingchartvalue - 32) * (\n",
    "                    5 / 9)) if x.nursingchartcelltypevalname == 'Temperature (F)' else x.nursingchartvalue, axis=1)\n",
    "        df_n_char_red = df_n_char_red.rename(columns={\"nursingchartoffset\": \"observationoffset\"})\n",
    "        df_n_char_final = df_n_char_red.loc[(df_n_char_red[vital_name] >= lower_realistic_bound) & (\n",
    "                    df_n_char_red[vital_name] <= upper_realistic_bound),\n",
    "                                            [\"patientunitstayid\", \"observationoffset\",\n",
    "                                             vital_name]].copy().reset_index(drop=True)\n",
    "\n",
    "        df_temp = pd.concat([df_temp, df_n_char_final])\n",
    "\n",
    "    # create bins for the timeunit in the given offset interval and then cut the column to these bins\n",
    "    lst_bins = [i for i in range(lower_offset, upper_offset + 1, timeunit) if i <= upper_offset]\n",
    "    \n",
    "    if (upper_offset - lower_offset) % timeunit != 0: \n",
    "        lst_bins.append(upper_offset)\n",
    "\n",
    "    df_temp.observationoffset = pd.cut(df_temp.observationoffset, bins=lst_bins, right=True, include_lowest=True)\n",
    "\n",
    "    # group first by hour (cleaning the data of outliers) and then over the total offset span\n",
    "    df_grouped_hours = (df_temp\n",
    "                        .groupby([\"patientunitstayid\", \"observationoffset\"])\n",
    "                        .agg(lambda x: groupby_vitals_per_hour(x, agg_timeunit=agg_timeunit))\n",
    "                        .reset_index()\n",
    "                        .drop(columns=[\"observationoffset\"])\n",
    "                        .dropna()\n",
    "                        .groupby([\"patientunitstayid\"])\n",
    "                        .agg(lambda x: groupby_vitals_total(x, agg_total=agg_total))\n",
    "                        .reset_index()\n",
    "                        )\n",
    "\n",
    "    # make a dataframe with a single column containing the ids and then merge the results to that\n",
    "    df_pat = pd.DataFrame({'patientunitstayid': lst_ids})\n",
    "    clm_name = \"{}_{}_{}to{}_u{}\".format(vital_name, agg_total, lower_offset, upper_offset, timeunit)\n",
    "    df_pat_final = df_pat.merge(df_grouped_hours, on=\"patientunitstayid\", how=\"left\").rename(columns={vital_name: clm_name})\n",
    "\n",
    "    return df_pat_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ec0189e7-0849-4770-8748-54dc8d2859fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fast_vitals_combined(df_periodic, df_aperiodic, lst_ids, vital_name, realistic_bounds, offset, agg_timeunit=\"median\",\n",
    "                         agg_total=\"median\", timeunit=60):\n",
    "    \"\"\"\n",
    "    Takes the both the vitalPeriodic and Aperiodic tables of eICU, target patientunitstayids as a list, offset bounds, and realistic bounds and a vitalname and\n",
    "    returns the aggregated and cleaned value for that offset timeframe. There are different options to choose from on how to aggregate that\n",
    "    value. Possible vitalnames: systolic, diastolic, mean_bp, pulsepressure\n",
    "\n",
    "    :param df_periodic: Dataframe - vitalPeriodic Dataframe of the eICU Database (abbreviated unless a lot of free RAM)\n",
    "\n",
    "    :param df_aperiodic: Dataframe - vitalAperiodic Dataframe (abbreviated unless a lot of free RAM)\n",
    "\n",
    "    :param lst_ids: List - list of patientunitstayids of the target population\n",
    "\n",
    "    :param vital_name: String, picklist - options \"systolic\", \"diastolic\", \"mean_bp\", \"pulsepressure\"\n",
    "\n",
    "    :param realistic_bounds: Tuple - realistic values of the vital in the form of (lower bound, upper bound) eg. (20, 250) for systolic\n",
    "\n",
    "    :param offset: Tuple - (lower time offest, time upper offset)\n",
    "\n",
    "    :param agg_timeunit: String, picklist, preset \"median\" - whether to use \"median\", \"max\" or \"min\" to aggregate the values per timeunit\n",
    "    (if the offset-duration is longer than the timeunit)\n",
    "\n",
    "    :param agg_total: String, picklist, preset \"median\" - whether to use \"median\", \"max\" or \"min\" to aggregate the values to the final value\n",
    "    \n",
    "    :param timeunit: Int, preset 60 - Number of minutes for the timeunit\n",
    "\n",
    "    :return: Dataframe \n",
    "    \"\"\"\n",
    "\n",
    "    # dictionary that sorts the vital_names to the respective names of the columns in the periodic and Aperiodic dfs\n",
    "    dict_vitalnames = {\n",
    "        \"systolic\": (\"systemicsystolic\", \"noninvasivesystolic\"),\n",
    "        \"diastolic\": (\"systemicdiastolic\", \"noninvasivediastolic\"),\n",
    "        \"mean_bp\": (\"systemicmean\", \"noninvasivemean\")\n",
    "    }\n",
    "\n",
    "    # reducing the general dfs to reduce the computational load\n",
    "    df_reduced_periodic = df_periodic[df_periodic[\"patientunitstayid\"].isin(lst_ids)].copy()\n",
    "    df_reduced_aperiodic = df_aperiodic[df_aperiodic[\"patientunitstayid\"].isin(lst_ids)].copy()\n",
    "\n",
    "    # open the tuples\n",
    "    lower_realistic_bound, upper_realistic_bound = realistic_bounds\n",
    "    lower_offset, upper_offset = offset\n",
    "\n",
    "    # next reduction, incorporating the big offset bounds and the realistic bounds into each dataframe and then adding both\n",
    "    # datafrems to have one united dataframes with all the vitals values\n",
    "    # calculate the pulsepressure if this is selected; via systolic BP - diastolic BP\n",
    "    if vital_name == \"pulsepressure\":\n",
    "        df_temp_initial_periodic = df_reduced_periodic.loc[\n",
    "            (df_reduced_periodic[\"systemicsystolic\"] >= 20) & (df_reduced_periodic[\"systemicsystolic\"] <= 300) &\n",
    "            (df_reduced_periodic[\"systemicdiastolic\"] >= 10) & (df_reduced_periodic[\"systemicdiastolic\"] <= 200) &\n",
    "            (df_reduced_periodic[\"observationoffset\"] >= lower_offset) & (\n",
    "                    df_reduced_periodic[\"observationoffset\"] <= upper_offset),\n",
    "            [\"patientunitstayid\", \"observationoffset\", \"systemicsystolic\", \"systemicdiastolic\"]].copy()\n",
    "\n",
    "        df_temp_periodic = (df_temp_initial_periodic.assign(\n",
    "            pulsepressure=df_temp_initial_periodic[\"systemicsystolic\"] - df_temp_initial_periodic[\"systemicdiastolic\"])\n",
    "                            .drop(columns=[\"systemicsystolic\", \"systemicdiastolic\"])\n",
    "                            .dropna()\n",
    "                            )\n",
    "\n",
    "        df_temp_initial_aperiodic = df_reduced_aperiodic.loc[\n",
    "            (df_reduced_aperiodic[\"noninvasivesystolic\"] >= 20) & (df_reduced_aperiodic[\"noninvasivesystolic\"] <= 300) &\n",
    "            (df_reduced_aperiodic[\"noninvasivediastolic\"] >= 10) & (df_reduced_aperiodic[\"noninvasivediastolic\"] <= 200) &\n",
    "            (df_reduced_aperiodic[\"observationoffset\"] >= lower_offset) & (\n",
    "                    df_reduced_aperiodic[\"observationoffset\"] <= upper_offset),\n",
    "            [\"patientunitstayid\", \"observationoffset\", \"noninvasivesystolic\", \"noninvasivediastolic\"]].copy()\n",
    "\n",
    "        df_temp_aperiodic = (df_temp_initial_aperiodic.assign(\n",
    "            pulsepressure=df_temp_initial_aperiodic[\"noninvasivesystolic\"] - df_temp_initial_aperiodic[\"noninvasivediastolic\"])\n",
    "                             .drop(columns=[\"noninvasivesystolic\", \"noninvasivediastolic\"])\n",
    "                             .dropna()\n",
    "                             )\n",
    "        \n",
    "    # path for systolic, diastolic and mean_bp\n",
    "    else:\n",
    "        key_periodic, key_aperiodic = dict_vitalnames[vital_name]\n",
    "        df_temp_periodic = df_reduced_periodic.loc[\n",
    "            (df_reduced_periodic[key_periodic] >= lower_realistic_bound) & (df_reduced_periodic[key_periodic] <= upper_realistic_bound) &\n",
    "            (df_reduced_periodic[\"observationoffset\"] >= lower_offset) & (df_reduced_periodic[\"observationoffset\"] <= upper_offset),\n",
    "            [\"patientunitstayid\", \"observationoffset\", key_periodic]].copy().dropna().rename(columns={key_periodic: vital_name})\n",
    "        df_temp_aperiodic = df_reduced_aperiodic.loc[\n",
    "            (df_reduced_aperiodic[key_aperiodic] >= lower_realistic_bound) & (\n",
    "                        df_reduced_aperiodic[key_aperiodic] <= upper_realistic_bound) &\n",
    "            (df_reduced_aperiodic[\"observationoffset\"] >= lower_offset) & (df_reduced_aperiodic[\"observationoffset\"] <= upper_offset),\n",
    "            [\"patientunitstayid\", \"observationoffset\", key_aperiodic]].copy().dropna().rename(columns={key_aperiodic: vital_name})\n",
    "\n",
    "    df_temp_whole = pd.concat([df_temp_periodic, df_temp_aperiodic])\n",
    "\n",
    "    # create bins for the timeunit in the given offset interval and then cut the column to these bins\n",
    "    lst_bins = [i for i in range(lower_offset, upper_offset + 1, timeunit) if i <= upper_offset]\n",
    "    \n",
    "    if (upper_offset - lower_offset) % timeunit != 0:\n",
    "        lst_bins.append(upper_offset)\n",
    "\n",
    "    df_temp_whole.observationoffset = pd.cut(df_temp_whole.observationoffset, bins=lst_bins, right=True, include_lowest=True)\n",
    "\n",
    "    # group first by hour (cleaning the data of outliers) and then over the total offset span\n",
    "    df_grouped_all = (df_temp_whole\n",
    "                      .groupby([\"patientunitstayid\", \"observationoffset\"])\n",
    "                      .agg(lambda x: groupby_vitals_per_hour(x, agg_timeunit=agg_timeunit))\n",
    "                      .reset_index()\n",
    "                      .drop(columns=[\"observationoffset\"])\n",
    "                      .dropna()\n",
    "                      .groupby([\"patientunitstayid\"])\n",
    "                      .agg(lambda x: groupby_vitals_total(x, agg_total=agg_total))\n",
    "                      .reset_index()\n",
    "                      )\n",
    "\n",
    "    # make a dataframe with a single column containing the ids and then merge the results to that\n",
    "    df_pat = pd.DataFrame({'patientunitstayid': lst_ids})\n",
    "    clm_name = \"{}_{}_{}to{}_u{}\".format(vital_name, agg_total, lower_offset, upper_offset, timeunit)\n",
    "    df_pat_final = df_pat.merge(df_grouped_all, on=\"patientunitstayid\", how=\"left\").rename(columns={vital_name: clm_name})\n",
    "\n",
    "    return df_pat_final\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "26d617e9-40b8-4c40-94fb-b4f189a7a604",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_time_to_death_from_unit_admit(x):\n",
    "    # if the patient did not die, return NaN\n",
    "    if x.hospitaldischargestatus == \"Alive\":\n",
    "        return np.nan\n",
    "    \n",
    "    # if the patient died in the ICU then the time on ICU is the time-to-death\n",
    "    if x.unitdischargestatus == \"Expired\":\n",
    "        return x.actualiculos\n",
    "    \n",
    "    # if the patient died in the hospital calculate the time to death by subtracting the time to ICU admission\n",
    "    if x.hospitaldischargestatus == \"Expired\":\n",
    "        time_to_death = x.unabridgedhosplos - (x.hospitaladmitoffset/(24*60))\n",
    "        return time_to_death\n",
    "    \n",
    "    else:\n",
    "        return np.nan\n",
    "    \n",
    "\n",
    "def time_to_death_from_unit_admission(df_pat, df_apache_res, lst_ids):\n",
    "    \"\"\"\n",
    "    Compute the time to death from ICU-admission for a cohort of interest. Will return np.nan if the patient did not die and \n",
    "    for irregularities.\n",
    "    \n",
    "    :param df_pat: Dataframe - patient dataframe of the eICU or abbreviated\n",
    "    \n",
    "    :param df_apache_res: Dataframe - apachePatientResult dataframe of the eICU or abbreviated\n",
    "    \n",
    "    :param lst_ids: List - List of patientunitstayids\n",
    "    \n",
    "    return: Dataframe with 2 columns (patientunitstayids and time_to_death_unitadmit)\n",
    "    \"\"\"\n",
    "    \n",
    "    # reducing the general dfs to reduce the computational load\n",
    "    df_pat_red = df_pat.loc[df_pat.patientunitstayid.isin(lst_ids), \n",
    "                           [\"patientunitstayid\", \"hospitaldischargestatus\", \"unitdischargestatus\", \"hospitaladmitoffset\"]].copy()\n",
    "    df_apache_res_red = df_apache_res.loc[df_apache_res.patientunitstayid.isin(lst_ids),\n",
    "                                         [\"patientunitstayid\", 'actualiculos', 'unabridgedhosplos']].copy()\n",
    "    \n",
    "    # merging both to have all these columns ready for the apply method\n",
    "    df_combined = pd.merge(left=df_pat_red, right=df_apache_res_red, how=\"left\", on=\"patientunitstayid\")\n",
    "    df_combined = df_combined.drop_duplicates()\n",
    "    \n",
    "    # calculate the time-to-death in a row-wise approach\n",
    "    df_combined[\"time_to_death_unitadmit\"] = df_combined.apply(lambda x: apply_time_to_death_from_unit_admit(x), axis=1)\n",
    "    \n",
    "    df_final = df_combined[[\"patientunitstayid\", \"time_to_death_unitadmit\"]].copy()\n",
    "    \n",
    "    return df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "77cb169e-7b41-4fc0-8990-e26d84b1d6af",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def map_vitals_from_two_sources(x, df_ref_data, clm_aps, clm_own, threshold, aps_midpoint, side):\n",
    "    \"\"\"\n",
    "    Decide whether vitals are above or below a certain threshold based on both the APS extreme vitals and under certain conditions based on my own calculations:\n",
    "    The APS vitals are extremes from a certain midpoint. However, this goes both way. E.g. heartrate is measured as an extreme from the midpoint 75 in the APS.\n",
    "    This means that theoretically a recorded APS heartrate of 38 does not exlcude that this patient had a heartrate of 111 at some point as 38 is more extreme.\n",
    "    Therefore, in case \n",
    "\n",
    "    :param x: x - lambda x parameter\n",
    "    :param df_ref_data: Dataframe\n",
    "    :param clm_aps: String - column name of the aps vitals\n",
    "    :param clm_own: String - column name of my vitals\n",
    "    :param threshold: Int/Float - threshold, is NOT included (is used with > / < and NOT >= / <=! )\n",
    "    :param aps_midpoint: Int/Float - midpoint value the aps is based on\n",
    "    :param side: String, picklist - \"below\" or \"above\"\n",
    "    :return: value for mapping\n",
    "    \"\"\"\n",
    "    \n",
    "    # calculating the counterthreshold \n",
    "    if side == \"below\":\n",
    "        if threshold > aps_midpoint:\n",
    "            counterthresh = aps_midpoint + (threshold - aps_midpoint)\n",
    "        else:\n",
    "            counterthresh = aps_midpoint + (aps_midpoint - threshold)\n",
    "    if side == \"above\":\n",
    "        if threshold < aps_midpoint:\n",
    "            counterthresh = aps_midpoint - (aps_midpoint - threshold)\n",
    "        else:\n",
    "            counterthresh = aps_midpoint - (threshold - aps_midpoint) \n",
    "    \n",
    "    # values for 1 patient as this function is applied row-wise with 1 row representing 1 patient\n",
    "    value_aps = df_ref_data.loc[x][clm_aps]\n",
    "    value_own = df_ref_data.loc[x][clm_own]\n",
    "    \n",
    "    # if there is no data in both calculations return NaN\n",
    "    if np.isnan(value_aps) and np.isnan(value_own):\n",
    "        return np.nan\n",
    "    \n",
    "    # if there is no APS data (but my own data), use only my calculations\n",
    "    if np.isnan(value_aps):\n",
    "        # if we are looking for vitals above a certain threshold\n",
    "        if side == \"above\":\n",
    "            if value_own > threshold:\n",
    "                return 1    \n",
    "        # if we are looking for vitals below a certain threshold\n",
    "        if side == \"below\":\n",
    "            if value_own < threshold:\n",
    "                return 1\n",
    "        # if the vitals is not above/below a certain threshold\n",
    "        else:\n",
    "            return 0\n",
    "        \n",
    "    # if there is no own data (but APS data), use only the APS data\n",
    "    if np.isnan(value_own):\n",
    "        # if we are looking for vitals above a certain threshold\n",
    "        if side == \"above\":\n",
    "            if value_aps > threshold:\n",
    "                return 1  \n",
    "        # if we are looking for vitals below a certain threshold\n",
    "        if side == \"below\":\n",
    "            if value_aps < threshold:\n",
    "                return 1 \n",
    "        # if the vitals is not above/below a certain threshold\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "    # if there is data in both the APS column and my calculcations, use first the APS data and only\n",
    "    # under certain circumstances (see docstring) my own calculations instead\n",
    "    if side == \"above\":\n",
    "        if value_aps > threshold:\n",
    "            return 1\n",
    "        if value_aps < counterthresh:\n",
    "            if value_own > threshold:\n",
    "                return 1\n",
    "        else:\n",
    "            return 0\n",
    "        \n",
    "    if side == \"below\":\n",
    "        if value_aps < threshold:\n",
    "            return 1\n",
    "        if value_aps > counterthresh:\n",
    "            if value_own < threshold:\n",
    "                return 1\n",
    "        else:\n",
    "            return 0\n",
    "    else:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3bd7841-9f5a-40f9-a594-7843a8e54d74",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Demographic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "55a94892-9899-40c7-a8ff-3b3be4507657",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_pat = pd.read_csv(\"PE_data/patient_PE.csv\", low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "00e06116-fcb8-4d79-bff5-fae4ed4d4ab4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_patinfo_PE = get_basic_patient_info(df_pat, lst_pat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "571dd0c4-ad4f-4d90-8f9f-6edc248908ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Process the result (aggregate the ethnicity column as in, only keep the top 2 ethnicities as distinct categories; int-binarize the death columns)\n",
    "df_patinfo_PE.loc[~(df_patinfo_PE.ethnicity.isin(df_patinfo_PE.ethnicity.value_counts().index[:2].to_list())), \"ethnicity\"] = \"Other/Unknown\"\n",
    "df_patinfo_PE.ethnicity = df_patinfo_PE.ethnicity.fillna(\"Other/Unknown\")\n",
    "df_patinfo_PE.hospitaldischargestatus = df_patinfo_PE.hospitaldischargestatus.map({\"Expired\": 1, \"Alive\": 0})\n",
    "df_patinfo_PE.unitdischargestatus = df_patinfo_PE.unitdischargestatus.map({\"Expired\": 1, \"Alive\": 0})\n",
    "\n",
    "# the demographic PESI components\n",
    "df_patinfo_PE[\"PESI_age\"] = df_patinfo_PE[\"age\"]\n",
    "df_patinfo_PE[\"PESI_gender\"] = df_patinfo_PE[\"gender\"].map({\"Male\": 1, \"Female\":0})\n",
    "\n",
    "# sPESI age component (> 80 years old)\n",
    "df_patinfo_PE[\"sPESI_age\"] = df_patinfo_PE[\"PESI_age\"].map(lambda x: 1 if x > 80 else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9e989f6-baaa-49e3-a284-cb44df215a48",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Comorbidities "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c21abb0c-f8ba-4174-ae6a-bba27c683ecd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_pmh = pd.read_csv(\"PE_data/pastHistory_PE.csv\", low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "67770b48-0444-41f1-a7c3-3d5097918a9a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 64/64 [00:03<00:00, 19.52it/s]\n"
     ]
    }
   ],
   "source": [
    "df_pmhinfo = get_pastHistory(df_pmh, lst_pat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6bb22101-32c4-4c7e-b4a2-c43da54e09e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Merge the dataframe with the Comorbidities to the dataframe with the demographic data\n",
    "df_pe = pd.merge(\n",
    "    left=df_patinfo_PE,\n",
    "    right=df_pmhinfo,\n",
    "    how=\"left\",\n",
    "    on=\"patientunitstayid\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f93866-bbe2-44e9-9f18-ce692c67bb58",
   "metadata": {
    "tags": []
   },
   "source": [
    "## APACHE IVa, APS and associated variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c838dae4-a27f-4238-b1fa-ed341d8e0784",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_apsVar = pd.read_csv(\"PE_data/apacheApsVar_PE.csv\", low_memory=False)\n",
    "df_predVar = pd.read_csv(\"PE_data/apachePredVar_PE.csv\", low_memory=False)\n",
    "df_apacheresult = pd.read_csv(\"PE_data/apachePatientResult_PE.csv\", low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6309118b-2cc9-4572-99b5-9955b92556e2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_apsvarinfo = get_and_initial_clean_apacheApsVar(df_apsVar, lst_pat)\n",
    "df_predvarinfo = get_cleaned_apachePredVar_basics(df_predVar, lst_pat)\n",
    "df_apacheresult_info = get_cleaned_apachePatientResult_basics(df_apacheresult, lst_pat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "49019be4-2402-4e73-afe1-e884acb14cc6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Merge the results dataframes to the growing final dataframe\n",
    "df_pe = df_pe.merge(\n",
    "    right=df_apsvarinfo,\n",
    "    how=\"left\",\n",
    "    on=\"patientunitstayid\"\n",
    ")\n",
    "\n",
    "df_pe = df_pe.merge(\n",
    "    right=df_predvarinfo,\n",
    "    how=\"left\",\n",
    "    on=\"patientunitstayid\"\n",
    ")\n",
    "\n",
    "df_pe = df_pe.merge(\n",
    "    right=df_apacheresult_info,\n",
    "    how=\"left\",\n",
    "    on=\"patientunitstayid\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "875f4e58-6435-473d-8699-8c3cda40870e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### the PESI pmh components:\n",
    "# chronic pulmonary disease: if the patient has COPD or asthma or restrictive lung disease or uses home-O2 or is s/p LuTx\n",
    "df_pe[\"PESI_pulm\"] = 0\n",
    "df_pe.loc[(df_pe['pmh_COPD'] != 0) | (df_pe['pmh_asthma'] != 0) | (df_pe['pmh_home_o2'] != 0) |\n",
    "          (df_pe['pmh_restrictive_lung_disease'] != 0) | (df_pe['pmh_s_p_lungTx'] != 0), [\"PESI_pulm\"]] = 1\n",
    "df_pe.loc[(df_pe['pmh_COPD'].isna()) & (df_pe['pmh_asthma'].isna()) & (df_pe['pmh_home_o2'].isna()) &\n",
    "          (df_pe['pmh_restrictive_lung_disease'].isna()) & (df_pe['pmh_s_p_lungTx'].isna()), [\"PESI_pulm\"]] = np.nan\n",
    "\n",
    "# heart failure\n",
    "df_pe[\"PESI_hf\"] = df_pe.pmh_CHF.map(lambda x: 1 if x != 0 else 0)\n",
    "\n",
    "# cancer: if the patient has any type of cancer or has received cancer therapy in the past\n",
    "df_pe[\"PESI_cancer\"] = 0\n",
    "df_pe[\"PESI_cancer\"] = df_pe.apply(lambda x: 1 if (x.pmh_cancer_therapy != 0 or \n",
    "                                                   x.pred_metastaticcancer > 0 or \n",
    "                                                   x.pmh_cancer != 0 or\n",
    "                                                   x.pred_lymphoma > 0 or \n",
    "                                                   x.pred_leukemia > 0) else 0, axis=1)\n",
    "\n",
    "# cancer for the sPESI\n",
    "df_pe[\"sPESI_cancer\"] = df_pe[\"PESI_cancer\"]\n",
    "\n",
    "df_pe.loc[(df_pe[\"pmh_cancer_therapy\"].isna()) &\n",
    "          (df_pe[\"pmh_cancer\"].isna()) &\n",
    "          (df_pe[\"pred_lymphoma\"].isna()) &\n",
    "          (df_pe[\"pred_metastaticcancer\"].isna()) &\n",
    "          (df_pe[\"pred_leukemia\"].isna()), [\"PESI_cancer\"]] = np.nan\n",
    "\n",
    "# chronic cardiopulmonary disease: if the patient had either chronic pulmonary disease or a range of cardiac PMH\n",
    "df_pe[\"sPESI_cardiopulm\"] = df_pe.apply(lambda x: 1 if (x.PESI_pulm > 0 or \n",
    "                                                        x.PESI_hf > 0 or \n",
    "                                                        x.pmh_MI != 0 or\n",
    "                                                        x.pmh_pacemaker != 0 or \n",
    "                                                        x.pmh_AICD != 0 or\n",
    "                                                        x.pred_midur > 0 or\n",
    "                                                        x.pmh_CA_bypass != 0) else 0, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c36c6fc0-344d-4ca5-85ad-a827ac187e30",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Infusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "eafdbb63-e391-4a0f-91c2-9c857efa5023",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_infusions = pd.read_csv(\"PE_data/infusionDrug_PE.csv\", low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "befe9934-4196-4ae1-80e2-870d5d7582cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_inf_results = get_infusion_drugs(df_infusion=df_infusions, \n",
    "                                    lst_ids=lst_pat, \n",
    "                                    timeframe=(0, 1440))\n",
    "df_inf_results = df_inf_results.rename(columns={\"infusion_vaso_ino\": \"ICU_sPESI_infusion_vaso_ino\"}).reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "264631d9-4287-464a-93e9-aa247ddfd385",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Merge the results dataframe to the growing final dataframe\n",
    "df_pe = df_pe.merge(\n",
    "    right=df_inf_results,\n",
    "    how=\"left\",\n",
    "    on=\"patientunitstayid\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db4e47b0-7d6f-4e08-b8f3-1ac103393228",
   "metadata": {},
   "source": [
    "## AMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3b0ccc62-cb3d-4107-a374-b1c62f5fbc7c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# We defined AMS as a GCS verbal score < 5 (less than full score) using the APS (Acute Physiology Score) GCS verbal variable which contains the worst (lowest) score for the \n",
    "# first 24 hours after admission\n",
    "df_pe[\"PESI_ams\"] = df_pe.aps_verbal.map(lambda x: 1 if x < 5 else 0)\n",
    "df_pe[\"ICU_sPESI_ams\"] = df_pe.aps_verbal.map(lambda x: 1 if x < 5 else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1718e64b-2647-4279-9011-1c1f3bfe7ad9",
   "metadata": {},
   "source": [
    "## Intubation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bf6ebdef-34db-46bd-87bc-dad6c0a867f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Overall, we defined \"intubation\" as ever being intubated which corresponds to the APACHE variable oobintubday1\n",
    "df_pe[\"ICU_sPESI_intubation\"] = df_pe.pred_oobintubday1.map(lambda x: 1 if x == 1 else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e47dddd-7cb9-4dd3-8ecd-5326ac8ac9f5",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Vitals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a0622023-4825-41e7-a8cf-6501a417ea37",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_periodic = pd.read_csv(\"PE_data/vitalPeriodic_PE.csv\", low_memory=False)\n",
    "df_a_periodic = pd.read_csv(\"PE_data/vitalAperiodic_PE.csv\", low_memory=False)\n",
    "df_nurseCharting = pd.read_csv(\"PE_data/nurseCharting_PE.csv\", low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "27cde5c6-cf0a-4718-b480-e46dd70d50f0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:34<00:00,  8.60s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:23<00:00,  7.70s/it]\n"
     ]
    }
   ],
   "source": [
    "### General (median) vitals\n",
    "# dictionaries of extreme vitals that were excluded as outliers\n",
    "dict_vitals = {\n",
    "    \"heartrate\": (20, 200),\n",
    "    \"temperature\": (32, 43),\n",
    "    \"respiration\": (3, 80),\n",
    "    \"sao2\": (50, 100),\n",
    "}\n",
    "\n",
    "dict_vitals_combined = {\n",
    "    \"systolic\": (20, 250),\n",
    "    \"diastolic\": (5, 180),\n",
    "    \"mean_bp\": (10, 200)\n",
    "}\n",
    "\n",
    "lst_clms_vitals_general = []\n",
    "\n",
    "# for the \"periodic\" vitals\n",
    "for key, values in tqdm(dict_vitals.items()):\n",
    "    \n",
    "    if key == \"temperature\":\n",
    "        df_temp = fast_vitals_periodic(df_periodic=df_periodic, \n",
    "                                       lst_ids=lst_pat, \n",
    "                                       vital_name=key, \n",
    "                                       realistic_bounds=values, \n",
    "                                       offset=(0, 1440),  \n",
    "                                       agg_total=\"median\", \n",
    "                                       timeunit=30, \n",
    "                                       temp_nurse_bool=True, \n",
    "                                       temp_nursechart=df_nurseCharting)\n",
    "            \n",
    "    else:\n",
    "        df_temp = fast_vitals_periodic(df_periodic=df_periodic, \n",
    "                                       lst_ids=lst_pat, \n",
    "                                       vital_name=key, \n",
    "                                       realistic_bounds=values, \n",
    "                                       offset=(0, 1440), \n",
    "                                       agg_total=\"median\",  \n",
    "                                       timeunit=30)\n",
    "\n",
    "    lst_clms_vitals_general.append(df_temp)\n",
    "\n",
    "# for the vitals (the blood pressures) that use both the periodic and aperiodic datafiles\n",
    "for key, values in tqdm(dict_vitals_combined.items()):\n",
    "\n",
    "    df_temp = fast_vitals_combined(df_periodic=df_periodic, \n",
    "                                   df_aperiodic=df_a_periodic,\n",
    "                                   lst_ids=lst_pat, \n",
    "                                   vital_name=key, \n",
    "                                   realistic_bounds=values, \n",
    "                                   offset=(0, 1440), \n",
    "                                   agg_total=\"median\", \n",
    "                                   timeunit=30)\n",
    "\n",
    "    lst_clms_vitals_general.append(df_temp)\n",
    "\n",
    "lst_clms_vitals_general_indexed = [df.set_index(\"patientunitstayid\") for df in lst_clms_vitals_general]\n",
    "df_final_vitals_general = pd.concat(lst_clms_vitals_general_indexed, axis=1)\n",
    "\n",
    "df_final_vitals_general = df_final_vitals_general.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c29df917-c08c-4181-adac-c5d8067e4aba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Merge the results dataframe to the growing final dataframe\n",
    "df_pe = df_pe.merge(\n",
    "    right=df_final_vitals_general,\n",
    "    how=\"left\",\n",
    "    on=\"patientunitstayid\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "befed01b-9c08-4dbd-b7cc-03a8f97b1b76",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:33<00:00,  8.48s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:07<00:00,  7.83s/it]\n"
     ]
    }
   ],
   "source": [
    "### \"worst\" vitals for the score calculation\n",
    "# dictionaries of extreme vitals that were excluded as outliers\n",
    "dict_vitals = {\n",
    "    \"heartrate\": [(20, 200), \"max\"],\n",
    "    \"temperature\": [(32, 43), \"min\"],\n",
    "    \"respiration\": [(3, 80), \"max\"],\n",
    "    \"sao2\": [(50, 100), \"min\"]\n",
    "}\n",
    "\n",
    "dict_vitals_combined = {\n",
    "    \"systolic\": [(20, 250), \"min\"]\n",
    "}\n",
    "\n",
    "lst_clms_pesi_vitals = []\n",
    "\n",
    "# for the \"periodic\" vitals\n",
    "for key, values in tqdm(dict_vitals.items()):\n",
    "    realistic = values[0]\n",
    "    direction = values[1]\n",
    "    \n",
    "    clm_name = \"pesi_{}_own\".format(key)\n",
    "    internal_clm_name = \"{}_{}_0to1440_u30\".format(key, direction)\n",
    "    \n",
    "    if key == \"temperature\":\n",
    "        df_temp = fast_vitals_periodic(df_periodic=df_periodic, \n",
    "                                       lst_ids=lst_pat, \n",
    "                                       vital_name=key, \n",
    "                                       realistic_bounds=realistic, \n",
    "                                       offset=(0, 1440), \n",
    "                                       agg_total=direction, \n",
    "                                       timeunit=30, \n",
    "                                       temp_nurse_bool=True, \n",
    "                                       temp_nursechart=df_nurseCharting)\n",
    "            \n",
    "    else:\n",
    "        df_temp = fast_vitals_periodic(df_periodic=df_periodic, \n",
    "                                       lst_ids=lst_pat, \n",
    "                                       vital_name=key, \n",
    "                                       realistic_bounds=realistic, \n",
    "                                       offset=(0, 1440), \n",
    "                                       agg_total=direction, \n",
    "                                       timeunit=30)\n",
    "\n",
    "    df_clm = df_temp.rename(columns={internal_clm_name: clm_name})\n",
    "    lst_clms_pesi_vitals.append(df_clm)\n",
    "\n",
    "# for vital \"systolic\" that uses both the periodic and aperiodic datafiles\n",
    "for key, values in tqdm(dict_vitals_combined.items()):\n",
    "    realistic = values[0]\n",
    "    direction = values[1]\n",
    "\n",
    "    clm_name = \"pesi_{}_own\".format(key)\n",
    "    internal_clm_name = \"{}_{}_0to1440_u30\".format(key, direction)\n",
    "\n",
    "    df_temp = fast_vitals_combined(df_periodic=df_periodic, \n",
    "                                   df_aperiodic=df_a_periodic,\n",
    "                                   lst_ids=lst_pat, \n",
    "                                   vital_name=key, \n",
    "                                   realistic_bounds=realistic, \n",
    "                                   offset=(0, 1440), \n",
    "                                   agg_total=direction, \n",
    "                                   timeunit=30)\n",
    "\n",
    "    df_clm = df_temp.rename(columns={internal_clm_name: clm_name})\n",
    "    lst_clms_pesi_vitals.append(df_clm)\n",
    "\n",
    "lst_clms_pesi_vitals_indexed = [df.set_index(\"patientunitstayid\") for df in lst_clms_pesi_vitals]\n",
    "df_final_vitals_pesi = pd.concat(lst_clms_pesi_vitals_indexed, axis=1)\n",
    "\n",
    "df_final_vitals_pesi = df_final_vitals_pesi.reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0b636f0f-7d9b-4542-8ad4-c8797d96acab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Merge the results dataframe to the growing final dataframe\n",
    "df_pe = df_pe.merge(\n",
    "    right=df_final_vitals_pesi,\n",
    "    how=\"left\",\n",
    "    on=\"patientunitstayid\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c28225f1-70ac-4aa6-a4e5-5d25ccc74bff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# creating a reference dataframe\n",
    "df_pe_ref = df_pe.copy().set_index(\"patientunitstayid\")\n",
    "\n",
    "# Heartrate component (heartrate >= 110/min), the APS midpoint is at 75\n",
    "df_pe[\"PESI_pulse\"] = df_pe[\"patientunitstayid\"].map(\n",
    "    lambda x: map_vitals_from_two_sources(x, df_pe_ref, \"aps_heartrate\", \"pesi_heartrate_own\", 109, 75, \"above\"))\n",
    "\n",
    "# Systolic BP component (systolic BP < 100 mmHg): Only from our own calculations as this is not included in the APS\n",
    "df_pe[\"PESI_systolic\"] = df_pe.pesi_systolic_own.map(lambda x: 1 if x < 100 else 0)\n",
    "\n",
    "# Temperature component (Temp < 36°C), the APS midpoint is 36\n",
    "df_pe[\"PESI_temp\"] = df_pe[\"patientunitstayid\"].map(\n",
    "    lambda x: map_vitals_from_two_sources(x, df_pe_ref, \"aps_temperature\", \"pesi_temperature_own\", 36, 38, \"below\"))\n",
    "\n",
    "# Respiratory rate component (RR >= 30/min), the APS midpoint is 19 \n",
    "df_pe[\"PESI_resp\"] = df_pe[\"patientunitstayid\"].map(\n",
    "    lambda x: map_vitals_from_two_sources(x, df_pe_ref, \"aps_respiratoryrate\", \"pesi_respiration_own\", 29, 19, \"above\"))\n",
    "\n",
    "# SpO2 component (SpO2 < 90%): Only from our own calculations as this is not included in the APS\n",
    "df_pe[\"PESI_o2\"] = df_pe.pesi_sao2_own.map(lambda x: 1 if x < 90 else 0)\n",
    "\n",
    "# setting any missing values in the vitals to 0, in line with the derivation/validation study of the PESI (Aujesky et al. (2005)) \n",
    "df_pe.PESI_pulse = df_pe.PESI_pulse.fillna(value=0)\n",
    "df_pe.PESI_systolic = df_pe.PESI_systolic.fillna(value=0)\n",
    "df_pe.PESI_temp = df_pe.PESI_temp.fillna(value=0)\n",
    "df_pe.PESI_resp = df_pe.PESI_resp.fillna(value=0)\n",
    "df_pe.PESI_o2 = df_pe.PESI_o2.fillna(value=0)\n",
    "\n",
    "# for the sPESI\n",
    "df_pe[\"sPESI_systolic\"] = df_pe[\"PESI_systolic\"]\n",
    "df_pe[\"sPESI_pulse\"] = df_pe[\"PESI_pulse\"]\n",
    "df_pe[\"sPESI_o2\"] = df_pe[\"PESI_o2\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9783d0bd-0687-4a18-8cc4-ad415fc4999d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Data for the sensitivity analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c2cdacff-978c-4d78-a8c4-15aeb8c08dae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_physical = pd.read_csv(\"PE_data/physicalExam_PE.csv\", low_memory=False)\n",
    "df_nurse_chart = pd.read_csv(\"PE_data/nurseCharting_PE.csv\", low_memory=False)\n",
    "df_resp_chart = pd.read_csv(\"PE_data/respiratoryCharting_PE.csv\", low_memory=False)\n",
    "df_resp_care = pd.read_csv(\"PE_data/respiratoryCare_PE.csv\", low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "370eef72-0c0a-4df0-a272-489bbfd58d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# time intervals for the sensitivity analysis\n",
    "lst_time_intervals_h_from_admission = [2, 3, 6, 12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0b1c1e3e-9d38-4501-8934-f74094f8852d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use/need for vasopressor/inotrope infusion in the different time intervals\n",
    "lst_columns_infusion = []\n",
    "\n",
    "# use the function with relative start times for the shorter time-intervals \n",
    "for i in lst_time_intervals_h_from_admission:\n",
    "    minutes = i*60\n",
    "\n",
    "    df_temp = get_infusion_drugs_relative_interval_from_start(df_infusion=df_infusions, \n",
    "                                                              lst_ids=lst_pat, \n",
    "                                                              overall_timeframe=(0, 1440), \n",
    "                                                              time_interval=minutes)\n",
    "\n",
    "    \n",
    "    df_temp = df_temp.rename(columns={\"infusion_vaso_ino\": f\"infusion_vaso_ino_{i}h\"})\n",
    "    \n",
    "    lst_columns_infusion.append(df_temp[f\"infusion_vaso_ino_{i}h\"])\n",
    "\n",
    "df_inf_sens_analysis = (pd.concat(lst_columns_infusion, axis=1)).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "db8f2eda-53e3-4101-9065-5d417a90ccfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the results dataframe to the growing final dataframe\n",
    "df_pe = df_pe.merge(\n",
    "    right=df_inf_sens_analysis,\n",
    "    how=\"left\",\n",
    "    on=\"patientunitstayid\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c6ed14f6-04f6-4744-97ac-40f1623572e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# AMS in the different time intervals (accessing the raw data on GCS values)\n",
    "lst_clms_ams = []\n",
    "\n",
    "# for the shorter time-intervals, extract this from boht the physicalExam and nurseCharting dataframes\n",
    "for i in lst_time_intervals_h_from_admission:\n",
    "    minutes = i*60\n",
    "    \n",
    "    df_temp = get_AMS_from_start_relative(df_physical=df_physical, \n",
    "                                          df_nurse_chart=df_nurse_chart, \n",
    "                                          lst_ids=lst_pat, \n",
    "                                          time_interval=minutes,\n",
    "                                          overall_offset=(0, 1440))\n",
    "    \n",
    "    df_temp = df_temp.set_index(\"patientunitstayid\")\n",
    "    df_temp = df_temp.rename(columns={f\"ams_first_{minutes}_min\": f\"ams_{i}h\"})\n",
    "\n",
    "    lst_clms_ams.append(df_temp[f\"ams_{i}h\"])\n",
    "\n",
    "df_ams_results = (pd.concat(lst_clms_ams, axis=1)).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ab71b068-8329-418f-9fa7-ebf60313680a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Merge the results dataframe to the growing final dataframe\n",
    "df_pe = df_pe.merge(\n",
    "    right=df_ams_results,\n",
    "    how=\"left\",\n",
    "    on=\"patientunitstayid\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "47b842f8-bdb6-472d-b549-1e4d5fb50d9d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Intubation in the different time intervals. Unfortunately, aside from the variable oobintubday1, the raw data regarding intubation itself is very sparse.\n",
    "# Thus, we looked for patients that were mechanically ventilated during that time and were intubated in the larger timeframe (oobintubday1).\n",
    "df_intub_24h = df_pe[[\"ICU_sPESI_intubation\", \"patientunitstayid\"]].copy().set_index(\"patientunitstayid\") \n",
    "\n",
    "lst_clms_intub = []\n",
    "\n",
    "for i in lst_time_intervals_h_from_admission:\n",
    "    minutes = i*60\n",
    "    \n",
    "    df_temp = get_mechanically_ventilated_from_start_relative(df_resp_chart=df_resp_chart, \n",
    "                                                              df_resp_care=df_resp_care, \n",
    "                                                              df_physical=df_physical, \n",
    "                                                              df_nurse_chart=df_nurse_chart, \n",
    "                                                              lst_ids=lst_pat,\n",
    "                                                              time_interval=minutes, \n",
    "                                                              overall_offset=(0, 1440))\n",
    "    \n",
    "    df_temp = df_temp.set_index(\"patientunitstayid\")\n",
    "    df_intub_combined = pd.concat([df_intub_24h, df_temp], axis=1)\n",
    "    df_intub_combined[f\"intubation_{i}h\"] = df_intub_combined.apply(lambda x: 1 if (x.ICU_sPESI_intubation == 1 and x[f\"mech_vent_first_{minutes}_min\"] == 1) else 0, axis=1).astype(int)\n",
    "\n",
    "    lst_clms_intub.append(df_intub_combined[f\"intubation_{i}h\"])\n",
    "\n",
    "df_intub_results = (pd.concat(lst_clms_intub, axis=1)).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "52c41336-69a7-43da-9bde-3a136589702b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the results dataframe to the growing final dataframe\n",
    "df_pe = df_pe.merge(\n",
    "    right=df_intub_results,\n",
    "    how=\"left\",\n",
    "    on=\"patientunitstayid\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7463a57d-19d6-4d6b-8160-41b2ae6d1eab",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:03<00:00,  1.03it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  1.09it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:05<00:00,  1.33s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.27s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:09<00:00,  2.44s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.33s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:18<00:00,  4.70s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:04<00:00,  4.47s/it]\n"
     ]
    }
   ],
   "source": [
    "# Vitals in the different time intervals (accessing the raw data on GCS values)\n",
    "dict_vitals = {\n",
    "    \"heartrate\": [(20, 200), \"max\"],\n",
    "    \"temperature\": [(32, 43), \"min\"],\n",
    "    \"respiration\": [(3, 80), \"max\"],\n",
    "    \"sao2\": [(50, 100), \"min\"]\n",
    "}\n",
    "\n",
    "dict_vitals_combined = {\n",
    "    \"systolic\": [(20, 250), \"min\"]\n",
    "}\n",
    "\n",
    "lst_clms_vitals_timeframes = []\n",
    "\n",
    "for i in lst_time_intervals_h_from_admission:\n",
    "    minutes = i*60\n",
    "\n",
    "    lst_clms_pesi_vitals = []\n",
    "      \n",
    "    # for the \"periodic\" vitals\n",
    "    for key, values in tqdm(dict_vitals.items()):\n",
    "        realistic = values[0]\n",
    "        direction = values[1]\n",
    "\n",
    "        clm_name = \"PESI_{}_{}h\".format(key, i)\n",
    "        internal_clm_name = \"{}_{}_0to{}_u30\".format(key, direction, minutes)\n",
    "\n",
    "        if key == \"temperature\":\n",
    "            df_temp = fast_vitals_periodic(df_periodic=df_periodic, \n",
    "                                           lst_ids=lst_pat, \n",
    "                                           vital_name=key, \n",
    "                                           realistic_bounds=realistic, \n",
    "                                           offset=(0, minutes), \n",
    "                                           agg_total=direction, \n",
    "                                           timeunit=30, \n",
    "                                           temp_nurse_bool=True, \n",
    "                                           temp_nursechart=df_nurseCharting)\n",
    "\n",
    "        else:\n",
    "            df_temp = fast_vitals_periodic(df_periodic=df_periodic, \n",
    "                                           lst_ids=lst_pat, \n",
    "                                           vital_name=key, \n",
    "                                           realistic_bounds=realistic, \n",
    "                                           offset=(0, minutes), \n",
    "                                           agg_total=direction, \n",
    "                                           timeunit=30)\n",
    "\n",
    "        df_clm = df_temp.rename(columns={internal_clm_name: clm_name})\n",
    "        lst_clms_pesi_vitals.append(df_clm)\n",
    "\n",
    "    # for vital \"systolic\" that uses both the periodic and aperiodic datafiles\n",
    "    for key, values in tqdm(dict_vitals_combined.items()):\n",
    "        realistic = values[0]\n",
    "        direction = values[1]\n",
    "\n",
    "        clm_name = \"PESI_{}_{}h\".format(key, i)\n",
    "        internal_clm_name = \"{}_{}_0to{}_u30\".format(key, direction, minutes)\n",
    "\n",
    "        df_temp = fast_vitals_combined(df_periodic=df_periodic, \n",
    "                                       df_aperiodic=df_a_periodic,\n",
    "                                       lst_ids=lst_pat, \n",
    "                                       vital_name=key, \n",
    "                                       realistic_bounds=realistic, \n",
    "                                       offset=(0, minutes), \n",
    "                                       agg_total=direction, \n",
    "                                       timeunit=30)\n",
    "\n",
    "        df_clm = df_temp.rename(columns={internal_clm_name: clm_name})\n",
    "        lst_clms_pesi_vitals.append(df_clm)\n",
    "\n",
    "    lst_clms_pesi_vitals_indexed = [df.set_index(\"patientunitstayid\") for df in lst_clms_pesi_vitals]\n",
    "    df_final_vitals_pesi = pd.concat(lst_clms_pesi_vitals_indexed, axis=1)\n",
    "    \n",
    "    df_final_vitals_pesi[\"PESI_systolic_{}h\".format(i)] =  df_final_vitals_pesi[\"PESI_systolic_{}h\".format(i)].map(lambda x: 1 if x<100 else 0)\n",
    "    df_final_vitals_pesi[\"PESI_heartrate_{}h\".format(i)] =  df_final_vitals_pesi[\"PESI_heartrate_{}h\".format(i)].map(lambda x: 1 if x>=110 else 0)\n",
    "    df_final_vitals_pesi[\"PESI_temperature_{}h\".format(i)] =  df_final_vitals_pesi[\"PESI_temperature_{}h\".format(i)].map(lambda x: 1 if x<36 else 0)\n",
    "    df_final_vitals_pesi[\"PESI_respiration_{}h\".format(i)] =  df_final_vitals_pesi[\"PESI_respiration_{}h\".format(i)].map(lambda x: 1 if x>=30 else 0)\n",
    "    df_final_vitals_pesi[\"PESI_sao2_{}h\".format(i)] =  df_final_vitals_pesi[\"PESI_sao2_{}h\".format(i)].map(lambda x: 1 if x<90 else 0)\n",
    "\n",
    "    lst_clms_vitals_timeframes.append(df_final_vitals_pesi)\n",
    "    \n",
    "    \n",
    "df_vitals_timeframes_results = (pd.concat(lst_clms_vitals_timeframes, axis=1)).reset_index().fillna(value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "365f3896-80b9-4e3d-9b42-4111419f6d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the results dataframe to the growing final dataframe\n",
    "df_pe = df_pe.merge(\n",
    "    right=df_vitals_timeframes_results,\n",
    "    how=\"left\",\n",
    "    on=\"patientunitstayid\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55cfc8dc-8e70-4d8b-a4ce-9c1e1404686e",
   "metadata": {},
   "source": [
    "## Time-to-death"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9874244f-55db-4fd5-b24c-d1bb9669f3ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ttd_pe = time_to_death_from_unit_admission(df_pat=df_pat, \n",
    "                                              df_apache_res=df_apacheresult, \n",
    "                                              lst_ids=lst_pat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6c05bf40-fd13-44d9-875c-cdf6720d8e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pe = df_pe.merge(\n",
    "    right=df_ttd_pe,\n",
    "    how=\"left\",\n",
    "    on=\"patientunitstayid\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d2bcf69-a1ee-4277-8a8e-b42f5849668d",
   "metadata": {
    "tags": []
   },
   "source": [
    "# PESI score calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "767da9ba-4c26-4a72-b70e-927f93b670f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## PESI score and PESI classes\n",
    "# calculate the PESI score\n",
    "df_pe[\"PESI_score\"] = df_pe.apply(lambda row: row[\"age\"] + row[\"PESI_gender\"]*10 +\n",
    "                                              row[\"PESI_cancer\"]*30 + row[\"PESI_hf\"]*10 +\n",
    "                                              row[\"PESI_pulm\"]*10 + row[\"PESI_pulse\"]*20 +\n",
    "                                              row[\"PESI_systolic\"]*30 + row[\"PESI_resp\"]*20 +\n",
    "                                              row[\"PESI_temp\"]*20 + row[\"PESI_ams\"]*60 +\n",
    "                                              row[\"PESI_o2\"]*20, axis=1)\n",
    "\n",
    "# calculate the PESI classes\n",
    "df_pe[\"PESI_class\"] = np.nan\n",
    "df_pe.loc[df_pe.PESI_score > 125, [\"PESI_class\"]] = 5\n",
    "df_pe.loc[(df_pe.PESI_score >= 106) & (df_pe.PESI_score <= 125), [\"PESI_class\"]] = 4\n",
    "df_pe.loc[(df_pe.PESI_score >= 86) & (df_pe.PESI_score <= 105), [\"PESI_class\"]] = 3\n",
    "df_pe.loc[(df_pe.PESI_score >= 66) & (df_pe.PESI_score <= 85), [\"PESI_class\"]] = 2\n",
    "df_pe.loc[df_pe.PESI_score < 66, [\"PESI_class\"]] = 1\n",
    "\n",
    "# PESI scores of the different time-intervals\n",
    "for i in lst_time_intervals_h_from_admission:\n",
    "    df_pe[f\"PESI_score_{i}h\"] = df_pe.apply(lambda row: row[\"age\"] + row[\"PESI_gender\"]*10 +\n",
    "                                                  row[\"PESI_cancer\"]*30 + row[\"PESI_hf\"]*10 +\n",
    "                                                  row[\"PESI_pulm\"]*10 + row[f\"PESI_heartrate_{i}h\"]*20 +\n",
    "                                                  row[f\"PESI_systolic_{i}h\"]*30 + row[f\"PESI_respiration_{i}h\"]*20 +\n",
    "                                                  row[f\"PESI_temperature_{i}h\"]*20 + row[f\"ams_{i}h\"]*60 +\n",
    "                                                  row[f\"PESI_sao2_{i}h\"]*20, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "413c1863-cf64-49e1-8496-133a966d1bc3",
   "metadata": {
    "tags": []
   },
   "source": [
    "# sPESI score calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9d1fc825-8524-42ea-ace3-801c437bc679",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# calculcation of the sPESI score\n",
    "df_pe[\"sPESI_score\"] = df_pe[\"sPESI_age\"] + df_pe[\"sPESI_cancer\"] + df_pe[\"sPESI_cardiopulm\"] + \\\n",
    "                                df_pe[\"sPESI_pulse\"] + df_pe[\"sPESI_systolic\"] + df_pe[\"sPESI_o2\"]\n",
    "\n",
    "# sPESI scores of the different time-frames\n",
    "for i in lst_time_intervals_h_from_admission:\n",
    "    df_pe[f\"sPESI_score_{i}h\"] = df_pe[\"sPESI_age\"] + df_pe[\"sPESI_cancer\"] + df_pe[\"sPESI_cardiopulm\"] + \\\n",
    "                                df_pe[f\"PESI_heartrate_{i}h\"] + df_pe[f\"PESI_systolic_{i}h\"] + df_pe[f\"PESI_sao2_{i}h\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff32e38d-6e1a-4531-99eb-6da480dd4117",
   "metadata": {},
   "source": [
    "# ICU-sPESI calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "962d1ddd-08e6-479d-8aa4-b61514991daf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# calculation of the ICU-sPESI score\n",
    "df_pe[\"ICU_sPESI_score\"] = df_pe[\"sPESI_score\"] + df_pe[f\"ICU_sPESI_ams\"] + df_pe[f\"ICU_sPESI_infusion_vaso_ino\"] + df_pe[\"ICU_sPESI_intubation\"]\n",
    "\n",
    "# sPESI scores of the different time-frames\n",
    "for i in lst_time_intervals_h_from_admission:\n",
    "    df_pe[f\"ICU_sPESI_score_{i}h\"] = df_pe[f\"sPESI_score_{i}h\"] + df_pe[f\"ams_{i}h\"] + df_pe[f\"infusion_vaso_ino_{i}h\"] + df_pe[f\"intubation_{i}h\"] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa67ee42-3242-4c2d-84e8-bf6e3ad74218",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Patient exclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "cfa49f9b-7aeb-4bc9-92e1-fabee22ba616",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1697, 153)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pe.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23cf14b7-dbe3-421b-97c6-8842b2ebe9b7",
   "metadata": {},
   "source": [
    "&rarr; 1697 patients total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ba40d94d-7a65-4ce5-a38c-8c2cf554e594",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# excluding patients with missing data in the APACHE-IV sore, regarding in-hospital mortality, gender and the GCS verbal component\n",
    "df_pe = df_pe.dropna(subset=[\"gender\", \"apachescore\", \"aps_verbal\", \"hospitaldischargestatus\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7699564d-2624-4b8a-9d39-ba55ea096544",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1427, 153)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pe.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "388c5da2-26d3-4f8b-8736-7133330c7cbb",
   "metadata": {},
   "source": [
    "&rarr; 270 patients excluded due to missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a68f6050-01b9-4aaf-be6a-36776d4d75d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# excluding patients with an age < 18\n",
    "df_pe = df_pe[df_pe['age'] >= 18].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "9ea9e4c5-fa1d-4c96-8459-d1ae8bbde1f0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1424, 153)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pe.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d89987-4daa-4400-8081-a7bf0151c702",
   "metadata": {},
   "source": [
    "&rarr; 3 patients excluded due to age < 18 years old"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c11bbc49-c148-4c5f-ae17-fd349bcbe68d",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Further data processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "411d220e-499f-4e5a-9cb5-f4d40fa0e65e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "bda0d28f-d2c5-4828-a63f-080cca52f4d8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_dict_for_categorical_with_0(df, column, printoption=False):\n",
    "    \"\"\"\n",
    "    Takes a column from a dataframe and forms a simple 1 to n categorical dictionary from the value counts.\n",
    "\n",
    "    :param df: Dataframe\n",
    "    :param column: String - column name\n",
    "    :param printoption: Boolean - whether to print the actual dictionary with value counts\n",
    "    :return: Dictionary\n",
    "    \"\"\"\n",
    "\n",
    "    df_val_counts = pd.DataFrame((df[column].value_counts())).reset_index()\n",
    "    df_val_counts.columns = ['unique_values', 'counts']\n",
    "    df_val_counts_2 = df_val_counts[df_val_counts.unique_values != 0].copy()\n",
    "    df_val_counts_2.index = np.arange(1, len(df_val_counts_2) + 1)\n",
    "\n",
    "    dict_to_cat = dict(zip(df_val_counts_2[\"unique_values\"], df_val_counts_2.index))\n",
    "    dict_to_cat[0] = 0\n",
    "\n",
    "    if printoption == True:\n",
    "        print(dict_to_cat)\n",
    "\n",
    "    return dict_to_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c7266fe0-17c5-4dec-8f7b-bf68846dc0e1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def map_pmh_cancer(x):\n",
    "    \"\"\" mapping the raw cancer string data to cancer sites and then cancer groups \"\"\"\n",
    "    # if the patient does not have cancer\n",
    "    if x == 0:\n",
    "        return 0\n",
    "    \n",
    "    # extract the specific cancer site\n",
    "    if \"Cancer-Primary Site/\" in x:\n",
    "        lst_pmh_cancer = x.split(\"|\")\n",
    "        lst_site = [i for i in lst_pmh_cancer if \"Cancer-Primary Site/\" in i]\n",
    "\n",
    "        if len(lst_site) > 1:\n",
    "            cancer_site = \"multiple\"\n",
    "\n",
    "        else:\n",
    "            site_description = lst_site[0]\n",
    "            lst_final = site_description.split(\"/\")\n",
    "            cancer_site = lst_final[1]\n",
    "\n",
    "    else:\n",
    "        cancer_site = \"other\"\n",
    "    \n",
    "    # group the cancer based on cancer site\n",
    "    # the keys of the dictionary represent all unique values for this column for this cohort\n",
    "    dict_cancer_sites = {\n",
    "        0: \"No_cancer\",\n",
    "        'other': \"other\",\n",
    "        'breast': \"Breast\",\n",
    "        'lung': \"Respiratory\",\n",
    "        'colon': \"GI\",\n",
    "        'prostate': \"Genitourinary\",\n",
    "        'uterus': \"Genitourinary\",\n",
    "        'bladder': \"Genitourinary\",\n",
    "        'pancreas - adenocarcinoma': \"GI\",\n",
    "        'melanoma': \"other\",\n",
    "        'brain': \"other\",\n",
    "        'kidney': \"Genitourinary\",\n",
    "        'ovary': \"Genitourinary\",\n",
    "        'esophagus': \"GI\",\n",
    "        'bile duct': \"GI\",\n",
    "        'liver': \"GI\",\n",
    "        'multiple': \"other\",\n",
    "        'bone': \"other\",\n",
    "        'head and neck': \"other\",\n",
    "        'sarcoma': \"other\",\n",
    "        'unknown': \"other\",\n",
    "        'testes': \"Genitourinary\",\n",
    "        'stomach': \"GI\"\n",
    "    }\n",
    "    \n",
    "    cancer_group = dict_cancer_sites[cancer_site]\n",
    "\n",
    "    return cancer_group"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce119ca3-5ede-4641-99d6-9a7283547863",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6f16c652-9f53-472f-b274-12d69e90bcdf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_pe.gender = df_pe.gender.map({\"Female\":0, \"Male\":1})\n",
    "df_pe = df_pe.rename(columns={\"pmh_hemolytic _anemia\": \"pmh_hemolytic_anemia\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d351f188-adb7-4b91-89c1-800f89c60580",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Binarize certain PMH columns\n",
    "lst_clms_binary = [\"pmh_HT_with_treatment\", \"pmh_MI\", \"pmh_angina\", \"pmh_strokes\", \"pmh_periph_vasc_disease\", \"pmh_CA_bypass\",\n",
    "                  \"pmh_PCI\", \"pmh_pacemaker\", \"pmh_AICD\", \"pmh_venous_thrombosis\", \"pmh_asthma\", \"pmh_hemolytic_anemia\",\n",
    "                  \"pmh_aplastic_anemia\", \"pmh_clotting_disorder\", \"pmh_hypercoagulable_condition\", \"pmh_hypothyroidism\", \"pmh_hyperthyroidism\", \n",
    "                  \"pmh_CHF\", \"pmh_restrictive_lung_disease\", \"pmh_card_valvular\", 'pmh_home_o2', 'pmh_seizures', 'pmh_dementia', 'pmh_neuromusk_disease',\n",
    "                  'pmh_intracranial_mass', 'pmh_sickle_cells', 'pmh_liver_cirrhosis', 'pmh_ITP']\n",
    "\n",
    "for i in lst_clms_binary:\n",
    "    df_pe.loc[(df_pe[i] != 0) & (df_pe[i].notna()), i] = 1\n",
    "    \n",
    "    \n",
    "dict_clms_to_binary = {\n",
    "    \"pmh_cancer\": \"pmh_cancer_binary\",\n",
    "    \"pmh_insulin_dep_DM\" : \"pmh_diabetes_binary\",\n",
    "    \"pmh_COPD\": \"pmh_COPD_binary\",\n",
    "    \"pmh_arrhythmias\": \"pmh_arrhythmias_binary\",\n",
    "    \"pmh_renal_insuff\": \"pmh_renal_insuff_binary\",\n",
    "    \"pmh_renal_failure\": \"pmh_renal_failure_binary\"   \n",
    "}\n",
    "\n",
    "for orig_clm, new_clm in dict_clms_to_binary.items():\n",
    "    df_pe[new_clm] = df_pe[orig_clm].map(lambda x: 1 if (x!=0 and x!=np.nan) else 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "32bf9c23-9d23-4da2-83ac-6d15263ae166",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# group the cancer column depending on the site of the cancer (for details see function above)\n",
    "df_pe[\"pmh_cancer_grouped\"] = df_pe[\"pmh_cancer\"].map(lambda x: map_pmh_cancer(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "899e2c4e-6cc2-4987-9a65-2c02e5464671",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# grouping the diabetes column depending on the type of diabetes (insulin dependent, only medication dependent and without any medication)\n",
    "def map_pmh_diabetes(x):\n",
    "    \"\"\" process the raw string data of the pmh_insulin_dep_DM column \"\"\"\n",
    "    if x == 0:\n",
    "        return 0\n",
    "\n",
    "    if \"non-medication\" in x:\n",
    "        return \"dm_without_treatment\"\n",
    "\n",
    "    if x == \"medication dependent\":\n",
    "        return \"medication_only\"\n",
    "\n",
    "    if \"insulin\" in x:\n",
    "        return \"including_Insulin\"\n",
    "\n",
    "df_pe[\"pmh_diabetes\"] = df_pe[\"pmh_insulin_dep_DM\"].map(lambda x: map_pmh_diabetes(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "fbbaec28-8513-4b01-b503-5fbf4ea44938",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# grouping the COPD column depending on the severity of the COPD\n",
    "# the keys of the dictionary represent all unique values for this column for this cohort\n",
    "dict_pmhCOPD = {\n",
    "    0: 0,\n",
    "    \"COPD  - moderate\": \"COPD_moderate\",\n",
    "    \"COPD  - no limitations\": \"COPD_mild\",\n",
    "    \"COPD  - severe\": \"COPD_severe\",\n",
    "    \"COPD  - moderate|COPD  - severe\": \"COPD_severe\"\n",
    "}\n",
    "\n",
    "df_pe[\"pmh_COPD\"] = df_pe[\"pmh_COPD\"].map(dict_pmhCOPD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f14c7e6a-903d-49d2-9af8-b1f76be6ac0c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# grouping the cardiac arrythmias column depending on whether the recorded arrythmias included atrial fibrillation or not\n",
    "def map_pmh_arrhythmias(x):\n",
    "    if x == 0:\n",
    "        return 0\n",
    "\n",
    "    if \"atrial fibrillation\" in x:\n",
    "        return \"Afib_orwith\"\n",
    "\n",
    "    else:\n",
    "        return \"other_arrhythmia\"\n",
    "\n",
    "\n",
    "df_pe[\"pmh_arrhythmias\"] = df_pe[\"pmh_arrhythmias\"].map(lambda x: map_pmh_arrhythmias(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "92437fe9-1dae-44fc-ad32-fc2e89da2406",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# grouping the COPD column depending on whether the patients were on dialysis or not\n",
    "# the keys of the dictionary represent all unique values for this column for this cohort\n",
    "dict_renal_failure = {\n",
    "    0: 0,\n",
    "    \"renal failure - hemodialysis\": \"renal_fail_w_dialysis\",\n",
    "    \"renal failure- not currently dialyzed\": \"renal_fail_no_dialysis\",\n",
    "    \"renal failure - peritoneal dialysis\": \"renal_fail_w_dialysis\"\n",
    "}\n",
    "\n",
    "df_pe[\"pmh_renal_failure\"] = df_pe[\"pmh_renal_failure\"].map(dict_renal_failure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "2a4ebd1f-22c7-4cf7-b3da-0e832546d689",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# grouping the previous PE column depending on whether it was a single or multiple previous PE\n",
    "def map_pmh_PE(x):\n",
    "    if x == 0:\n",
    "        return 0\n",
    "\n",
    "    if \"multiple\" in x:\n",
    "        return \"multiple_PE\"\n",
    "\n",
    "    else:\n",
    "        return \"single_PE\"\n",
    "\n",
    "df_pe[\"pmh_PE\"] = df_pe[\"pmh_PE\"].map(lambda x: map_pmh_PE(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "6daab515-4425-4683-a24a-8b644753f37b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### grouping other comorbidities\n",
    "# Coronary artery disease and other large vessel disease: myocardial infarction, angina, strokes, peripheral vascular disease, \n",
    "# coronary artery bypass, percutaneous coronary intervention\n",
    "df_pe[\"pmh_CAD_and_other_large_vessel\"] = df_pe.apply(lambda x: 1 if x.pmh_MI == 1 or x.pmh_angina == 1 or x.pmh_strokes == 1 or x.pmh_periph_vasc_disease == 1 \n",
    "                                                      or x.pmh_CA_bypass == 1 or x.pmh_PCI == 1 else 0, axis=1)\n",
    "\n",
    "# pacemaker: either a normal pacemaker or an AICD\n",
    "df_pe[\"pmh_any_pacemaker\"] = df_pe.apply(lambda x: 1 if x.pmh_pacemaker == 1 or x.pmh_AICD == 1 else 0, axis=1)\n",
    "\n",
    "# Venous thomboses & PE\n",
    "df_pe[\"pmh_venous_thromb_and_PE\"] = df_pe.apply(lambda x: 1 if x.pmh_venous_thrombosis == 1 or (x.pmh_PE!=0 and x.pmh_PE!=np.nan) else 0, axis=1)\n",
    "\n",
    "# obstructive lung disease: COPD and asthma\n",
    "df_pe[\"pmh_obstructive_LD\"] = df_pe.apply(lambda x: 1 if (x.pmh_COPD!=0 and x.pmh_COPD!=np.nan) or x.pmh_asthma == 1 else 0, axis=1)\n",
    "\n",
    "# anemias\n",
    "df_pe[\"pmh_anemias\"] = df_pe.apply(lambda x: 1 if x.pmh_hemolytic_anemia == 1 or x.pmh_aplastic_anemia == 1 else 0, axis=1)\n",
    "\n",
    "# thyroid diseases (bother hyper- and hpoythyroidism)\n",
    "df_pe[\"pmh_thyroid_disease\"] = df_pe.apply(lambda x: 1 if x.pmh_hypothyroidism == 1 or x.pmh_hyperthyroidism == 1 else 0, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "6546895c-c41c-4cd3-8855-21a48f9f459e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating age categories for a better overview over the distribution of that variable\n",
    "def get_age_cat_for_table(x):\n",
    "    if x>=81: return \">80\"\n",
    "    if x>=71: return \"71-80\"\n",
    "    if x>=61: return \"61-70\"\n",
    "    else: return \"<60\"\n",
    "\n",
    "df_pe[\"age_categories\"] = df_pe.age.map(lambda x: get_age_cat_for_table(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d8f066-8025-4ae3-ba07-10dfd2ac0318",
   "metadata": {},
   "source": [
    "# Export \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b3585cae-5c31-4ef0-85b6-289f4ea13bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pe.to_excel(\"PE_data/PE_DATA_FINAL.xlsx\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
