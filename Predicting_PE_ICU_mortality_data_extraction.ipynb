{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb9188d1-f5fb-4ecc-b4b9-4d051b4df8b9",
   "metadata": {},
   "source": [
    "Import the necessary python modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d778e988-f696-43d3-8a70-1bfff0df65d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import the necessary python modules\n",
    "import pandas as pd # v.1.4.3\n",
    "import numpy as np # v.1.23.0\n",
    "\n",
    "from tqdm import tqdm # v.4.65.0\n",
    "\n",
    "import math # python v.3.9.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f298ef84-7a6e-4940-8fce-cb942241f19f",
   "metadata": {},
   "source": [
    "# Cohort selection\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c56fbd63-07cf-4589-bda5-8be0f712e0b5",
   "metadata": {},
   "source": [
    "Selecting all ICU-stays that had Pulmonary Embolism (PE) as their main (APACHE) admission diagnosis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d051869f-2291-4421-a537-e4a9a22a260e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_pat_big = pd.read_csv(\"../../eICU_data/patient.csv\", low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86a2853a-eb67-458e-9d4a-283d149f5353",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Embolus, pulmonary']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i for i in df_pat_big.apacheadmissiondx.value_counts().index.to_numpy() if \"Embolus\" in i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d110f35-612a-4d7d-b184-9b169b7e4d88",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1697"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pat_big_pe = df_pat_big[df_pat_big.apacheadmissiondx == \"Embolus, pulmonary\"].copy()\n",
    "lst_pat = df_pat_big_pe.patientunitstayid.to_list()\n",
    "len(lst_pat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b10fe268-566c-4103-9f5b-82850a3379bc",
   "metadata": {},
   "source": [
    "&rarr; 1697 ICU-admissions with a primary diagnosis of PE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f3f56ce-3a8a-4e66-8d52-ae75c0fc688d",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Reducing the file-size\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc140fd5-5809-4e9c-885d-ff42d718fa35",
   "metadata": {},
   "source": [
    "As the original file sizes are quite large, we take a copy of all files with just the information of our PE patients. This will speed up data extraction/calculations down the line"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7de48f7-2677-4999-9c8e-742e49cdb04b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf9196cb-ab61-467f-9a4b-5c047b538fa5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_reduced_files(import_path, export_path, notation, lst_ids):\n",
    "    \"\"\"\n",
    "    Takes an import path (folder where all the eICU files are), an export path, a \"notation\" (will be added behind the file name as an identifier) and a list of ids, and then returns the reduced\n",
    "    files of eICU for only that population (except for the hospital table).\n",
    "\n",
    "    :param import_path: String - Folder where all the eICU data is stored.\n",
    "    \n",
    "    :param export_path: String - Should only include the folder, not the filename, and should end with \"/\".\n",
    "\n",
    "    :param notation: String - Short notation that will be added to each file name for future identification.\n",
    "\n",
    "    :param lst_ids: List - List of target population patientunitstayids.\n",
    "\n",
    "    :return: Saves a list of abbreviated dataframes to the specified export_path.\n",
    "    \"\"\"\n",
    "\n",
    "    # List of all tables in the eICU database, except the hospital table as it is not connected to patientunitstayid\n",
    "    lst_tables = [\"admissionDrug\", \"admissionDx\", \"allergy\", \"apacheApsVar\", \"apachePatientResult\", \"apachePredVar\",\n",
    "                  \"carePlanCareProvider\", \"carePlanEOL\", \"carePlanGeneral\", \"carePlanGoal\", \"carePlanInfectiousDisease\", \"customLab\",\n",
    "                  \"diagnosis\", \"infusionDrug\", \"intakeOutput\", \"lab\", \"medication\", \"microLab\", \"note\",\n",
    "                  \"nurseAssessment\", \"nurseCare\", \"nurseCharting\", \"pastHistory\", \"patient\", \"physicalExam\",\n",
    "                  \"respiratoryCare\", \"respiratoryCharting\", \"treatment\", \"vitalAperiodic\", \"vitalPeriodic\"]\n",
    "\n",
    "    # Looping over all tables, selecting only the data pertaining to the cohort of interest and then saving these files in a specified location\n",
    "    for table in tqdm(lst_tables):\n",
    "        df_chunk = pd.read_csv(f\"{import_path}{table}.csv\", chunksize=100000, low_memory=False)\n",
    "        lst_dataframes = []\n",
    "        \n",
    "        for chunk in df_chunk:\n",
    "            df_temp = chunk[chunk[\"patientunitstayid\"].isin(lst_ids)]\n",
    "            lst_dataframes.append(df_temp)\n",
    "\n",
    "        df_small = pd.concat(lst_dataframes)\n",
    "        df_small.to_csv(f\"{export_path}{table}_{notation}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1e141f2-290b-472f-9dc6-390337c073fc",
   "metadata": {},
   "source": [
    "## Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "137dfe06-71f2-4c62-ba82-148592ae0cdd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#make_reduced_files(\n",
    "#    import_path = \"../../eICU_data/\",\n",
    "#    export_path = \"PE_data/\",\n",
    "#    notation = \"PE\",\n",
    "#    lst_ids = lst_pat\n",
    "#)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be1b0c0-1841-4444-9d7c-b395eb77a668",
   "metadata": {},
   "source": [
    "To make this code work in your environment, the complete unpacked eICU data has to be located at the relative path \"../../eICU_data/\" in your project.\n",
    "\n",
    "Now all of the data for our PE patients is in the folder at the relative path \"PE_data/\" and can be accessed from there.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f6be55-6c20-43e1-ba12-9dbc4684b75d",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Data extraction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee79231-a1c5-4ca0-a4df-f870cc261579",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e00639b9-9aab-404e-9ad3-83757e72c574",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_basic_patient_info(df_pat, lst_ids):\n",
    "    \"\"\"\n",
    "    Takes the patient dataframe of the eICU database, a list of target patientunitstayids and\n",
    "    returns a dataframe with \"cleaned\" info per patientunitstayid.\n",
    "\n",
    "    :param df_pat: DataFrame - Patient dataframe of eICU (or abbreviated). \n",
    "\n",
    "    :param lst_ids: List - List of the population patientunitstayids.\n",
    "\n",
    "    :return: DataFrame with the information.\n",
    "    \"\"\"\n",
    "\n",
    "    lst_columns = [\"patientunitstayid\", \"uniquepid\", \"gender\", \"age\", \"ethnicity\", \"hospitalid\", \"wardid\",\n",
    "                   \"unittype\", \"apacheadmissiondx\", \"admissionheight\", \"admissionweight\", \"hospitaldischargestatus\",\n",
    "                   'hospitaladmittime24', \"hospitaladmitsource\", \"hospitaldischargelocation\", 'unitadmittime24',\n",
    "                   'unitadmitsource', 'unitstaytype', 'dischargeweight', 'unitdischargelocation', 'unitdischargestatus', \"unitvisitnumber\"]\n",
    "\n",
    "    # reducing the general pat_df to reduce the computational load\n",
    "    df_temp = df_pat.loc[df_pat[\"patientunitstayid\"].isin(lst_ids), lst_columns].copy()\n",
    "\n",
    "    # gender column\n",
    "    df_temp[\"gender\"] = df_temp[\"gender\"].replace({\"Unknown\": np.nan, \"Other\": np.nan})\n",
    "\n",
    "    # age column\n",
    "    df_temp[\"age\"] = df_temp[\"age\"].replace(\"> 89\", \"90\")\n",
    "    df_temp[\"age\"] = pd.to_numeric(df_temp[\"age\"])\n",
    "\n",
    "    # weight columns\n",
    "    df_temp.loc[(df_temp.admissionweight <= 20) | (df_temp.admissionweight >= 300), [\"admissionweight\"]] = np.nan\n",
    "    df_temp.loc[(df_temp.dischargeweight <= 20) | (df_temp.dischargeweight >= 300), [\"dischargeweight\"]] = np.nan\n",
    "\n",
    "    # admissionheight\n",
    "    df_temp.loc[(df_temp.admissionheight < 100) | (df_temp.admissionheight > 210), [\"admissionheight\"]] = np.nan\n",
    "    \n",
    "    # creating the BMI column\n",
    "    df_temp[\"BMI\"] = df_temp[\"admissionweight\"] / (df_temp[\"admissionheight\"] / 100) ** 2\n",
    "    df_temp.loc[(df_temp.BMI > 100) | (df_temp.BMI < 12), \"BMI\"] = np.nan\n",
    "    \n",
    "    df_final = df_temp[[\"patientunitstayid\", \"gender\", \"age\", \"ethnicity\", \"BMI\", \"hospitaldischargestatus\", \"unitdischargestatus\"]].copy()\n",
    "\n",
    "    return df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5870491b-9de9-4cb2-953f-32ccc7478a6a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def apply_group_pmh_subcat(x, df, clm_name):\n",
    "    df_one_id = df.loc[(df.patientunitstayid == x), [clm_name]]\n",
    "    lst_diagnoses = df_one_id[clm_name].unique().tolist()\n",
    "    final_string = \"|\".join(lst_diagnoses)\n",
    "    return final_string\n",
    "\n",
    "def apply_split_and_rejoin_for_output(str_pmh):\n",
    "    lst_strings = str_pmh.split(\"/\")\n",
    "    lst_final = lst_strings[6:]\n",
    "\n",
    "    if len(lst_final) == 1:\n",
    "        return lst_final[0]\n",
    "\n",
    "    if len(lst_final) > 1:\n",
    "        joined = \"/\".join(lst_final)\n",
    "        return joined\n",
    "\n",
    "def get_pastHistory(df_pmh, lst_ids):\n",
    "    \"\"\"\n",
    "    Receives the pastHistory Dataframe from eICU or abbreviated and a list of target patientunitstayids and returns\n",
    "    a kind of longformat dataframe with the most important categories/PMH.\n",
    "\n",
    "    :param df_pmh: DataFrame - pastHistory dataframe from eICU. \n",
    "\n",
    "    :param lst_ids: List - list of patientunitstayids from the target population.\n",
    "\n",
    "    :return: DataFrame with patientunitstayids as the index and columns for each category of PMH\n",
    "    \"\"\"\n",
    "    \n",
    "    # Dictionary of prospective column names (key) and the string keys to the PMH-string-path of each disease (values)\n",
    "    dict_subcat_clms = {\n",
    "        'pmh_HT_with_treatment': ['notes/Progress Notes/Past History/Organ Systems/Cardiovascular', 'Hypertension Requiring Treatment'],\n",
    "        'pmh_cancer': ['notes/Progress Notes/Past History/Organ Systems/Hematology-Oncology', 'Cancer'],\n",
    "        'pmh_non_insulin_dep_DM': ['notes/Progress Notes/Past History/Organ Systems/Endocrine', 'Non-Insulin Dependent Diabetes'],\n",
    "        'pmh_COPD': ['notes/Progress Notes/Past History/Organ Systems/Pulmonary', 'COPD'],\n",
    "        'pmh_CHF': ['notes/Progress Notes/Past History/Organ Systems/Cardiovascular', 'Congestive Heart Failure'],\n",
    "        'pmh_insulin_dep_DM': ['notes/Progress Notes/Past History/Organ Systems/Endocrine', 'Insulin Dependent Diabetes'],\n",
    "        'pmh_arrhythmias': ['notes/Progress Notes/Past History/Organ Systems/Cardiovascular', 'Arrhythmias'],\n",
    "        'pmh_hypothyroidism': ['notes/Progress Notes/Past History/Organ Systems/Endocrine', 'Hypothyroidism'],\n",
    "        'pmh_MI': ['notes/Progress Notes/Past History/Organ Systems/Cardiovascular', 'Myocardial Infarction'],\n",
    "        'pmh_strokes': ['notes/Progress Notes/Past History/Organ Systems/Neurologic', 'Strokes'],\n",
    "        'pmh_renal_insuff': ['notes/Progress Notes/Past History/Organ Systems/Renal', 'Renal Insufficiency'],\n",
    "        'pmh_PCI': ['notes/Progress Notes/Past History/Organ Systems/Cardiovascular', 'Procedural Coronary Intervention'],\n",
    "        'pmh_card_valvular': ['notes/Progress Notes/Past History/Organ Systems/Cardiovascular', 'Valve disease'],\n",
    "        'pmh_asthma': ['notes/Progress Notes/Past History/Organ Systems/Pulmonary', 'Asthma'],\n",
    "        'pmh_liver_cirrhosis': ['notes/Progress Notes/Past History/Organ Systems/Gastrointestinal', 'Cirrhosis'],\n",
    "        'pmh_renal_failure': ['notes/Progress Notes/Past History/Organ Systems/Renal', 'Renal Failure'],\n",
    "        'pmh_CA_bypass': ['notes/Progress Notes/Past History/Organ Systems/Cardiovascular', 'Coronary Artery Bypass'],\n",
    "        'pmh_seizures': ['notes/Progress Notes/Past History/Organ Systems/Neurologic', 'Seizures'],\n",
    "        'pmh_periph_vasc_disease': ['notes/Progress Notes/Past History/Organ Systems/Cardiovascular', 'Peripheral Vascular Disease'],\n",
    "        'pmh_home_o2': ['notes/Progress Notes/Past History/Organ Systems/Pulmonary', 'Home Oxygen'],\n",
    "        'pmh_venous_thrombosis': ['notes/Progress Notes/Past History/Organ Systems/Cardiovascular', 'Venous Thrombosis'],\n",
    "        'pmh_dementia': ['notes/Progress Notes/Past History/Organ Systems/Neurologic', 'Dementia'],\n",
    "        'pmh_pacemaker': ['notes/Progress Notes/Past History/Organ Systems/Cardiovascular', 'Pacemaker'],\n",
    "        'pmh_cancer_therapy': ['notes/Progress Notes/Past History/Organ Systems/Hematology-Oncology', 'Cancer Therapy'],\n",
    "        'pmh_angina': ['notes/Progress Notes/Past History/Organ Systems/Cardiovascular', 'Angina'],\n",
    "        'pmh_peptic_ulcer_disease': ['notes/Progress Notes/Past History/Organ Systems/Gastrointestinal', 'Peptic Ulcer Disease'],\n",
    "        'pmh_TIAs': ['notes/Progress Notes/Past History/Organ Systems/Neurologic', 'TIAs'],\n",
    "        'pmh_PFTs': ['notes/Progress Notes/Past History/Organ Systems/Pulmonary', 'Pulmonary Function Tests'],\n",
    "        'pmh_resp_failure': ['notes/Progress Notes/Past History/Organ Systems/Pulmonary', 'Respiratory Failure'],\n",
    "        'pmh_AICD': ['notes/Progress Notes/Past History/Organ Systems/Cardiovascular', 'AICD'],\n",
    "        'pmh_PE': ['notes/Progress Notes/Past History/Organ Systems/Cardiovascular', 'Pulmonary Embolism'],\n",
    "        'pmh_RA': ['notes/Progress Notes/Past History/Organ Systems/Rheumatic', 'Rheumatoid Arthritis'],\n",
    "        'pmh_mmunosuppression_last_6m': ['notes/Progress Notes/Past History/Organ Systems/Infectious Disease', 'Immunosuppression within past 6 months'],\n",
    "        'pmh_chronic_kidney_stones': ['notes/Progress Notes/Past History/Organ Systems/Renal', 'Chronic Stone Disease'],\n",
    "        'pmh_neuromusk_disease': ['notes/Progress Notes/Past History/Organ Systems/Neurologic', 'Neuromuscular Disease'],\n",
    "        'pmh_restrictive_lung_disease': ['notes/Progress Notes/Past History/Organ Systems/Pulmonary', 'Restrictive Disease'],\n",
    "        'pmh_s_p_NTx': ['notes/Progress Notes/Past History/Organ Systems/Renal', 's_p Renal Transplant'],\n",
    "        'pmh_HIV_only': ['notes/Progress Notes/Past History/Organ Systems/Infectious Disease', 'HIV only'],\n",
    "        'pmh_hemolytic _anemia': ['notes/Progress Notes/Past History/Organ Systems/Hematology-Oncology', 'Hemolytic Anemia'],\n",
    "        'pmh_SLE': ['notes/Progress Notes/Past History/Organ Systems/Rheumatic', 'SLE'],\n",
    "        'pmh_exercise_tolerance': ['notes/Progress Notes/Past History/Organ Systems/Cardiovascular', 'Exercise Tolerance'],\n",
    "        'pmh_intracranial_mass': ['notes/Progress Notes/Past History/Organ Systems/Neurologic', 'Intracranial Mass'],\n",
    "        'pmh_hyperthyroidism': ['notes/Progress Notes/Past History/Organ Systems/Endocrine', 'Hyperthyroidism'],\n",
    "        'pmh_recent_steroids_>10d': ['notes/Progress Notes/Past History/Organ Systems/Endocrine', 'Recent Steroid Use for > 10 days'],\n",
    "        'pmh__petite_mal_seizures': ['notes/Progress Notes/Past History/Organ Systems/Neurologic', 'Seizures_petite mal seizures'],\n",
    "        'pmh_s_p_LTx': ['notes/Progress Notes/Past History/Organ Systems/Gastrointestinal', 's_p Liver Transplant'],\n",
    "        'pmh_hypercoagulable_condition': ['notes/Progress Notes/Past History/Organ Systems/Hematology-Oncology', 'Hypercoagulable Condition'],\n",
    "        'pmh_ITP': ['notes/Progress Notes/Past History/Organ Systems/Hematology-Oncology', 'ITP'],\n",
    "        'pmh_neurogenic_bladder': ['notes/Progress Notes/Past History/Organ Systems/Renal ', 'Neurogenic Bladder'],\n",
    "        'pmh_sickle_cells': ['notes/Progress Notes/Past History/Organ Systems/Hematology-Oncology', 'Sickle Cell Disease'],\n",
    "        'pmh_clotting_disorder': ['notes/Progress Notes/Past History/Organ Systems/Hematology-Oncology', 'Clotting Disorder'],\n",
    "        'pmh_AIDS': ['notes/Progress Notes/Past History/Organ Systems/Infectious Disease', 'AIDS'],\n",
    "        'pmh_sarcoidosis': ['notes/Progress Notes/Past History/Organ Systems/Pulmonary', 'Sarcoidosis'],\n",
    "        'pmh_vasculitis': ['notes/Progress Notes/Past History/Organ Systems/Rheumatic', 'Vasculitis'],\n",
    "        'pmh_myeloproliferative_disease': ['notes/Progress Notes/Past History/Organ Systems/Hematology-Oncology', 'Myeloproliferative Disease'],\n",
    "        'pmh_s_p_HTx': ['notes/Progress Notes/Past History/Organ Systems/Cardiovascular', 's_p Heart Transplant'],\n",
    "        'pmh_aplastic_anemia': ['notes/Progress Notes/Past History/Organ Systems/Hematology-Oncology', 'Aplastic Anemia'],\n",
    "        'pmh_hypercalcemia': ['notes/Progress Notes/Past History/Organ Systems/Endocrine', 'Hypercalcemia'],\n",
    "        'pmh_hypersplenism': ['notes/Progress Notes/Past History/Organ Systems/Gastrointestinal', 'Hypersplenism'],\n",
    "        'pmh_scleroderma': ['notes/Progress Notes/Past History/Organ Systems/Rheumatic', 'Scleroderma'],\n",
    "        'pmh_RTA': ['notes/Progress Notes/Past History/Organ Systems/Renal', 'RTA'],\n",
    "        'pmh_s_p_lungTx': ['notes/Progress Notes/Past History/Organ Systems/Pulmonary', 's_p Lung Transplant'],\n",
    "        \"pmh_cushings\": [\"notes/Progress Notes/Past History/Organ Systems/Endocrine\", \"Cushing's Syndrome\"],\n",
    "        'pmh_dermato': ['notes/Progress Notes/Past History/Organ Systems/Rheumatic', 'Dermato']\n",
    "    }\n",
    "    \n",
    "    # reducing the general pastHistory df to reduce the computational load\n",
    "    df_temp = df_pmh.loc[df_pmh[\"patientunitstayid\"].isin(lst_ids), [\"patientunitstayid\", \"pasthistorypath\", \"pasthistoryvalue\"]].copy()\n",
    "\n",
    "    # Replace substrings in pasthistorypath (which would cause issues due to regex expressions later on)\n",
    "    df_temp[\"pasthistorypath\"] = df_temp[\"pasthistorypath\"].str.replace(\"Hematology/Oncology\", \"Hematology-Oncology\",\n",
    "                                                                        regex=True)\n",
    "\n",
    "    df_pmh[\"pasthistorypath\"] = df_pmh[\"pasthistorypath\"].str.replace(\"s/p\", \"s_p\",\n",
    "                                                                      regex=True)\n",
    "\n",
    "    df_pmh[\"pasthistorypath\"] = df_pmh[\"pasthistorypath\"].str.replace(\"TIA(s)\", \"TIAs\",\n",
    "                                                                      regex=True)\n",
    "\n",
    "    df_pmh[\"pasthistorypath\"] = df_pmh[\"pasthistorypath\"].str.replace(\"HIV (only)\", \"HIV only\",\n",
    "                                                                      regex=True)\n",
    "\n",
    "    df_pmh[\"pasthistorypath\"] = df_pmh[\"pasthistorypath\"].str.replace(\"Recent Steroid Use (for > 10 days)\", \"Recent Steroid Use for > 10 days\",\n",
    "                                                                      regex=True)\n",
    "\n",
    "    # list for the future columns\n",
    "    lst_columns = []\n",
    "\n",
    "    # Iterate over the individual diseases and check whether a patient has this PMH or not then saving this as a column to the list\n",
    "    for clm_name, key_phrases in tqdm(dict_subcat_clms.items()):\n",
    "        key1 = key_phrases[0]\n",
    "        key2 = key_phrases[1]\n",
    "\n",
    "        df_new_clm_raw = df_temp.loc[(df_temp['pasthistorypath'].str.contains(key1, na=False)) &\n",
    "                                     (df_temp['pasthistorypath'].str.contains(key2, na=False)), [\"patientunitstayid\", \"pasthistorypath\"]].copy().drop_duplicates()\n",
    "\n",
    "        df_new_clm_raw[\"output_pmh_path\"] = df_new_clm_raw[\"pasthistorypath\"].apply(lambda x: apply_split_and_rejoin_for_output(x))\n",
    "\n",
    "        df_new_clm_reference = df_new_clm_raw.copy()\n",
    "\n",
    "        df_new_clm_raw[clm_name] = df_new_clm_raw[\"patientunitstayid\"].apply(lambda x: apply_group_pmh_subcat(x, df_new_clm_reference, \"output_pmh_path\"))\n",
    "\n",
    "        df_pat_w_data = df_new_clm_raw.loc[:, [\"patientunitstayid\", clm_name]].copy().drop_duplicates()\n",
    "\n",
    "        lst_pat_w_data = list(df_new_clm_raw.patientunitstayid.unique())\n",
    "        lst_pat_no_data = [x for x in lst_ids if x not in lst_pat_w_data]\n",
    "\n",
    "        df_pat_without_data = pd.DataFrame(lst_pat_no_data, columns=['patientunitstayid'])\n",
    "        df_pat_without_data[clm_name] = 0\n",
    "\n",
    "        df_clm_final = pd.concat([df_pat_w_data, df_pat_without_data])\n",
    "        df_clm_final = df_clm_final.set_index(\"patientunitstayid\")\n",
    "\n",
    "        lst_columns.append(df_clm_final)\n",
    "\n",
    "    # Concatenate all the columns and export this with the ids as another column  \n",
    "    df_final = pd.concat(lst_columns, axis=1)\n",
    "    df_final = df_final.reset_index()\n",
    "    df_final = df_final[['patientunitstayid', 'pmh_HT_with_treatment', 'pmh_cancer',\n",
    "       'pmh_non_insulin_dep_DM', 'pmh_COPD', 'pmh_CHF', 'pmh_insulin_dep_DM',\n",
    "       'pmh_arrhythmias', 'pmh_MI', 'pmh_strokes', \"pmh_hypothyroidism\", \n",
    "       'pmh_renal_insuff', 'pmh_PCI', 'pmh_card_valvular', 'pmh_asthma',\n",
    "       'pmh_liver_cirrhosis', 'pmh_renal_failure', 'pmh_CA_bypass',\n",
    "       'pmh_seizures', 'pmh_periph_vasc_disease', 'pmh_home_o2',\n",
    "       'pmh_venous_thrombosis', 'pmh_dementia', 'pmh_pacemaker',\n",
    "       'pmh_cancer_therapy', 'pmh_angina', \n",
    "       'pmh_TIAs', 'pmh_resp_failure', 'pmh_AICD', 'pmh_PE',\n",
    "       'pmh_neuromusk_disease', 'pmh_restrictive_lung_disease', 'pmh_hemolytic _anemia', 'pmh_intracranial_mass',\n",
    "       'pmh_hyperthyroidism', 'pmh__petite_mal_seizures', 'pmh_hypercoagulable_condition', 'pmh_ITP', \n",
    "       'pmh_sickle_cells', 'pmh_clotting_disorder','pmh_aplastic_anemia', 'pmh_s_p_lungTx']]\n",
    "\n",
    "    return df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a14bfd1b-9bc9-466b-afda-c916a83d46fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_and_initial_clean_apacheApsVar(df_apsVar, lst_ids):\n",
    "    \"\"\"\n",
    "    Receives the apacheApsVar Dataframe of the eICU database or abbreviated and a list of target patientunitstayids and\n",
    "    returns a dataframe with initially \"cleaned\" data: The -1 Values in several columns which denote for \"no data was\n",
    "    entered\" were set to np.nan. Additionally, a GCS column was added.\n",
    "\n",
    "    :param df_apsVar: DataFrame - apacheApsVar Dataframe from eICU or abreviated. \n",
    "\n",
    "    :param lst_ids: List - list of target patientunitstayids.\n",
    "\n",
    "    :return: DataFrame with patientunitstayid as the index and the data\n",
    "    \"\"\"\n",
    "   \n",
    "    # reducing the general df to reduce the computational load\n",
    "    df_temp = df_apsVar.loc[df_apsVar[\"patientunitstayid\"].isin(lst_ids), ['patientunitstayid', 'dialysis',\n",
    "                                 'eyes', 'motor', 'verbal', 'meds',  'temperature',\n",
    "                                 'respiratoryrate',  'heartrate', 'meanbp']].copy()\n",
    "    \n",
    "    # set the missing data to NaN\n",
    "    lst_clms = ['eyes', 'motor', 'verbal', 'meds', 'temperature',\n",
    "                'respiratoryrate',  'heartrate', 'meanbp']\n",
    "    for clm in lst_clms:\n",
    "        df_temp.loc[df_temp[clm] == -1, [clm]] = np.nan\n",
    "    \n",
    "    # create the GCS column\n",
    "    df_temp[\"GCS\"] = df_temp.eyes + df_temp.motor + df_temp.verbal\n",
    "\n",
    "    # add the patients that did not have any data at all \n",
    "    lst_pat_with_data = list(df_temp.patientunitstayid.unique())\n",
    "    lst_pat_without_data = [x for x in lst_ids if x not in lst_pat_with_data]\n",
    "    df_pat_without_data = pd.DataFrame(np.nan, index=[i for i in range(len(lst_pat_without_data))],\n",
    "                                       columns=[\"patientunitstayid\", 'dialysis',\n",
    "                                                'eyes', 'motor', 'verbal', 'meds', 'temperature',\n",
    "                                                'respiratoryrate', 'heartrate', 'meanbp', \"GCS\"])\n",
    "    df_pat_without_data['patientunitstayid'] = lst_pat_without_data\n",
    "    df_final = pd.concat([df_temp, df_pat_without_data])\n",
    "                       \n",
    "    # Rename columns\n",
    "    rename_clms = ['dialysis', 'eyes', 'motor', 'verbal', 'meds', 'temperature', 'respiratoryrate', 'heartrate', 'meanbp', \"GCS\"]\n",
    "    df_final = df_final.rename(columns={clm: \"aps_{}\".format(clm) for clm in rename_clms})\n",
    "\n",
    "    return df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dc99b59a-d1af-4892-acc4-22dac2aed4f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_cleaned_apachePredVar_basics(df_predvar, lst_ids):\n",
    "    \"\"\"\n",
    "    This function takes the apachePredVar Dataframe (or abbreviated) and a list of patientunitstayids and returns a \n",
    "    cleaned Dataframe with the information for those unitstays. The dataframe will have the ids as index.\n",
    "\n",
    "    :param df_predvar: DataFrame - apachePredVar Dataframe or abbreviated. \n",
    "\n",
    "    :param lst_ids: List - List of patientunitstayids of the target population.\n",
    "\n",
    "    :return: DataFrame with patientunitstayid as the index and the data\n",
    "    \"\"\"\n",
    "      \n",
    "    # reducing the general df to reduce the computational load\n",
    "    df_temp = df_predvar.loc[df_predvar[\"patientunitstayid\"].isin(lst_ids), ['patientunitstayid', 'thrombolytics',\n",
    "               'hepaticfailure', 'lymphoma', 'metastaticcancer', 'leukemia',\n",
    "               'midur', 'oobintubday1', 'oobventday1']].copy()\n",
    "        \n",
    "    # add the patients that did not have any data at all \n",
    "    lst_pat_with_data = list(df_temp.patientunitstayid.unique())\n",
    "    lst_pat_without_data = [x for x in lst_ids if x not in lst_pat_with_data]\n",
    "    df_pat_without_data = pd.DataFrame(np.nan, index=[i for i in range(len(lst_pat_without_data))],\n",
    "                                       columns=['patientunitstayid', 'thrombolytics',\n",
    "                                               'hepaticfailure', 'lymphoma', 'metastaticcancer', 'leukemia',\n",
    "                                               'midur', 'oobintubday1', 'oobventday1'])\n",
    "    df_pat_without_data['patientunitstayid'] = lst_pat_without_data\n",
    "    df_final = pd.concat([df_temp, df_pat_without_data])\n",
    "        \n",
    "    # Rename columns\n",
    "    rename_clms = ['thrombolytics','hepaticfailure', 'lymphoma', 'metastaticcancer', 'leukemia', 'midur', 'oobintubday1', 'oobventday1']\n",
    "    df_final = df_final.rename(columns={clm: \"pred_{}\".format(clm) for clm in rename_clms})\n",
    "    \n",
    "    return df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2dd1687a-f3fc-493a-a380-7350aa58c07b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_cleaned_apachePatientResult_basics(df_apacheresult, lst_ids):\n",
    "    \"\"\"\n",
    "    This function takes the apachePatientResult Dataframe (or abbreviated) and a list of patientunitstayids and returns a \n",
    "    cleaned Dataframe with the information for those unitstays. The dataframe will have the ids as index.\n",
    "\n",
    "    :param df_apacheresult: DataFrame - apachePatientResult Dataframe or abbreviated. \n",
    "\n",
    "    :param lst_ids: List - List of patientunitstayids of the target population.\n",
    "\n",
    "    :return: DataFrame with patientunitstayid as the index and the data\n",
    "    \"\"\"\n",
    "    \n",
    "    # reducing the general df to reduce the computational load\n",
    "    df_temp = df_apacheresult.loc[(df_apacheresult[\"apacheversion\"] == \"IVa\") & (df_apacheresult[\"patientunitstayid\"].isin(lst_ids)),\n",
    "                             ['patientunitstayid', 'acutephysiologyscore', 'apachescore','actualiculos', 'predictedhospitalmortality',\"predictedicumortality\", 'unabridgedhosplos']].copy()\n",
    "\n",
    "    # set the missing data to NaN\n",
    "    lst_minus_ones = ['acutephysiologyscore', 'apachescore',\"predictedicumortality\", 'predictedhospitalmortality']\n",
    "    for clm in lst_minus_ones:\n",
    "        df_temp.loc[df_temp[clm] == -1, [clm]] = np.nan\n",
    "\n",
    "    # add the patients that did not have any data at all \n",
    "    lst_pat_with_data = list(df_temp.patientunitstayid.unique())\n",
    "    lst_pat_without_data = [x for x in lst_ids if x not in lst_pat_with_data]\n",
    "    df_pat_without_data = pd.DataFrame(np.nan, index=[i for i in range(len(lst_pat_without_data))],\n",
    "                                       columns=['patientunitstayid', 'acutephysiologyscore', 'apachescore', 'actualiculos', 'predictedhospitalmortality', \"predictedicumortality\", 'unabridgedhosplos'])\n",
    "    df_pat_without_data['patientunitstayid'] = lst_pat_without_data\n",
    "    df_final = pd.concat([df_temp, df_pat_without_data])\n",
    "\n",
    "    return df_final\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "24f72935-befe-4f43-971c-8c8602a82277",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_infusion_drugs(df_infusion, lst_ids, additional_dict=None, timeframe=(0, 1440)):\n",
    "    \"\"\"\n",
    "    This function returns a dataframe indicating whether patients received certain medication classes within a specified timeframe.\n",
    "\n",
    "    :param df_infusion: DataFrame - infusionDrug Dataframe from eICU. \n",
    "\n",
    "    :param lst_ids: List - List of patientunitstayids of the target population.\n",
    "\n",
    "    :param additional_dict: Dict - Additional/custom dictionary with the \"clm_name\": \"drugname|drugname|drugname\" format.\n",
    "\n",
    "    :param timeframe: Tuple, default is (0, 1440) - (lower offset, upper offset), offset bounds.\n",
    "\n",
    "    :return: DataFrame with the columns of who got which medication.\n",
    "    \"\"\"\n",
    "\n",
    "    lower_offset, upper_offset = timeframe\n",
    "\n",
    "    # reducing the general df to reduce the computational load\n",
    "    df_reduced = df_infusion.query(\"patientunitstayid in @lst_ids and @lower_offset <= infusionoffset <= @upper_offset\").copy()\n",
    "\n",
    "    df_reduced.drugname = df_reduced.drugname.str.lower()\n",
    "\n",
    "    dict_drugs = {\n",
    "        \"infusion_vaso_ino\": 'epinephrine|adrenaline|norepinephrine|levophed|dobutamine|dobutrex|vasopressin|isoprotenerol|isuprel|phenylephrine|neo-synephrine|dopamine|milrinone',\n",
    "        \"infusion_thrombolytic\": \"alteplase|activase|tpa|altaplase|altepase\"}\n",
    "\n",
    "    if additional_dict is not None:\n",
    "        dict_drugs.update(additional_dict)\n",
    "\n",
    "    lst_columns = []\n",
    "    \n",
    "    # loop over the the drug groups and look at whether patients received this as an infusion or not\n",
    "    for clm_name, drug_str in dict_drugs.items():\n",
    "\n",
    "        lst_pat_drug = df_reduced.loc[df_reduced.drugname.str.contains(drug_str), \"patientunitstayid\"].copy().unique().tolist()\n",
    "        lst_pat_wo_drug = [i for i in lst_ids if i not in lst_pat_drug]\n",
    "\n",
    "        df_pat_w_data = pd.DataFrame(lst_pat_drug, columns=['patientunitstayid'])\n",
    "        df_pat_w_data[clm_name] = 1\n",
    "\n",
    "        df_pat_without_data = pd.DataFrame(lst_pat_wo_drug, columns=['patientunitstayid'])\n",
    "        df_pat_without_data[clm_name] = 0\n",
    "\n",
    "        df_clm_final = pd.concat([df_pat_w_data, df_pat_without_data])\n",
    "        df_clm_final = df_clm_final.set_index(\"patientunitstayid\")\n",
    "\n",
    "        lst_columns.append(df_clm_final)\n",
    "\n",
    "    df_final = pd.concat(lst_columns, axis=1)\n",
    "\n",
    "    return df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "854c2055-29d4-45b1-980b-9c6a1b9be3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_infusion_drugs_relative_interval_from_start(df_infusion, lst_ids, additional_dict=None, overall_timeframe=(0, 1440), time_interval=360):\n",
    "    \"\"\"\n",
    "    This function returns a dataframe indicating whether patients received certain medication classes within a specified timeframe from the start. \n",
    "    More specifically, this function looks at the timeframe relative from the individual start of a patients data collection. This function is\n",
    "    meant for shorter timeframes where differences in the starting time of data-collection (e.g. starting at 5 minutes vs 65 minutes vs 92 minutes),.\n",
    "    e.g. induced by delayed data entry, has major impact. There will be no differences between this and the more general function for longer timeframes.\n",
    "\n",
    "    :param df_infusion: DataFrame - infusionDrug Dataframe from eICU. \n",
    "\n",
    "    :param lst_ids: List - List of patientunitstayids of the target population.\n",
    "\n",
    "    :param additional_dict: Dict - Additional/custom dictionary with the \"clm_name\": \"drugname|drugname|drugname\" format.\n",
    "\n",
    "    :param overall_timeframe: Tuple, default is (0, 1440) - (lower offset, upper offset), used to trim the data down to improve speed\n",
    "    \n",
    "    :param time_interval: Int, default is 360 - time in minutes from the start of data collection\n",
    "\n",
    "    :return: DataFrame with the columns of who got which medication.\n",
    "    \"\"\"\n",
    "\n",
    "    lower_overall_offset, upper_overall_offset = overall_timeframe\n",
    "    \n",
    "    # reducing the general df to reduce the computational load \n",
    "    df_in_icu = df_infusion.loc[(df_infusion.patientunitstayid.isin(lst_ids))\n",
    "                                 & (df_infusion.infusionoffset >= lower_overall_offset)\n",
    "                                 & (df_infusion.infusionoffset <= upper_overall_offset), :].copy()\n",
    "    \n",
    "\n",
    "    df_in_icu.drugname = df_in_icu.drugname.str.lower()\n",
    "\n",
    "    # calculate the starting time of the first point of data collection for the individual patients and then select only the intended time-interval\n",
    "    df_in_icu['first_observation'] = df_in_icu.groupby('patientunitstayid')['infusionoffset'].transform(min)\n",
    "    df_in_icu['group'] = ((df_in_icu['infusionoffset'] - df_in_icu['first_observation']) // (time_interval + 1)).astype(int)\n",
    "    df_in_icu = df_in_icu[df_in_icu['group'] == 0].copy()\n",
    "\n",
    "    dict_drugs = {\n",
    "        \"infusion_vaso_ino\": 'epinephrine|adrenaline|norepinephrine|levophed|dobutamine|dobutrex|vasopressin|isoprotenerol|isuprel|phenylephrine|neo-synephrine|dopamine|milrinone|isoproterenol',\n",
    "        \"infusion_thrombolytic\": \"alteplase|activase|tpa|altaplase|altepase\"}\n",
    "\n",
    "    if additional_dict is not None:\n",
    "        dict_drugs.update(additional_dict)\n",
    "\n",
    "    lst_columns = []\n",
    "    \n",
    "    # loop over the the drug groups and look at whether patients received this as an infusion or not\n",
    "    for clm_name, drug_str in dict_drugs.items():\n",
    "        \n",
    "        lst_pat_drug = df_in_icu.loc[df_in_icu.drugname.str.contains(drug_str), \"patientunitstayid\"].copy().unique().tolist()\n",
    "\n",
    "        lst_pat_wo_drug = [i for i in lst_ids if i not in lst_pat_drug]\n",
    "\n",
    "        df_pat_w_data = pd.DataFrame(lst_pat_drug, columns=['patientunitstayid'])\n",
    "        df_pat_w_data[clm_name] = 1\n",
    "\n",
    "        df_pat_without_data = pd.DataFrame(lst_pat_wo_drug, columns=['patientunitstayid'])\n",
    "        df_pat_without_data[clm_name] = 0\n",
    "\n",
    "        df_clm_final = pd.concat([df_pat_w_data, df_pat_without_data])\n",
    "        df_clm_final.set_index(\"patientunitstayid\", inplace=True)\n",
    "\n",
    "        lst_columns.append(df_clm_final)\n",
    "        \n",
    "    df_final = pd.concat(lst_columns, axis=1)\n",
    "\n",
    "    return df_final\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5af954d9-6aab-49e2-b405-b6c77ad4ffc3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_mechanically_ventilated_from_start_relative(df_resp_chart, df_resp_care, df_physical, df_nurse_chart, lst_ids,\n",
    "                                                 time_interval=360, overall_offset=(0, 1440)):\n",
    "    \"\"\"\n",
    "    This function returns, whether patients were mechanically ventilated during the given time from the start of admission/data collection.\n",
    "    More specifically, this function looks at the timeframe relative from the individual start of a patients data collection. This function is\n",
    "    meant for shorter timeframes where differences in the starting time of data-collection (e.g. starting at 5 minutes vs 65 minutes vs 92 minutes),\n",
    "    e.g. induced by delayed data entry, has major impact.\n",
    "    \n",
    "    :param df_resp_chart: Dataframe - respiratoryCharting dataframe from the eICU\n",
    "    :param df_resp_care: Dataframe - respiratoryCare dataframe from the eICU\n",
    "    :param df_physical: Dataframe - physicalExam dataframe from the eICU\n",
    "    :param df_nurse_chart: Dataframe - nurseCharting dataframe from the eICU\n",
    "    :param lst_ids: List - List of patientunitstayids of the target population.\n",
    "    :param time_interval: Int, default is 360 - time in minutes from the start of data collection\n",
    "    :param overall_offset: Tuple, default is (0, 1440) - (lower offset, upper offset), used to trim the data down to improve speed\n",
    "    :return: DataFrame with a column \"mech_vent_first_{time_interval}_min\" of who was mechanically ventilated at some point during this\n",
    "    timeframe from the start\n",
    "    \"\"\"\n",
    "\n",
    "    lower_offset, higher_offset = overall_offset\n",
    "    \n",
    "    # reducing the general df to reduce the computational load\n",
    "    df_pe_red = df_physical.loc[(df_physical.patientunitstayid.isin(lst_ids)) &\n",
    "                                (df_physical.physicalexamoffset >= lower_offset) &\n",
    "                                (df_physical.physicalexamoffset <= higher_offset), :].copy()\n",
    "\n",
    "    df_nc_red = df_nurse_chart.loc[(df_nurse_chart.patientunitstayid.isin(lst_ids)) &\n",
    "                                   (df_nurse_chart.nursingchartoffset >= lower_offset) &\n",
    "                                   (df_nurse_chart.nursingchartoffset <= higher_offset), :].copy()\n",
    "\n",
    "    df_rt_red = df_resp_chart.loc[(df_resp_chart.patientunitstayid.isin(lst_ids)) &\n",
    "                                   (df_resp_chart.respchartoffset >= lower_offset) &\n",
    "                                   (df_resp_chart.respchartoffset <= higher_offset), :].copy()\n",
    "\n",
    "    df_re_red = df_resp_care.loc[(df_resp_care.patientunitstayid.isin(lst_ids)), :].copy()\n",
    "\n",
    "    # get a dictionary with all the relative individual start times: dict_first_pe\n",
    "    # This is derived from the physicalExaminations table as of these 4, it is the most granular/usually has the first data entry\n",
    "    # If a ICU-admission cannot be found in the physicalExamination table, then it's relative starting time is set to 0 (conservatively)\n",
    "    df_initial_pe = df_pe_red.groupby('patientunitstayid')['physicalexamoffset'].min().reset_index()\n",
    "\n",
    "    dict_first_pe = dict(zip(df_initial_pe[\"patientunitstayid\"], df_initial_pe[\"physicalexamoffset\"]))\n",
    "\n",
    "    missing_ids_first_neuro = set(lst_ids) - set(dict_first_pe.keys())\n",
    "    dict_first_pe.update({id_number: 0 for id_number in missing_ids_first_neuro})\n",
    "\n",
    "    # add these initial start times to all the dataframes and sort for only values that are in the actual timeframe (or before)\n",
    "    df_pe_red['first_observation'] = df_pe_red.patientunitstayid.map(dict_first_pe)\n",
    "    df_pe_red['poss_before'] = (df_pe_red['physicalexamoffset'] - df_pe_red['first_observation']).astype(int)\n",
    "    df_pe_red['group'] = ((df_pe_red['physicalexamoffset'] - df_pe_red['first_observation']) // (time_interval + 1)).astype(int)\n",
    "    df_pe_red = df_pe_red[(df_pe_red['group'] == 0) | (df_pe_red['poss_before'] < -1)].copy()\n",
    "\n",
    "    df_nc_red['first_observation'] = df_nc_red.patientunitstayid.map(dict_first_pe)\n",
    "    df_nc_red['poss_before'] = (df_nc_red['nursingchartoffset'] - df_nc_red['first_observation']).astype(int)\n",
    "    df_nc_red['group'] = ((df_nc_red['nursingchartoffset'] - df_nc_red['first_observation']) // (time_interval + 1)).astype(int)\n",
    "    df_nc_red = df_nc_red[(df_nc_red['group'] == 0) | (df_nc_red['poss_before'] < -1)].copy()\n",
    "\n",
    "    df_rt_red['first_observation'] = df_rt_red.patientunitstayid.map(dict_first_pe)\n",
    "    df_rt_red['poss_before'] = (df_rt_red['respchartoffset'] - df_rt_red['first_observation']).astype(int)\n",
    "    df_rt_red['group'] = ((df_rt_red['respchartoffset'] - df_rt_red['first_observation']) // (time_interval + 1)).astype(int)\n",
    "    df_rt_red = df_rt_red[(df_rt_red['group'] == 0) | (df_rt_red['poss_before'] < -1)].copy()\n",
    "\n",
    "    # Rarely, the the vent-start time is entered as lower than the actual entry of the information, so we adjust for these vent-times preceding the \n",
    "    # target time-interval\n",
    "    df_re_red.loc[df_re_red.ventstartoffset != 0, 'respcarestatusoffset'] = df_re_red.loc[df_re_red.ventstartoffset != 0, ['respcarestatusoffset', 'ventstartoffset']].min(axis=1)\n",
    "    df_re_red['first_observation'] = df_re_red.patientunitstayid.map(dict_first_pe)\n",
    "    df_re_red['poss_before'] = (df_re_red['respcarestatusoffset'] - df_re_red['first_observation']).astype(int)\n",
    "    df_re_red['group'] = ((df_re_red['respcarestatusoffset'] - df_re_red['first_observation']) // (time_interval + 1)).astype(int)\n",
    "    df_re_red = df_re_red[(df_re_red['group'] == 0) | (df_re_red['poss_before'] < -1)].copy()\n",
    "\n",
    "    lst_all_vent_lsts = []\n",
    "\n",
    "    # get the ICU-admissions indicating mechanical ventilation from the nurseCharting table\n",
    "    df_nc_vent = df_nc_red.loc[\n",
    "                 ((df_nc_red.nursingchartcelltypevallabel == \"O2 Admin Device\") &\n",
    "                  (df_nc_red.nursingchartvalue.isin([\"ventilator\", \"trach collar\", \"vent\", \"VENT\", \"vented\", \"ac 10/400/40+5\", \"AC10 500 60 5\"]))) |\n",
    "                 (df_nc_red.nursingchartcelltypevallabel == \"End Tidal CO2\"), :].copy()\n",
    "    lst_nc_vent = list(df_nc_vent.patientunitstayid.unique())\n",
    "    lst_all_vent_lsts.append(lst_nc_vent)\n",
    "\n",
    "    # get the ICU-admissions indicating mechanical ventilation from the physicalExamination table\n",
    "    df_pe_vent = df_pe_red.loc[((df_pe_red.physicalexampath.str.contains(\"Pulmonary/Airway\", regex=False, case=False)) &\n",
    "                                (df_pe_red.physicalexamvalue.isin([\"intubated\", \"tracheostomy\"]))) |\n",
    "                               ((df_pe_red.physicalexampath.str.contains(\"Constitutional/Vital Sign and Physiological Data/Resp Mode/\", regex=False, case=False)) &\n",
    "                                (df_pe_red.physicalexamvalue == \"ventilated\")), :].copy()\n",
    "    lst_pe_vent = list(df_pe_vent.patientunitstayid.unique())\n",
    "    lst_all_vent_lsts.append(lst_pe_vent)\n",
    "\n",
    "    # get the ICU-admissions indicating mechanical ventilation from the respiratoryCare table\n",
    "    df_re_vent = df_re_red.loc[df_re_red.lowexhmvlimit.notna() |\n",
    "                               df_re_red.hiexhmvlimit.notna() |\n",
    "                               df_re_red.lowexhtvlimit.notna() |\n",
    "                               df_re_red.hipeakpreslimit.notna() |\n",
    "                               df_re_red.lowpeakpreslimit.notna() |\n",
    "                               df_re_red.hirespratelimit.notna() |\n",
    "                               df_re_red.lowrespratelimit.notna() |\n",
    "                               df_re_red.cuffpressure.notna() |\n",
    "                               df_re_red.airwaysize.notna() |\n",
    "                               df_re_red.airwayposition.notna() |\n",
    "                               df_re_red.airwaytype.isin([\"Oral ETT\", \"Tracheostomy\"]) , :].copy()\n",
    "    lst_re_vent = list(df_re_vent.patientunitstayid.unique())\n",
    "    lst_all_vent_lsts.append(lst_re_vent)\n",
    "\n",
    "    # get the ICU-admissions indicating mechanical ventilation from the respiratoryCharting table\n",
    "    df_rt_vent = df_rt_red.loc[\n",
    "                  ((df_rt_red.respcharttypecat == \"respFlowSettings\") &\n",
    "                   (df_rt_red.respchartvaluelabel.isin([\"TV/kg IBW\", \"Tidal Volume (set)\", \"Pressure Control\", \"PEEP\"]))) |\n",
    "                  ((df_rt_red.respcharttypecat == \"respFlowPtVentData\") &\n",
    "                   (df_rt_red.respchartvaluelabel.isin([\"Peak Insp. Pressure\", \"Mean Airway Pressure\", \"Exhaled MV\", \"Exhaled TV (machine)\", \"Plateau Pressure\", \"Compliance\"]))) |\n",
    "                  ((df_rt_red.respcharttypecat == \"respFlowCareData\") &\n",
    "                   (df_rt_red.respchartvaluelabel.isin(\n",
    "                       [\"Set Vt (Servo,LTV)\", \"Tidal Volume Observed (VT)\", \"Adult Con Setting Set RR\", \"Adult Con Setting Set Vt\", \"Secured at-ETT\", \"Adult Con Pt/Vent MinuteVentil\",\n",
    "                        \"Adult Con Pt/Vent InspiratorTV\", \"Adult Con Alarms Hi Press Alarm\", \"Endotracheal Tube Placement\", \"Tidal Volume, Delivered\",\n",
    "                        \"Set Fraction of Inspired Oxygen (FIO2)\", \"Mechanical Ventilator Compliance\", \"Mechanical Ventilation Slope\", \"Mechanical Ventilator Resistance\",\n",
    "                        \"Endotracheal Tube Placement Checked\", \"Mechanical Ventilator High Tidal Volume Alarm\", \"Mechanical Ventilator Mode\"]))) |\n",
    "                  ((df_rt_red.respcharttypecat == \"respFlowCareData\") & (df_rt_red.respchartvaluelabel == \"O2 Device\") &\n",
    "                   df_rt_red.respchartvalue.isin([\"Ventilator\", \"Trach mask/collar\", \"ETT\", \"Ambubag\"])), :].copy()\n",
    "    lst_rt_intub = list(df_rt_vent.patientunitstayid.unique())\n",
    "    lst_all_vent_lsts.append(lst_rt_intub)\n",
    "\n",
    "    # combine these lists to a binary column\n",
    "    lst_pat_intub = list({pat_id for sublist_ams in lst_all_vent_lsts for pat_id in sublist_ams})\n",
    "    lst_pat_wo_intub = [i for i in lst_ids if i not in lst_pat_intub]\n",
    "\n",
    "    final_clm_name = f\"mech_vent_first_{time_interval}_min\"\n",
    "\n",
    "    df_pat_intub = pd.DataFrame(lst_pat_intub, columns=['patientunitstayid'])\n",
    "    df_pat_intub[final_clm_name] = 1\n",
    "\n",
    "    df_pat_wo_intub = pd.DataFrame(lst_pat_wo_intub, columns=['patientunitstayid'])\n",
    "    df_pat_wo_intub[final_clm_name] = 0\n",
    "\n",
    "    df_final = pd.concat([df_pat_intub, df_pat_wo_intub], axis=0)\n",
    "\n",
    "    return df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bf5fb202-b2cb-4b88-922d-0b12df78473e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_AMS_from_start_relative(df_physical, df_nurse_chart, lst_ids, time_interval=360, overall_offset=(0, 1440)):\n",
    "    \"\"\"\n",
    "    This function returns, whether patients had AMS (defined as a GCS <5) during the given time from the start of admission/data collection.\n",
    "    More specifically, this function looks at the timeframe relative from the individual start of a patients data collection. This function is\n",
    "    meant for shorter timeframes where differences in the starting time of data-collection (e.g. starting at 5 minutes vs 65 minutes vs 92 minutes),\n",
    "    e.g. induced by delayed data entry, has major impact.\n",
    "    \n",
    "    :param df_physical: Dataframe - physicalExam dataframe from the eICU\n",
    "    :param df_nurse_chart: Dataframe - nurseCharting dataframe from the eICU\n",
    "    :param lst_ids: List - List of patientunitstayids of the target population.\n",
    "    :param time_interval: Int, default is 360 - time in minutes from the start of data collection\n",
    "    :param overall_offset: Tuple, default is (0, 1440) - (lower offset, upper offset), used to trim the data down to improve speed\n",
    "    :return: DataFrame with a column \"ams_first_{time_interval}_min\" of who had AMS at some point during this\n",
    "    timeframe from the start\n",
    "    \"\"\"\n",
    "    # reducing the general df to reduce the computational load\n",
    "    lower_offset, higher_offset = overall_offset\n",
    "\n",
    "    df_pe_red = df_physical.loc[(df_physical.patientunitstayid.isin(lst_ids)) &\n",
    "                                (df_physical.physicalexampath.str.contains(\"Neurologic/GCS/\")) &\n",
    "                                (df_physical.physicalexamoffset >= lower_offset) &\n",
    "                                (df_physical.physicalexamoffset <= higher_offset), :].copy()\n",
    "\n",
    "    df_nc_red = df_nurse_chart.loc[(df_nurse_chart.patientunitstayid.isin(lst_ids)) &\n",
    "                                 (df_nurse_chart.nursingchartoffset >= lower_offset) &\n",
    "                                 (df_nurse_chart.nursingchartoffset <= higher_offset), :].copy()\n",
    "\n",
    "    # get a dictionary with all the relative individual start times: dict_first_neuro_pe\n",
    "    df_pe_red['exampath'] = df_pe_red['physicalexampath'].str.replace(\n",
    "        \"notes/Progress Notes/Physical Exam/Physical Exam/\", \"\", 1)\n",
    "    df_initial_pe = df_pe_red.groupby('patientunitstayid')['physicalexamoffset'].min().reset_index()\n",
    "\n",
    "    dict_first_neuro_pe = dict(zip(df_initial_pe[\"patientunitstayid\"], df_initial_pe[\"physicalexamoffset\"]))\n",
    "\n",
    "    missing_ids_first_neuro = set(lst_ids) - set(dict_first_neuro_pe.keys())\n",
    "    dict_first_neuro_pe.update({id_number: 0 for id_number in missing_ids_first_neuro})\n",
    "\n",
    "    # add these initial start times to all the dataframes and sort for only values that are in the actual timeframe\n",
    "    df_pe_red['first_observation'] = df_pe_red.patientunitstayid.map(dict_first_neuro_pe)\n",
    "    df_pe_red['group'] = ((df_pe_red['physicalexamoffset'] - df_pe_red['first_observation']) // (time_interval + 1)).astype(int)\n",
    "    df_pe_red = df_pe_red[df_pe_red['group'] == 0].copy()\n",
    "\n",
    "    df_nc_red['first_observation'] = df_nc_red.patientunitstayid.map(dict_first_neuro_pe)\n",
    "    df_nc_red['group'] = ((df_nc_red['nursingchartoffset'] - df_nc_red['first_observation']) // (time_interval + 1)).astype(int)\n",
    "    df_nc_red = df_nc_red[df_nc_red['group'] == 0].copy()\n",
    "\n",
    "    lst_all_ams_lsts = []\n",
    "\n",
    "    # get the AMS patients from the physicalExam dataframe\n",
    "    df_pe_gcs = df_pe_red[df_pe_red.physicalexampath.str.contains(\"Neurologic/GCS/Verbal Score\", regex=False, case=False)].copy()\n",
    "    df_pe_gcs.physicalexamvalue = pd.to_numeric(df_pe_gcs.physicalexamvalue)\n",
    "    lst_pe_gcs_ams = list(df_pe_gcs[df_pe_gcs.physicalexamvalue <= 4].patientunitstayid.unique())\n",
    "    lst_all_ams_lsts.append(lst_pe_gcs_ams)\n",
    "    \n",
    "    # get the AMS patients from the nurseCharting dataframe\n",
    "    df_nc_gcs = df_nc_red[(df_nc_red.nursingchartcelltypevallabel == \"Glasgow coma score\") & (df_nc_red.nursingchartcelltypevalname == \"Verbal\")].copy()\n",
    "    df_nc_gcs.nursingchartvalue = pd.to_numeric(df_nc_gcs.nursingchartvalue)\n",
    "    lst_ns_gcs_ams = list(df_nc_gcs[df_nc_gcs.nursingchartvalue <= 4].patientunitstayid.unique())\n",
    "    lst_all_ams_lsts.append(lst_ns_gcs_ams)\n",
    "\n",
    "    df_nc_other_ams = df_nc_red.loc[((df_nc_red.nursingchartcelltypevallabel == \"Best Verbal Response\") & (df_nc_red.nursingchartvalue.str.contains(\"4|3|2|1|confused|intubated\", regex=True, case=False))), :].copy()\n",
    "    df_nc_other_ams = list(df_nc_other_ams.patientunitstayid.unique())\n",
    "    lst_all_ams_lsts.append(df_nc_other_ams)\n",
    "\n",
    "    # combine these lists to a binary column\n",
    "    lst_pat_w_ams = list({pat_id for sublist_ams in lst_all_ams_lsts for pat_id in sublist_ams})\n",
    "    lst_pat_wo_ams = [i for i in lst_ids if i not in lst_pat_w_ams]\n",
    "\n",
    "    ams_clm_name = f\"ams_first_{time_interval}_min\"\n",
    "\n",
    "    df_pat_w_ams = pd.DataFrame(lst_pat_w_ams, columns=['patientunitstayid'])\n",
    "    df_pat_w_ams[ams_clm_name] = 1\n",
    "\n",
    "    df_pat_without_ams = pd.DataFrame(lst_pat_wo_ams, columns=['patientunitstayid'])\n",
    "    df_pat_without_ams[ams_clm_name] = 0\n",
    "\n",
    "    df_final = pd.concat([df_pat_w_ams, df_pat_without_ams], axis=0)\n",
    "\n",
    "    return df_final\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d966bbf4-2a35-443c-b02c-3a06850a50b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fast_clean_data(array_vitals):\n",
    "    \"\"\"\n",
    "    Discard outliers that are > (median + 2 IQR) or < (median - 2 IQR)\n",
    "\n",
    "    :param lst_values: List - list of values (eg. mean BPs from a certain timeframe of a patient)\n",
    "\n",
    "    :return: Array - numpy array of cleaned values\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # to detect outliers for the patients own baseline:\n",
    "    q25, q50, q75 = np.percentile(array_vitals, [25, 50, 75])\n",
    "    iqr = q75 - q25\n",
    "\n",
    "    cleaned_array = array_vitals[(array_vitals >= (q50 - 2 * iqr)) & (array_vitals <= (q50 + 2 * iqr))].copy()\n",
    "\n",
    "    return cleaned_array\n",
    "\n",
    "\n",
    "def groupby_vitals_per_hour(x, agg_timeunit):\n",
    "    \"\"\"\n",
    "    Discard outliers (apply fast_clean_data function ()) and then summarize the data in this timeframe as a\n",
    "    single value per patient\n",
    "    \"\"\"\n",
    "    np_hourly_vitals = x.to_numpy()\n",
    "\n",
    "    cleaned_hourly = fast_clean_data(np_hourly_vitals)\n",
    "\n",
    "    if agg_timeunit == \"median\":\n",
    "        hour_vital = np.median(cleaned_hourly)\n",
    "    if agg_timeunit == \"max\":\n",
    "        hour_vital = np.max(cleaned_hourly)\n",
    "    if agg_timeunit == \"min\":\n",
    "        hour_vital = np.min(cleaned_hourly)\n",
    "\n",
    "    return hour_vital\n",
    "\n",
    "\n",
    "def groupby_vitals_total(x, agg_total):\n",
    "    \"\"\"\n",
    "    Summarize the data in this timeframe as a single value per patient\n",
    "    \"\"\"\n",
    "    np_total_vitals = x.to_numpy()\n",
    "\n",
    "    if agg_total == \"median\":\n",
    "        total_vital = np.median(np_total_vitals)\n",
    "    if agg_total == \"max\":\n",
    "        total_vital = np.max(np_total_vitals)\n",
    "    if agg_total == \"min\":\n",
    "        total_vital = np.min(np_total_vitals)\n",
    "\n",
    "    return total_vital\n",
    "\n",
    "\n",
    "def fast_vitals_periodic(df_periodic, lst_ids, vital_name, realistic_bounds, offset, agg_timeunit=\"median\",\n",
    "                         agg_total=\"median\", timeunit=60, temp_nurse_bool=False, temp_nursechart=None):\n",
    "    \"\"\"\n",
    "        Takes the vitalPeriodic table of eICU, target patientunitstayids as a list, offset bounds, and realistic bounds and a vitalname and\n",
    "        returns the aggregated and cleaned value for that offset timeframe. There are different options to choose from on how to aggregate that\n",
    "        value. If looking at the temperature, there is the option to include all temperature measurements from the nurses charting (which often \n",
    "        primarily includes the temperature values of a patient. Pulsepressure is calculated from the respective BP_sys - BP_dia. (will \n",
    "        automatically use 20/300 (systolic) and 10/200 (diastolic) as bounds)\n",
    "        Accepted vitalnames: temperature, sao2, heartrate, respiration, cvp, etco2, systemicsystolic, systemicdiastolic, systemicmean, pasystolic, \n",
    "        padiastolic, pamean, icp\n",
    "\n",
    "        :param df_periodic: Dataframe - abbreviated (! unless a lot of free RAM) Dataframe of the vitalPeriodic table of eICU\n",
    "\n",
    "        :param lst_ids: List - list of patientunitstayids of the target population\n",
    "\n",
    "        :param vital_name: String - Column name of the vital \n",
    "\n",
    "        :param realistic_bounds: Tuple - realistic values of the vital in the form of (lower bound, upper bound) eg. (20,100) for fio2\n",
    "\n",
    "        :param offset: Tuple - (lower time offest, upper time offset)\n",
    "\n",
    "        :param agg_timeunit: String, picklist, preset \"median\" - whether to use \"median\", \"max\" or \"min\" to aggregate the values per timeunit (if the\n",
    "                offset duration is longer than the timeunit)\n",
    "\n",
    "        :param agg_total: String, picklist, preset \"median\" - whether to use \"median\", \"max\" or \"min\" to aggregate the values to the final value\n",
    "        \n",
    "        :param timeunit: Int, preset 60 - Number of minutes for the timeunit\n",
    "        \n",
    "        :param temp_nurse_bool: Boolean, preset False - Whether to use the nurse charting for the temperature\n",
    "        \n",
    "        :param temp_nursechart: Dataframe - NurseCharting Dataframe of the eICU if the vital_name is temperature and temp_nurse_bool is True\n",
    "\n",
    "        :return: Dataframe \n",
    "        \"\"\"\n",
    "\n",
    "    # reducing the general df to reduce the computational load\n",
    "    df_reduced = df_periodic[df_periodic[\"patientunitstayid\"].isin(lst_ids)].copy()\n",
    "\n",
    "    # open the tuples of the bounds \n",
    "    lower_realistic_bound, upper_realistic_bound = realistic_bounds\n",
    "    lower_offset, upper_offset = offset\n",
    "\n",
    "    # next reduction, incorporating the big offset bounds and the realistic bounds\n",
    "    df_temp = df_reduced.loc[\n",
    "        (df_reduced[vital_name] >= lower_realistic_bound) & (df_reduced[vital_name] <= upper_realistic_bound) &\n",
    "        (df_reduced[\"observationoffset\"] >= lower_offset) & (df_reduced[\"observationoffset\"] <= upper_offset),\n",
    "        [\"patientunitstayid\", \"observationoffset\", vital_name]].copy().dropna()\n",
    "\n",
    "    # calculate the pulsepressure if this is selected; via systolic BP - diastolic BP\n",
    "    if vital_name == \"pulsepressure\":\n",
    "        df_temp_initial = df_reduced.loc[(df_reduced[\"systemicsystolic\"] >= 20) & (df_reduced[\"systemicsystolic\"] <= 300) &\n",
    "                                         (df_reduced[\"systemicdiastolic\"] >= 10) & (df_reduced[\"systemicdiastolic\"] <= 200) &\n",
    "                                         (df_reduced[\"observationoffset\"] >= lower_offset) & (\n",
    "                                                 df_reduced[\"observationoffset\"] <= upper_offset),\n",
    "                                         [\"patientunitstayid\", \"observationoffset\", \"systemicsystolic\", \"systemicdiastolic\"]].copy()\n",
    "\n",
    "        df_temp = (df_temp_initial.assign(pulsepressure=df_temp_initial[\"systemicsystolic\"] - df_temp_initial[\"systemicdiastolic\"])\n",
    "                   .drop(columns=[\"systemicsystolic\", \"systemicdiastolic\"])\n",
    "                   .dropna()\n",
    "                   )\n",
    "        \n",
    "    # add the temperature information from the nurse chart if temperature is selected and this feature is used\n",
    "    if vital_name == \"temperature\" and temp_nurse_bool:\n",
    "        # reduce the nurse charting to lessen the computational load\n",
    "        df_nursechart = temp_nursechart[temp_nursechart[\"patientunitstayid\"].isin(lst_ids)].copy()\n",
    "        df_n_char_red = df_nursechart.loc[(df_nursechart.nursingchartoffset <= upper_offset) &\n",
    "                                          (df_nursechart.nursingchartoffset >= lower_offset) &\n",
    "                                          (df_nursechart.nursingchartcelltypevallabel == \"Temperature\") &\n",
    "                                          (df_nursechart.nursingchartcelltypevalname.isin(\n",
    "                                              ['Temperature (C)', 'Temperature (F)'])),\n",
    "                                          [\"patientunitstayid\", \"nursingchartoffset\", \"nursingchartcelltypevalname\",\n",
    "                                           \"nursingchartvalue\"]].copy()\n",
    "        \n",
    "        # adjust for the fact that some values are taken as °F and some as °C\n",
    "        df_n_char_red.nursingchartvalue = df_n_char_red.nursingchartvalue.astype(float)\n",
    "        df_n_char_red[\"temperature\"] = df_n_char_red.apply(lambda x: ((x.nursingchartvalue - 32) * (\n",
    "                    5 / 9)) if x.nursingchartcelltypevalname == 'Temperature (F)' else x.nursingchartvalue, axis=1)\n",
    "        df_n_char_red = df_n_char_red.rename(columns={\"nursingchartoffset\": \"observationoffset\"})\n",
    "        df_n_char_final = df_n_char_red.loc[(df_n_char_red[vital_name] >= lower_realistic_bound) & (\n",
    "                    df_n_char_red[vital_name] <= upper_realistic_bound),\n",
    "                                            [\"patientunitstayid\", \"observationoffset\",\n",
    "                                             vital_name]].copy().reset_index(drop=True)\n",
    "\n",
    "        df_temp = pd.concat([df_temp, df_n_char_final])\n",
    "\n",
    "    # create bins for the timeunit in the given offset interval and then cut the column to these bins\n",
    "    lst_bins = [i for i in range(lower_offset, upper_offset + 1, timeunit) if i <= upper_offset]\n",
    "    \n",
    "    if (upper_offset - lower_offset) % timeunit != 0: \n",
    "        lst_bins.append(upper_offset)\n",
    "\n",
    "    df_temp.observationoffset = pd.cut(df_temp.observationoffset, bins=lst_bins, right=True, include_lowest=True)\n",
    "\n",
    "    # group first by hour (cleaning the data of outliers) and then over the total offset span\n",
    "    df_grouped_hours = (df_temp\n",
    "                        .groupby([\"patientunitstayid\", \"observationoffset\"])\n",
    "                        .agg(lambda x: groupby_vitals_per_hour(x, agg_timeunit=agg_timeunit))\n",
    "                        .reset_index()\n",
    "                        .drop(columns=[\"observationoffset\"])\n",
    "                        .dropna()\n",
    "                        .groupby([\"patientunitstayid\"])\n",
    "                        .agg(lambda x: groupby_vitals_total(x, agg_total=agg_total))\n",
    "                        .reset_index()\n",
    "                        )\n",
    "\n",
    "    # make a dataframe with a single column containing the ids and then merge the results to that\n",
    "    df_pat = pd.DataFrame({'patientunitstayid': lst_ids})\n",
    "    clm_name = \"{}_{}_{}to{}_u{}\".format(vital_name, agg_total, lower_offset, upper_offset, timeunit)\n",
    "    df_pat_final = df_pat.merge(df_grouped_hours, on=\"patientunitstayid\", how=\"left\").rename(columns={vital_name: clm_name})\n",
    "\n",
    "    return df_pat_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0c0cce81-d5b2-4107-9e35-c4a142466fc0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fast_vitals_combined(df_periodic, df_aperiodic, lst_ids, vital_name, realistic_bounds, offset, agg_timeunit=\"median\",\n",
    "                         agg_total=\"median\", timeunit=60):\n",
    "    \"\"\"\n",
    "    Takes the both the vitalPeriodic and Aperiodic tables of eICU, target patientunitstayids as a list, offset bounds, and realistic bounds and a vitalname and\n",
    "    returns the aggregated and cleaned value for that offset timeframe. There are different options to choose from on how to aggregate that\n",
    "    value. Possible vitalnames: systolic, diastolic, mean_bp, pulsepressure\n",
    "\n",
    "    :param df_periodic: Dataframe - vitalPeriodic Dataframe of the eICU Database (abbreviated unless a lot of free RAM)\n",
    "\n",
    "    :param df_aperiodic: Dataframe - vitalAperiodic Dataframe (abbreviated unless a lot of free RAM)\n",
    "\n",
    "    :param lst_ids: List - list of patientunitstayids of the target population\n",
    "\n",
    "    :param vital_name: String, picklist - options \"systolic\", \"diastolic\", \"mean_bp\", \"pulsepressure\"\n",
    "\n",
    "    :param realistic_bounds: Tuple - realistic values of the vital in the form of (lower bound, upper bound) eg. (20, 250) for systolic\n",
    "\n",
    "    :param offset: Tuple - (lower time offest, time upper offset)\n",
    "\n",
    "    :param agg_timeunit: String, picklist, preset \"median\" - whether to use \"median\", \"max\" or \"min\" to aggregate the values per timeunit\n",
    "    (if the offset-duration is longer than the timeunit)\n",
    "\n",
    "    :param agg_total: String, picklist, preset \"median\" - whether to use \"median\", \"max\" or \"min\" to aggregate the values to the final value\n",
    "    \n",
    "    :param timeunit: Int, preset 60 - Number of minutes for the timeunit\n",
    "\n",
    "    :return: Dataframe \n",
    "    \"\"\"\n",
    "\n",
    "    # dictionary that sorts the vital_names to the respective names of the columns in the periodic and Aperiodic dfs\n",
    "    dict_vitalnames = {\n",
    "        \"systolic\": (\"systemicsystolic\", \"noninvasivesystolic\"),\n",
    "        \"diastolic\": (\"systemicdiastolic\", \"noninvasivediastolic\"),\n",
    "        \"mean_bp\": (\"systemicmean\", \"noninvasivemean\")\n",
    "    }\n",
    "\n",
    "    # reducing the general dfs to reduce the computational load\n",
    "    df_reduced_periodic = df_periodic[df_periodic[\"patientunitstayid\"].isin(lst_ids)].copy()\n",
    "    df_reduced_aperiodic = df_aperiodic[df_aperiodic[\"patientunitstayid\"].isin(lst_ids)].copy()\n",
    "\n",
    "    # open the tuples\n",
    "    lower_realistic_bound, upper_realistic_bound = realistic_bounds\n",
    "    lower_offset, upper_offset = offset\n",
    "\n",
    "    # next reduction, incorporating the big offset bounds and the realistic bounds into each dataframe and then adding both\n",
    "    # datafrems to have one united dataframes with all the vitals values\n",
    "    # calculate the pulsepressure if this is selected; via systolic BP - diastolic BP\n",
    "    if vital_name == \"pulsepressure\":\n",
    "        df_temp_initial_periodic = df_reduced_periodic.loc[\n",
    "            (df_reduced_periodic[\"systemicsystolic\"] >= 20) & (df_reduced_periodic[\"systemicsystolic\"] <= 300) &\n",
    "            (df_reduced_periodic[\"systemicdiastolic\"] >= 10) & (df_reduced_periodic[\"systemicdiastolic\"] <= 200) &\n",
    "            (df_reduced_periodic[\"observationoffset\"] >= lower_offset) & (\n",
    "                    df_reduced_periodic[\"observationoffset\"] <= upper_offset),\n",
    "            [\"patientunitstayid\", \"observationoffset\", \"systemicsystolic\", \"systemicdiastolic\"]].copy()\n",
    "\n",
    "        df_temp_periodic = (df_temp_initial_periodic.assign(\n",
    "            pulsepressure=df_temp_initial_periodic[\"systemicsystolic\"] - df_temp_initial_periodic[\"systemicdiastolic\"])\n",
    "                            .drop(columns=[\"systemicsystolic\", \"systemicdiastolic\"])\n",
    "                            .dropna()\n",
    "                            )\n",
    "\n",
    "        df_temp_initial_aperiodic = df_reduced_aperiodic.loc[\n",
    "            (df_reduced_aperiodic[\"noninvasivesystolic\"] >= 20) & (df_reduced_aperiodic[\"noninvasivesystolic\"] <= 300) &\n",
    "            (df_reduced_aperiodic[\"noninvasivediastolic\"] >= 10) & (df_reduced_aperiodic[\"noninvasivediastolic\"] <= 200) &\n",
    "            (df_reduced_aperiodic[\"observationoffset\"] >= lower_offset) & (\n",
    "                    df_reduced_aperiodic[\"observationoffset\"] <= upper_offset),\n",
    "            [\"patientunitstayid\", \"observationoffset\", \"noninvasivesystolic\", \"noninvasivediastolic\"]].copy()\n",
    "\n",
    "        df_temp_aperiodic = (df_temp_initial_aperiodic.assign(\n",
    "            pulsepressure=df_temp_initial_aperiodic[\"noninvasivesystolic\"] - df_temp_initial_aperiodic[\"noninvasivediastolic\"])\n",
    "                             .drop(columns=[\"noninvasivesystolic\", \"noninvasivediastolic\"])\n",
    "                             .dropna()\n",
    "                             )\n",
    "        \n",
    "    # path for systolic, diastolic and mean_bp\n",
    "    else:\n",
    "        key_periodic, key_aperiodic = dict_vitalnames[vital_name]\n",
    "        df_temp_periodic = df_reduced_periodic.loc[\n",
    "            (df_reduced_periodic[key_periodic] >= lower_realistic_bound) & (df_reduced_periodic[key_periodic] <= upper_realistic_bound) &\n",
    "            (df_reduced_periodic[\"observationoffset\"] >= lower_offset) & (df_reduced_periodic[\"observationoffset\"] <= upper_offset),\n",
    "            [\"patientunitstayid\", \"observationoffset\", key_periodic]].copy().dropna().rename(columns={key_periodic: vital_name})\n",
    "        df_temp_aperiodic = df_reduced_aperiodic.loc[\n",
    "            (df_reduced_aperiodic[key_aperiodic] >= lower_realistic_bound) & (\n",
    "                        df_reduced_aperiodic[key_aperiodic] <= upper_realistic_bound) &\n",
    "            (df_reduced_aperiodic[\"observationoffset\"] >= lower_offset) & (df_reduced_aperiodic[\"observationoffset\"] <= upper_offset),\n",
    "            [\"patientunitstayid\", \"observationoffset\", key_aperiodic]].copy().dropna().rename(columns={key_aperiodic: vital_name})\n",
    "\n",
    "    df_temp_whole = pd.concat([df_temp_periodic, df_temp_aperiodic])\n",
    "\n",
    "    # create bins for the timeunit in the given offset interval and then cut the column to these bins\n",
    "    lst_bins = [i for i in range(lower_offset, upper_offset + 1, timeunit) if i <= upper_offset]\n",
    "    \n",
    "    if (upper_offset - lower_offset) % timeunit != 0:\n",
    "        lst_bins.append(upper_offset)\n",
    "\n",
    "    df_temp_whole.observationoffset = pd.cut(df_temp_whole.observationoffset, bins=lst_bins, right=True, include_lowest=True)\n",
    "\n",
    "    # group first by hour (cleaning the data of outliers) and then over the total offset span\n",
    "    df_grouped_all = (df_temp_whole\n",
    "                      .groupby([\"patientunitstayid\", \"observationoffset\"])\n",
    "                      .agg(lambda x: groupby_vitals_per_hour(x, agg_timeunit=agg_timeunit))\n",
    "                      .reset_index()\n",
    "                      .drop(columns=[\"observationoffset\"])\n",
    "                      .dropna()\n",
    "                      .groupby([\"patientunitstayid\"])\n",
    "                      .agg(lambda x: groupby_vitals_total(x, agg_total=agg_total))\n",
    "                      .reset_index()\n",
    "                      )\n",
    "\n",
    "    # make a dataframe with a single column containing the ids and then merge the results to that\n",
    "    df_pat = pd.DataFrame({'patientunitstayid': lst_ids})\n",
    "    clm_name = \"{}_{}_{}to{}_u{}\".format(vital_name, agg_total, lower_offset, upper_offset, timeunit)\n",
    "    df_pat_final = df_pat.merge(df_grouped_all, on=\"patientunitstayid\", how=\"left\").rename(columns={vital_name: clm_name})\n",
    "\n",
    "    return df_pat_final\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "67028640-2a2e-4afc-88da-2bc789e7258f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_time_to_death_from_unit_admit(x):\n",
    "    # if the patient did not die, return NaN\n",
    "    if x.hospitaldischargestatus == \"Alive\":\n",
    "        return np.nan\n",
    "    \n",
    "    # if the patient died in the ICU then the time on ICU is the time-to-death\n",
    "    if x.unitdischargestatus == \"Expired\":\n",
    "        return x.actualiculos\n",
    "    \n",
    "    # if the patient died in the hospital calculate the time to death by subtracting the time to ICU admission\n",
    "    if x.hospitaldischargestatus == \"Expired\":\n",
    "        time_to_death = x.unabridgedhosplos - (x.hospitaladmitoffset/(24*60))\n",
    "        return time_to_death\n",
    "    \n",
    "    else:\n",
    "        return np.nan\n",
    "    \n",
    "\n",
    "def time_to_death_from_unit_admission(df_pat, df_apache_res, lst_ids):\n",
    "    \"\"\"\n",
    "    Compute the time to death from ICU-admission for a cohort of interest. Will return np.nan if the patient did not die and \n",
    "    for irregularities.\n",
    "    \n",
    "    :param df_pat: Dataframe - patient dataframe of the eICU or abbreviated\n",
    "    \n",
    "    :param df_apache_res: Dataframe - apachePatientResult dataframe of the eICU or abbreviated\n",
    "    \n",
    "    :param lst_ids: List - List of patientunitstayids\n",
    "    \n",
    "    return: Dataframe with 2 columns (patientunitstayids and time_to_death_unitadmit)\n",
    "    \"\"\"\n",
    "    \n",
    "    # reducing the general dfs to reduce the computational load\n",
    "    df_pat_red = df_pat.loc[df_pat.patientunitstayid.isin(lst_ids), \n",
    "                           [\"patientunitstayid\", \"hospitaldischargestatus\", \"unitdischargestatus\", \"hospitaladmitoffset\"]].copy()\n",
    "    df_apache_res_red = df_apache_res.loc[df_apache_res.patientunitstayid.isin(lst_ids),\n",
    "                                         [\"patientunitstayid\", 'actualiculos', 'unabridgedhosplos']].copy()\n",
    "    \n",
    "    # merging both to have all these columns ready for the apply method\n",
    "    df_combined = pd.merge(left=df_pat_red, right=df_apache_res_red, how=\"left\", on=\"patientunitstayid\")\n",
    "    df_combined = df_combined.drop_duplicates()\n",
    "    \n",
    "    # calculate the time-to-death in a row-wise approach\n",
    "    df_combined[\"time_to_death_unitadmit\"] = df_combined.apply(lambda x: apply_time_to_death_from_unit_admit(x), axis=1)\n",
    "    \n",
    "    df_final = df_combined[[\"patientunitstayid\", \"time_to_death_unitadmit\"]].copy()\n",
    "    \n",
    "    return df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0fabd46e-05dd-434b-a22f-bcd1df3c525a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def map_vitals_from_two_sources(x, df_ref_data, clm_aps, clm_own, threshold, aps_midpoint, side):\n",
    "    \"\"\"\n",
    "    Decide whether vitals are above or below a certain threshold based on both the APS extreme vitals and under certain conditions based on my own calculations:\n",
    "    The APS vitals are extremes from a certain midpoint. However, this goes both way. E.g. heartrate is measured as an extreme from the midpoint 75 in the APS.\n",
    "    This means that theoretically a recorded APS heartrate of 38 does not exlcude that this patient had a heartrate of 111 at some point as 38 is more extreme.\n",
    "    Therefore, in case \n",
    "\n",
    "    :param x: x - lambda x parameter\n",
    "    :param df_ref_data: Dataframe\n",
    "    :param clm_aps: String - column name of the aps vitals\n",
    "    :param clm_own: String - column name of my vitals\n",
    "    :param threshold: Int/Float - threshold, is NOT included (is used with > / < and NOT >= / <=! )\n",
    "    :param aps_midpoint: Int/Float - midpoint value the aps is based on\n",
    "    :param side: String, picklist - \"below\" or \"above\"\n",
    "    :return: value for mapping\n",
    "    \"\"\"\n",
    "    \n",
    "    # calculating the counterthreshold \n",
    "    if side == \"below\":\n",
    "        if threshold > aps_midpoint:\n",
    "            counterthresh = aps_midpoint + (threshold - aps_midpoint)\n",
    "        else:\n",
    "            counterthresh = aps_midpoint + (aps_midpoint - threshold)\n",
    "    if side == \"above\":\n",
    "        if threshold < aps_midpoint:\n",
    "            counterthresh = aps_midpoint - (aps_midpoint - threshold)\n",
    "        else:\n",
    "            counterthresh = aps_midpoint - (threshold - aps_midpoint) \n",
    "    \n",
    "    # values for 1 patient as this function is applied row-wise with 1 row representing 1 patient\n",
    "    value_aps = df_ref_data.loc[x][clm_aps]\n",
    "    value_own = df_ref_data.loc[x][clm_own]\n",
    "    \n",
    "    # if there is no data in both calculations return NaN\n",
    "    if np.isnan(value_aps) and np.isnan(value_own):\n",
    "        return np.nan\n",
    "    \n",
    "    # if there is no APS data (but my own data), use only my calculations\n",
    "    if np.isnan(value_aps):\n",
    "        # if we are looking for vitals above a certain threshold\n",
    "        if side == \"above\":\n",
    "            if value_own > threshold:\n",
    "                return 1    \n",
    "        # if we are looking for vitals below a certain threshold\n",
    "        if side == \"below\":\n",
    "            if value_own < threshold:\n",
    "                return 1\n",
    "        # if the vitals is not above/below a certain threshold\n",
    "        else:\n",
    "            return 0\n",
    "        \n",
    "    # if there is no own data (but APS data), use only the APS data\n",
    "    if np.isnan(value_own):\n",
    "        # if we are looking for vitals above a certain threshold\n",
    "        if side == \"above\":\n",
    "            if value_aps > threshold:\n",
    "                return 1  \n",
    "        # if we are looking for vitals below a certain threshold\n",
    "        if side == \"below\":\n",
    "            if value_aps < threshold:\n",
    "                return 1 \n",
    "        # if the vitals is not above/below a certain threshold\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "    # if there is data in both the APS column and my calculcations, use first the APS data and only\n",
    "    # under certain circumstances (see docstring) my own calculations instead\n",
    "    if side == \"above\":\n",
    "        if value_aps > threshold:\n",
    "            return 1\n",
    "        if value_aps < counterthresh:\n",
    "            if value_own > threshold:\n",
    "                return 1\n",
    "        else:\n",
    "            return 0\n",
    "        \n",
    "    if side == \"below\":\n",
    "        if value_aps < threshold:\n",
    "            return 1\n",
    "        if value_aps > counterthresh:\n",
    "            if value_own < threshold:\n",
    "                return 1\n",
    "        else:\n",
    "            return 0\n",
    "    else:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9400d6a7-4e42-4f0d-887b-f7966c90f8b0",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Demographic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f070dc09-dc5e-49c1-907f-90cd7efef01c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_pat = pd.read_csv(\"PE_data/patient_PE.csv\", low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "24b6abf8-448e-4137-9c28-41fcea5b720b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_patinfo_PE = get_basic_patient_info(df_pat, lst_pat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5e06e70a-ed8f-47f9-8988-0129d539d2e2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Process the result (aggregate the ethnicity column as in, only keep the top 2 ethnicities as distinct categories; int-binarize the death columns)\n",
    "df_patinfo_PE.loc[~(df_patinfo_PE.ethnicity.isin(df_patinfo_PE.ethnicity.value_counts().index[:2].to_list())), \"ethnicity\"] = \"Other/Unknown\"\n",
    "df_patinfo_PE.ethnicity = df_patinfo_PE.ethnicity.fillna(\"Other/Unknown\")\n",
    "df_patinfo_PE.hospitaldischargestatus = df_patinfo_PE.hospitaldischargestatus.map({\"Expired\": 1, \"Alive\": 0})\n",
    "df_patinfo_PE.unitdischargestatus = df_patinfo_PE.unitdischargestatus.map({\"Expired\": 1, \"Alive\": 0})\n",
    "\n",
    "# the demographic PESI components\n",
    "df_patinfo_PE[\"PESI_age\"] = df_patinfo_PE[\"age\"]\n",
    "df_patinfo_PE[\"PESI_gender\"] = df_patinfo_PE[\"gender\"].map({\"Male\": 1, \"Female\":0})\n",
    "\n",
    "# sPESI age component (> 80 years old)\n",
    "df_patinfo_PE[\"sPESI_age\"] = df_patinfo_PE[\"PESI_age\"].map(lambda x: 1 if x > 80 else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ac42a5-6053-4e21-bff9-f8adc853c93d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Comorbidities "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fe88f28c-c5f2-4345-a64e-9d2f8e2c12d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_pmh = pd.read_csv(\"PE_data/pastHistory_PE.csv\", low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "372596cb-e025-4928-ad11-8dfa0a21a3af",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 64/64 [00:03<00:00, 19.64it/s]\n"
     ]
    }
   ],
   "source": [
    "df_pmhinfo = get_pastHistory(df_pmh, lst_pat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "096e4c73-b687-4eb0-94fd-2caf977ca2b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Merge the dataframe with the Comorbidities to the dataframe with the demographic data\n",
    "df_pe = pd.merge(\n",
    "    left=df_patinfo_PE,\n",
    "    right=df_pmhinfo,\n",
    "    how=\"left\",\n",
    "    on=\"patientunitstayid\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d90d3593-db2d-4f10-8cd8-4b061fe00939",
   "metadata": {
    "tags": []
   },
   "source": [
    "## APACHE IVa, APS and associated variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "04286513-14ab-40a0-bc27-7efd218d81cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_apsVar = pd.read_csv(\"PE_data/apacheApsVar_PE.csv\", low_memory=False)\n",
    "df_predVar = pd.read_csv(\"PE_data/apachePredVar_PE.csv\", low_memory=False)\n",
    "df_apacheresult = pd.read_csv(\"PE_data/apachePatientResult_PE.csv\", low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2e19afc7-d4bb-45fe-ad1a-565addeb6a37",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_apsvarinfo = get_and_initial_clean_apacheApsVar(df_apsVar, lst_pat)\n",
    "df_predvarinfo = get_cleaned_apachePredVar_basics(df_predVar, lst_pat)\n",
    "df_apacheresult_info = get_cleaned_apachePatientResult_basics(df_apacheresult, lst_pat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c18d22e8-0597-431c-9b80-b2039b7a1362",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Merge the results dataframes to the growing final dataframe\n",
    "df_pe = df_pe.merge(\n",
    "    right=df_apsvarinfo,\n",
    "    how=\"left\",\n",
    "    on=\"patientunitstayid\"\n",
    ")\n",
    "\n",
    "df_pe = df_pe.merge(\n",
    "    right=df_predvarinfo,\n",
    "    how=\"left\",\n",
    "    on=\"patientunitstayid\"\n",
    ")\n",
    "\n",
    "df_pe = df_pe.merge(\n",
    "    right=df_apacheresult_info,\n",
    "    how=\"left\",\n",
    "    on=\"patientunitstayid\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9636ca75-27a9-4add-b850-31e702e6159a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### the PESI pmh components:\n",
    "# chronic pulmonary disease: if the patient has COPD or asthma or restrictive lung disease or uses home-O2 or is s/p LuTx\n",
    "df_pe[\"PESI_pulm\"] = 0\n",
    "df_pe.loc[(df_pe['pmh_COPD'] != 0) | (df_pe['pmh_asthma'] != 0) | (df_pe['pmh_home_o2'] != 0) |\n",
    "          (df_pe['pmh_restrictive_lung_disease'] != 0) | (df_pe['pmh_s_p_lungTx'] != 0), [\"PESI_pulm\"]] = 1\n",
    "df_pe.loc[(df_pe['pmh_COPD'].isna()) & (df_pe['pmh_asthma'].isna()) & (df_pe['pmh_home_o2'].isna()) &\n",
    "          (df_pe['pmh_restrictive_lung_disease'].isna()) & (df_pe['pmh_s_p_lungTx'].isna()), [\"PESI_pulm\"]] = np.nan\n",
    "\n",
    "# heart failure\n",
    "df_pe[\"PESI_hf\"] = df_pe.pmh_CHF.map(lambda x: 1 if x != 0 else 0)\n",
    "\n",
    "# cancer: if the patient has any type of cancer or has received cancer therapy in the past\n",
    "df_pe[\"PESI_cancer\"] = 0\n",
    "df_pe[\"PESI_cancer\"] = df_pe.apply(lambda x: 1 if (x.pmh_cancer_therapy != 0 or \n",
    "                                                   x.pred_metastaticcancer > 0 or \n",
    "                                                   x.pmh_cancer != 0 or\n",
    "                                                   x.pred_lymphoma > 0 or \n",
    "                                                   x.pred_leukemia > 0) else 0, axis=1)\n",
    "\n",
    "# cancer for the sPESI\n",
    "df_pe[\"sPESI_cancer\"] = df_pe[\"PESI_cancer\"]\n",
    "\n",
    "df_pe.loc[(df_pe[\"pmh_cancer_therapy\"].isna()) &\n",
    "          (df_pe[\"pmh_cancer\"].isna()) &\n",
    "          (df_pe[\"pred_lymphoma\"].isna()) &\n",
    "          (df_pe[\"pred_metastaticcancer\"].isna()) &\n",
    "          (df_pe[\"pred_leukemia\"].isna()), [\"PESI_cancer\"]] = np.nan\n",
    "\n",
    "# chronic cardiopulmonary disease: if the patient had either chronic pulmonary disease or a range of cardiac PMH\n",
    "df_pe[\"sPESI_cardiopulm\"] = df_pe.apply(lambda x: 1 if (x.PESI_pulm > 0 or \n",
    "                                                        x.PESI_hf > 0 or \n",
    "                                                        x.pmh_MI != 0 or\n",
    "                                                        x.pmh_pacemaker != 0 or \n",
    "                                                        x.pmh_AICD != 0 or\n",
    "                                                        x.pred_midur > 0 or\n",
    "                                                        x.pmh_CA_bypass != 0) else 0, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0cad266-f674-4cb8-bb56-7bee473e4374",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Infusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "21d925d0-1805-4e98-828b-c300faa94cf7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_infusions = pd.read_csv(\"PE_data/infusionDrug_PE.csv\", low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fa3f219a-2cb9-44d2-bce4-3cf9bd82a61c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_inf_results = get_infusion_drugs(df_infusion=df_infusions, \n",
    "                                    lst_ids=lst_pat, \n",
    "                                    timeframe=(0, 1440))\n",
    "df_inf_results = df_inf_results.rename(columns={\"infusion_vaso_ino\": \"ICU_sPESI_infusion_vaso_ino\"}).reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d32a6513-3c75-4c51-8d25-c356676e683b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patientunitstayid</th>\n",
       "      <th>ICU_sPESI_infusion_vaso_ino</th>\n",
       "      <th>infusion_thrombolytic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>253854</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>269141</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>460041</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>481155</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>497657</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1692</th>\n",
       "      <td>3351680</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1693</th>\n",
       "      <td>3351888</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1694</th>\n",
       "      <td>3352956</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1695</th>\n",
       "      <td>3353237</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1696</th>\n",
       "      <td>3353263</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1697 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      patientunitstayid  ICU_sPESI_infusion_vaso_ino  infusion_thrombolytic\n",
       "0                253854                            1                      0\n",
       "1                269141                            1                      0\n",
       "2                460041                            1                      0\n",
       "3                481155                            1                      0\n",
       "4                497657                            1                      0\n",
       "...                 ...                          ...                    ...\n",
       "1692            3351680                            0                      0\n",
       "1693            3351888                            0                      0\n",
       "1694            3352956                            0                      0\n",
       "1695            3353237                            0                      0\n",
       "1696            3353263                            0                      0\n",
       "\n",
       "[1697 rows x 3 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_inf_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ce253532-afe5-447b-82dc-ea4b66995716",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Merge the results dataframe to the growing final dataframe\n",
    "df_pe = df_pe.merge(\n",
    "    right=df_inf_results,\n",
    "    how=\"left\",\n",
    "    on=\"patientunitstayid\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec8ca7a-2ea8-49af-adea-eb19efcced86",
   "metadata": {},
   "source": [
    "## AMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "07cdc063-cef8-4428-af73-de03f12563c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# We defined AMS as a GCS verbal score < 5 (less than full score) using the APS (Acute Physiology Score) GCS verbal variable which contains the worst (lowest) score for the \n",
    "# first 24 hours after admission\n",
    "df_pe[\"PESI_ams\"] = df_pe.aps_verbal.map(lambda x: 1 if x < 5 else 0)\n",
    "df_pe[\"ICU_sPESI_ams\"] = df_pe.aps_verbal.map(lambda x: 1 if x < 5 else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2539aa7d-9adf-4d8f-b26a-152404283706",
   "metadata": {},
   "source": [
    "## Intubation / Ventilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3975acb5-56d3-41b0-8ead-22e11d4467c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Overall, we defined \"intubation\" as ever being intubated which corresponds to the APACHE variable oobintubday1\n",
    "df_pe[\"ICU_sPESI_intubation\"] = df_pe.pred_oobintubday1.map(lambda x: 1 if x == 1 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "04b8f423-a373-4a0c-983b-b017deffce7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# whether patients were ever ventilated on day (for a comparison)\n",
    "df_pe[\"ICU_sPESI_ventilation_comp\"] = df_pe.pred_oobventday1.map(lambda x: 1 if x == 1 else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a10726ad-7a77-493a-84eb-4c7f58df3b59",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Vitals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0e9ccf4b-c45a-474c-859a-02d58d856f54",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_periodic = pd.read_csv(\"PE_data/vitalPeriodic_PE.csv\", low_memory=False)\n",
    "df_a_periodic = pd.read_csv(\"PE_data/vitalAperiodic_PE.csv\", low_memory=False)\n",
    "df_nurseCharting = pd.read_csv(\"PE_data/nurseCharting_PE.csv\", low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2eed3db6-bded-4297-be9b-ac3a799ac58c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:33<00:00,  8.33s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:22<00:00,  7.38s/it]\n"
     ]
    }
   ],
   "source": [
    "### General (median) vitals\n",
    "# dictionaries of extreme vitals that were excluded as outliers\n",
    "dict_vitals = {\n",
    "    \"heartrate\": (20, 200),\n",
    "    \"temperature\": (32, 43),\n",
    "    \"respiration\": (3, 80),\n",
    "    \"sao2\": (50, 100),\n",
    "}\n",
    "\n",
    "dict_vitals_combined = {\n",
    "    \"systolic\": (20, 250),\n",
    "    \"diastolic\": (5, 180),\n",
    "    \"mean_bp\": (10, 200)\n",
    "}\n",
    "\n",
    "lst_clms_vitals_general = []\n",
    "\n",
    "# for the \"periodic\" vitals\n",
    "for key, values in tqdm(dict_vitals.items()):\n",
    "    \n",
    "    if key == \"temperature\":\n",
    "        df_temp = fast_vitals_periodic(df_periodic=df_periodic, \n",
    "                                       lst_ids=lst_pat, \n",
    "                                       vital_name=key, \n",
    "                                       realistic_bounds=values, \n",
    "                                       offset=(0, 1440),  \n",
    "                                       agg_total=\"median\", \n",
    "                                       timeunit=30, \n",
    "                                       temp_nurse_bool=True, \n",
    "                                       temp_nursechart=df_nurseCharting)\n",
    "            \n",
    "    else:\n",
    "        df_temp = fast_vitals_periodic(df_periodic=df_periodic, \n",
    "                                       lst_ids=lst_pat, \n",
    "                                       vital_name=key, \n",
    "                                       realistic_bounds=values, \n",
    "                                       offset=(0, 1440), \n",
    "                                       agg_total=\"median\",  \n",
    "                                       timeunit=30)\n",
    "\n",
    "    lst_clms_vitals_general.append(df_temp)\n",
    "\n",
    "# for the vitals (the blood pressures) that use both the periodic and aperiodic datafiles\n",
    "for key, values in tqdm(dict_vitals_combined.items()):\n",
    "\n",
    "    df_temp = fast_vitals_combined(df_periodic=df_periodic, \n",
    "                                   df_aperiodic=df_a_periodic,\n",
    "                                   lst_ids=lst_pat, \n",
    "                                   vital_name=key, \n",
    "                                   realistic_bounds=values, \n",
    "                                   offset=(0, 1440), \n",
    "                                   agg_total=\"median\", \n",
    "                                   timeunit=30)\n",
    "\n",
    "    lst_clms_vitals_general.append(df_temp)\n",
    "\n",
    "lst_clms_vitals_general_indexed = [df.set_index(\"patientunitstayid\") for df in lst_clms_vitals_general]\n",
    "df_final_vitals_general = pd.concat(lst_clms_vitals_general_indexed, axis=1)\n",
    "\n",
    "df_final_vitals_general = df_final_vitals_general.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fa8e7674-8f78-4024-b929-190fa5070cb7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Merge the results dataframe to the growing final dataframe\n",
    "df_pe = df_pe.merge(\n",
    "    right=df_final_vitals_general,\n",
    "    how=\"left\",\n",
    "    on=\"patientunitstayid\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d5cd0164-b67c-4a95-959f-24433085d025",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:33<00:00,  8.28s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:07<00:00,  7.43s/it]\n"
     ]
    }
   ],
   "source": [
    "### \"worst\" vitals for the score calculation\n",
    "# dictionaries of extreme vitals that were excluded as outliers\n",
    "dict_vitals = {\n",
    "    \"heartrate\": [(20, 200), \"max\"],\n",
    "    \"temperature\": [(32, 43), \"min\"],\n",
    "    \"respiration\": [(3, 80), \"max\"],\n",
    "    \"sao2\": [(50, 100), \"min\"]\n",
    "}\n",
    "\n",
    "dict_vitals_combined = {\n",
    "    \"systolic\": [(20, 250), \"min\"]\n",
    "}\n",
    "\n",
    "lst_clms_pesi_vitals = []\n",
    "\n",
    "# for the \"periodic\" vitals\n",
    "for key, values in tqdm(dict_vitals.items()):\n",
    "    realistic = values[0]\n",
    "    direction = values[1]\n",
    "    \n",
    "    clm_name = \"pesi_{}_own\".format(key)\n",
    "    internal_clm_name = \"{}_{}_0to1440_u30\".format(key, direction)\n",
    "    \n",
    "    if key == \"temperature\":\n",
    "        df_temp = fast_vitals_periodic(df_periodic=df_periodic, \n",
    "                                       lst_ids=lst_pat, \n",
    "                                       vital_name=key, \n",
    "                                       realistic_bounds=realistic, \n",
    "                                       offset=(0, 1440), \n",
    "                                       agg_total=direction, \n",
    "                                       timeunit=30, \n",
    "                                       temp_nurse_bool=True, \n",
    "                                       temp_nursechart=df_nurseCharting)\n",
    "            \n",
    "    else:\n",
    "        df_temp = fast_vitals_periodic(df_periodic=df_periodic, \n",
    "                                       lst_ids=lst_pat, \n",
    "                                       vital_name=key, \n",
    "                                       realistic_bounds=realistic, \n",
    "                                       offset=(0, 1440), \n",
    "                                       agg_total=direction, \n",
    "                                       timeunit=30)\n",
    "\n",
    "    df_clm = df_temp.rename(columns={internal_clm_name: clm_name})\n",
    "    lst_clms_pesi_vitals.append(df_clm)\n",
    "\n",
    "# for vital \"systolic\" that uses both the periodic and aperiodic datafiles\n",
    "for key, values in tqdm(dict_vitals_combined.items()):\n",
    "    realistic = values[0]\n",
    "    direction = values[1]\n",
    "\n",
    "    clm_name = \"pesi_{}_own\".format(key)\n",
    "    internal_clm_name = \"{}_{}_0to1440_u30\".format(key, direction)\n",
    "\n",
    "    df_temp = fast_vitals_combined(df_periodic=df_periodic, \n",
    "                                   df_aperiodic=df_a_periodic,\n",
    "                                   lst_ids=lst_pat, \n",
    "                                   vital_name=key, \n",
    "                                   realistic_bounds=realistic, \n",
    "                                   offset=(0, 1440), \n",
    "                                   agg_total=direction, \n",
    "                                   timeunit=30)\n",
    "\n",
    "    df_clm = df_temp.rename(columns={internal_clm_name: clm_name})\n",
    "    lst_clms_pesi_vitals.append(df_clm)\n",
    "\n",
    "lst_clms_pesi_vitals_indexed = [df.set_index(\"patientunitstayid\") for df in lst_clms_pesi_vitals]\n",
    "df_final_vitals_pesi = pd.concat(lst_clms_pesi_vitals_indexed, axis=1)\n",
    "\n",
    "df_final_vitals_pesi = df_final_vitals_pesi.reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "beeba5c3-1372-425a-a7e9-01ecb0b1b59f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Merge the results dataframe to the growing final dataframe\n",
    "df_pe = df_pe.merge(\n",
    "    right=df_final_vitals_pesi,\n",
    "    how=\"left\",\n",
    "    on=\"patientunitstayid\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b6b6537e-0bb9-4dea-b494-d324cb772fac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# creating a reference dataframe\n",
    "df_pe_ref = df_pe.copy().set_index(\"patientunitstayid\")\n",
    "\n",
    "# Heartrate component (heartrate >= 110/min), the APS midpoint is at 75\n",
    "df_pe[\"PESI_pulse\"] = df_pe[\"patientunitstayid\"].map(\n",
    "    lambda x: map_vitals_from_two_sources(x, df_pe_ref, \"aps_heartrate\", \"pesi_heartrate_own\", 109, 75, \"above\"))\n",
    "\n",
    "# Systolic BP component (systolic BP < 100 mmHg): Only from our own calculations as this is not included in the APS\n",
    "df_pe[\"PESI_systolic\"] = df_pe.pesi_systolic_own.map(lambda x: 1 if x < 100 else 0)\n",
    "\n",
    "# Temperature component (Temp < 36°C), the APS midpoint is 36\n",
    "df_pe[\"PESI_temp\"] = df_pe[\"patientunitstayid\"].map(\n",
    "    lambda x: map_vitals_from_two_sources(x, df_pe_ref, \"aps_temperature\", \"pesi_temperature_own\", 36, 38, \"below\"))\n",
    "\n",
    "# Respiratory rate component (RR >= 30/min), the APS midpoint is 19 \n",
    "df_pe[\"PESI_resp\"] = df_pe[\"patientunitstayid\"].map(\n",
    "    lambda x: map_vitals_from_two_sources(x, df_pe_ref, \"aps_respiratoryrate\", \"pesi_respiration_own\", 29, 19, \"above\"))\n",
    "\n",
    "# SpO2 component (SpO2 < 90%): Only from our own calculations as this is not included in the APS\n",
    "df_pe[\"PESI_o2\"] = df_pe.pesi_sao2_own.map(lambda x: 1 if x < 90 else 0)\n",
    "\n",
    "# setting any missing values in the vitals to 0, in line with the derivation/validation study of the PESI (Aujesky et al. (2005)) \n",
    "df_pe.PESI_pulse = df_pe.PESI_pulse.fillna(value=0)\n",
    "df_pe.PESI_systolic = df_pe.PESI_systolic.fillna(value=0)\n",
    "df_pe.PESI_temp = df_pe.PESI_temp.fillna(value=0)\n",
    "df_pe.PESI_resp = df_pe.PESI_resp.fillna(value=0)\n",
    "df_pe.PESI_o2 = df_pe.PESI_o2.fillna(value=0)\n",
    "\n",
    "# for the sPESI\n",
    "df_pe[\"sPESI_systolic\"] = df_pe[\"PESI_systolic\"]\n",
    "df_pe[\"sPESI_pulse\"] = df_pe[\"PESI_pulse\"]\n",
    "df_pe[\"sPESI_o2\"] = df_pe[\"PESI_o2\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3538e8ce-9134-4f4b-9e58-083bc3c54927",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Data for the sensitivity analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e814ca64-8474-4f01-950e-683bce310c2d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_physical = pd.read_csv(\"PE_data/physicalExam_PE.csv\", low_memory=False)\n",
    "df_nurse_chart = pd.read_csv(\"PE_data/nurseCharting_PE.csv\", low_memory=False)\n",
    "df_resp_chart = pd.read_csv(\"PE_data/respiratoryCharting_PE.csv\", low_memory=False)\n",
    "df_resp_care = pd.read_csv(\"PE_data/respiratoryCare_PE.csv\", low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "78bd2305-d33b-46fa-84e4-a0cb0320b48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# time intervals for the sensitivity analysis\n",
    "lst_time_intervals_h_from_admission = [2, 3, 6, 12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3507f56c-ce1c-4858-be24-4dfccb2a57a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use/need for vasopressor/inotrope infusion in the different time intervals\n",
    "lst_columns_infusion = []\n",
    "\n",
    "# use the function with relative start times for the shorter time-intervals \n",
    "for i in lst_time_intervals_h_from_admission:\n",
    "    minutes = i*60\n",
    "\n",
    "    df_temp = get_infusion_drugs_relative_interval_from_start(df_infusion=df_infusions, \n",
    "                                                              lst_ids=lst_pat, \n",
    "                                                              overall_timeframe=(0, 1440), \n",
    "                                                              time_interval=minutes)\n",
    "\n",
    "    \n",
    "    df_temp = df_temp.rename(columns={\"infusion_vaso_ino\": f\"infusion_vaso_ino_{i}h\"})\n",
    "    \n",
    "    lst_columns_infusion.append(df_temp[f\"infusion_vaso_ino_{i}h\"])\n",
    "\n",
    "df_inf_sens_analysis = (pd.concat(lst_columns_infusion, axis=1)).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ac0d2759-4054-446b-9b97-5c9bd6a9feb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the results dataframe to the growing final dataframe\n",
    "df_pe = df_pe.merge(\n",
    "    right=df_inf_sens_analysis,\n",
    "    how=\"left\",\n",
    "    on=\"patientunitstayid\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "65e92b99-ad0c-445a-966d-98db86868d24",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# AMS in the different time intervals (accessing the raw data on GCS values)\n",
    "lst_clms_ams = []\n",
    "\n",
    "# for the shorter time-intervals, extract this from boht the physicalExam and nurseCharting dataframes\n",
    "for i in lst_time_intervals_h_from_admission:\n",
    "    minutes = i*60\n",
    "    \n",
    "    df_temp = get_AMS_from_start_relative(df_physical=df_physical, \n",
    "                                          df_nurse_chart=df_nurse_chart, \n",
    "                                          lst_ids=lst_pat, \n",
    "                                          time_interval=minutes,\n",
    "                                          overall_offset=(0, 1440))\n",
    "    \n",
    "    df_temp = df_temp.set_index(\"patientunitstayid\")\n",
    "    df_temp = df_temp.rename(columns={f\"ams_first_{minutes}_min\": f\"ams_{i}h\"})\n",
    "\n",
    "    lst_clms_ams.append(df_temp[f\"ams_{i}h\"])\n",
    "\n",
    "df_ams_results = (pd.concat(lst_clms_ams, axis=1)).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "11891481-e590-46fc-a285-7f827989a90c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Merge the results dataframe to the growing final dataframe\n",
    "df_pe = df_pe.merge(\n",
    "    right=df_ams_results,\n",
    "    how=\"left\",\n",
    "    on=\"patientunitstayid\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "014de29e-d6ef-4c4d-bd81-94f742c0d748",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Intubation in the different time intervals. Unfortunately, aside from the variable oobintubday1, the raw data regarding intubation itself is very sparse.\n",
    "# Thus, we looked for patients that were mechanically ventilated during that time and were intubated in the larger timeframe (oobintubday1).\n",
    "df_intub_24h = df_pe[[\"ICU_sPESI_intubation\", \"patientunitstayid\"]].copy().set_index(\"patientunitstayid\") \n",
    "\n",
    "lst_clms_intub = []\n",
    "\n",
    "for i in lst_time_intervals_h_from_admission:\n",
    "    minutes = i*60\n",
    "    \n",
    "    df_temp = get_mechanically_ventilated_from_start_relative(df_resp_chart=df_resp_chart, \n",
    "                                                              df_resp_care=df_resp_care, \n",
    "                                                              df_physical=df_physical, \n",
    "                                                              df_nurse_chart=df_nurse_chart, \n",
    "                                                              lst_ids=lst_pat,\n",
    "                                                              time_interval=minutes, \n",
    "                                                              overall_offset=(0, 1440))\n",
    "    \n",
    "    df_temp = df_temp.set_index(\"patientunitstayid\")\n",
    "    df_intub_combined = pd.concat([df_intub_24h, df_temp], axis=1)\n",
    "    df_intub_combined[f\"intubation_{i}h\"] = df_intub_combined.apply(lambda x: 1 if (x.ICU_sPESI_intubation == 1 and x[f\"mech_vent_first_{minutes}_min\"] == 1) else 0, axis=1).astype(int)\n",
    "\n",
    "    lst_clms_intub.append(df_intub_combined[f\"intubation_{i}h\"])\n",
    "\n",
    "df_intub_results = (pd.concat(lst_clms_intub, axis=1)).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3f9b6d7b-30cd-4e39-a27c-0790525afd36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the results dataframe to the growing final dataframe\n",
    "df_pe = df_pe.merge(\n",
    "    right=df_intub_results,\n",
    "    how=\"left\",\n",
    "    on=\"patientunitstayid\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6682df41-5f64-408d-8243-0032d46eab5c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:03<00:00,  1.05it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  1.02it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:05<00:00,  1.31s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.27s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:09<00:00,  2.42s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.28s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:18<00:00,  4.60s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:04<00:00,  4.21s/it]\n"
     ]
    }
   ],
   "source": [
    "# Vitals in the different time intervals (accessing the raw data on GCS values)\n",
    "dict_vitals = {\n",
    "    \"heartrate\": [(20, 200), \"max\"],\n",
    "    \"temperature\": [(32, 43), \"min\"],\n",
    "    \"respiration\": [(3, 80), \"max\"],\n",
    "    \"sao2\": [(50, 100), \"min\"]\n",
    "}\n",
    "\n",
    "dict_vitals_combined = {\n",
    "    \"systolic\": [(20, 250), \"min\"]\n",
    "}\n",
    "\n",
    "lst_clms_vitals_timeframes = []\n",
    "\n",
    "for i in lst_time_intervals_h_from_admission:\n",
    "    minutes = i*60\n",
    "\n",
    "    lst_clms_pesi_vitals = []\n",
    "      \n",
    "    # for the \"periodic\" vitals\n",
    "    for key, values in tqdm(dict_vitals.items()):\n",
    "        realistic = values[0]\n",
    "        direction = values[1]\n",
    "\n",
    "        clm_name = \"PESI_{}_{}h\".format(key, i)\n",
    "        internal_clm_name = \"{}_{}_0to{}_u30\".format(key, direction, minutes)\n",
    "\n",
    "        if key == \"temperature\":\n",
    "            df_temp = fast_vitals_periodic(df_periodic=df_periodic, \n",
    "                                           lst_ids=lst_pat, \n",
    "                                           vital_name=key, \n",
    "                                           realistic_bounds=realistic, \n",
    "                                           offset=(0, minutes), \n",
    "                                           agg_total=direction, \n",
    "                                           timeunit=30, \n",
    "                                           temp_nurse_bool=True, \n",
    "                                           temp_nursechart=df_nurseCharting)\n",
    "\n",
    "        else:\n",
    "            df_temp = fast_vitals_periodic(df_periodic=df_periodic, \n",
    "                                           lst_ids=lst_pat, \n",
    "                                           vital_name=key, \n",
    "                                           realistic_bounds=realistic, \n",
    "                                           offset=(0, minutes), \n",
    "                                           agg_total=direction, \n",
    "                                           timeunit=30)\n",
    "\n",
    "        df_clm = df_temp.rename(columns={internal_clm_name: clm_name})\n",
    "        lst_clms_pesi_vitals.append(df_clm)\n",
    "\n",
    "    # for vital \"systolic\" that uses both the periodic and aperiodic datafiles\n",
    "    for key, values in tqdm(dict_vitals_combined.items()):\n",
    "        realistic = values[0]\n",
    "        direction = values[1]\n",
    "\n",
    "        clm_name = \"PESI_{}_{}h\".format(key, i)\n",
    "        internal_clm_name = \"{}_{}_0to{}_u30\".format(key, direction, minutes)\n",
    "\n",
    "        df_temp = fast_vitals_combined(df_periodic=df_periodic, \n",
    "                                       df_aperiodic=df_a_periodic,\n",
    "                                       lst_ids=lst_pat, \n",
    "                                       vital_name=key, \n",
    "                                       realistic_bounds=realistic, \n",
    "                                       offset=(0, minutes), \n",
    "                                       agg_total=direction, \n",
    "                                       timeunit=30)\n",
    "\n",
    "        df_clm = df_temp.rename(columns={internal_clm_name: clm_name})\n",
    "        lst_clms_pesi_vitals.append(df_clm)\n",
    "\n",
    "    lst_clms_pesi_vitals_indexed = [df.set_index(\"patientunitstayid\") for df in lst_clms_pesi_vitals]\n",
    "    df_final_vitals_pesi = pd.concat(lst_clms_pesi_vitals_indexed, axis=1)\n",
    "    \n",
    "    df_final_vitals_pesi[\"PESI_systolic_{}h\".format(i)] =  df_final_vitals_pesi[\"PESI_systolic_{}h\".format(i)].map(lambda x: 1 if x<100 else 0)\n",
    "    df_final_vitals_pesi[\"PESI_heartrate_{}h\".format(i)] =  df_final_vitals_pesi[\"PESI_heartrate_{}h\".format(i)].map(lambda x: 1 if x>=110 else 0)\n",
    "    df_final_vitals_pesi[\"PESI_temperature_{}h\".format(i)] =  df_final_vitals_pesi[\"PESI_temperature_{}h\".format(i)].map(lambda x: 1 if x<36 else 0)\n",
    "    df_final_vitals_pesi[\"PESI_respiration_{}h\".format(i)] =  df_final_vitals_pesi[\"PESI_respiration_{}h\".format(i)].map(lambda x: 1 if x>=30 else 0)\n",
    "    df_final_vitals_pesi[\"PESI_sao2_{}h\".format(i)] =  df_final_vitals_pesi[\"PESI_sao2_{}h\".format(i)].map(lambda x: 1 if x<90 else 0)\n",
    "\n",
    "    lst_clms_vitals_timeframes.append(df_final_vitals_pesi)\n",
    "    \n",
    "    \n",
    "df_vitals_timeframes_results = (pd.concat(lst_clms_vitals_timeframes, axis=1)).reset_index().fillna(value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f548abe1-f075-43d1-aff4-add0a985f42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the results dataframe to the growing final dataframe\n",
    "df_pe = df_pe.merge(\n",
    "    right=df_vitals_timeframes_results,\n",
    "    how=\"left\",\n",
    "    on=\"patientunitstayid\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51f5fe26-cb4d-44df-a58b-7c39b97e16af",
   "metadata": {},
   "source": [
    "## Time-to-death"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "daab74fc-cbee-4028-a795-aa6358d83b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ttd_pe = time_to_death_from_unit_admission(df_pat=df_pat, \n",
    "                                              df_apache_res=df_apacheresult, \n",
    "                                              lst_ids=lst_pat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e044cf01-6e39-4453-b4b9-b086939f317c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pe = df_pe.merge(\n",
    "    right=df_ttd_pe,\n",
    "    how=\"left\",\n",
    "    on=\"patientunitstayid\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8137886b-766b-4e78-a851-bffbada030e6",
   "metadata": {
    "tags": []
   },
   "source": [
    "# PESI score calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f9348307-8f8e-4c2d-816f-5e319ae281f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## PESI score and PESI classes\n",
    "# calculate the PESI score\n",
    "df_pe[\"PESI_score\"] = df_pe.apply(lambda row: row[\"age\"] + row[\"PESI_gender\"]*10 +\n",
    "                                              row[\"PESI_cancer\"]*30 + row[\"PESI_hf\"]*10 +\n",
    "                                              row[\"PESI_pulm\"]*10 + row[\"PESI_pulse\"]*20 +\n",
    "                                              row[\"PESI_systolic\"]*30 + row[\"PESI_resp\"]*20 +\n",
    "                                              row[\"PESI_temp\"]*20 + row[\"PESI_ams\"]*60 +\n",
    "                                              row[\"PESI_o2\"]*20, axis=1)\n",
    "\n",
    "# calculate the PESI classes\n",
    "df_pe[\"PESI_class\"] = np.nan\n",
    "df_pe.loc[df_pe.PESI_score > 125, [\"PESI_class\"]] = 5\n",
    "df_pe.loc[(df_pe.PESI_score >= 106) & (df_pe.PESI_score <= 125), [\"PESI_class\"]] = 4\n",
    "df_pe.loc[(df_pe.PESI_score >= 86) & (df_pe.PESI_score <= 105), [\"PESI_class\"]] = 3\n",
    "df_pe.loc[(df_pe.PESI_score >= 66) & (df_pe.PESI_score <= 85), [\"PESI_class\"]] = 2\n",
    "df_pe.loc[df_pe.PESI_score < 66, [\"PESI_class\"]] = 1\n",
    "\n",
    "# PESI scores of the different time-intervals\n",
    "for i in lst_time_intervals_h_from_admission:\n",
    "    df_pe[f\"PESI_score_{i}h\"] = df_pe.apply(lambda row: row[\"age\"] + row[\"PESI_gender\"]*10 +\n",
    "                                                  row[\"PESI_cancer\"]*30 + row[\"PESI_hf\"]*10 +\n",
    "                                                  row[\"PESI_pulm\"]*10 + row[f\"PESI_heartrate_{i}h\"]*20 +\n",
    "                                                  row[f\"PESI_systolic_{i}h\"]*30 + row[f\"PESI_respiration_{i}h\"]*20 +\n",
    "                                                  row[f\"PESI_temperature_{i}h\"]*20 + row[f\"ams_{i}h\"]*60 +\n",
    "                                                  row[f\"PESI_sao2_{i}h\"]*20, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b46070-a16b-47fe-b11d-3d72c53ca555",
   "metadata": {
    "tags": []
   },
   "source": [
    "# sPESI score calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c0427c7d-3398-46b3-892a-08a6407c6f82",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# calculcation of the sPESI score\n",
    "df_pe[\"sPESI_score\"] = df_pe[\"sPESI_age\"] + df_pe[\"sPESI_cancer\"] + df_pe[\"sPESI_cardiopulm\"] + \\\n",
    "                                df_pe[\"sPESI_pulse\"] + df_pe[\"sPESI_systolic\"] + df_pe[\"sPESI_o2\"]\n",
    "\n",
    "# sPESI scores of the different time-frames\n",
    "for i in lst_time_intervals_h_from_admission:\n",
    "    df_pe[f\"sPESI_score_{i}h\"] = df_pe[\"sPESI_age\"] + df_pe[\"sPESI_cancer\"] + df_pe[\"sPESI_cardiopulm\"] + \\\n",
    "                                df_pe[f\"PESI_heartrate_{i}h\"] + df_pe[f\"PESI_systolic_{i}h\"] + df_pe[f\"PESI_sao2_{i}h\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48370e0a-126b-4b11-8364-e068f1c28af0",
   "metadata": {},
   "source": [
    "# ICU-sPESI calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "10794c45-3a2c-4308-a240-f6e5e8bcb511",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# calculation of the ICU-sPESI score\n",
    "df_pe[\"ICU_sPESI_score\"] = df_pe[\"sPESI_score\"] + df_pe[f\"ICU_sPESI_ams\"] + df_pe[f\"ICU_sPESI_infusion_vaso_ino\"] + df_pe[\"ICU_sPESI_intubation\"]\n",
    "\n",
    "df_pe[\"ICU_sPESI_score_any_vent\"] = df_pe[\"sPESI_score\"] + df_pe[f\"ICU_sPESI_ams\"] + df_pe[f\"ICU_sPESI_infusion_vaso_ino\"] + df_pe[\"ICU_sPESI_ventilation_comp\"]\n",
    "\n",
    "# sPESI scores of the different time-frames\n",
    "for i in lst_time_intervals_h_from_admission:\n",
    "    df_pe[f\"ICU_sPESI_score_{i}h\"] = df_pe[f\"sPESI_score_{i}h\"] + df_pe[f\"ams_{i}h\"] + df_pe[f\"infusion_vaso_ino_{i}h\"] + df_pe[f\"intubation_{i}h\"] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b24a8fb-d6d6-4f2c-9189-443869834f7c",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Patient exclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2b0b081b-426d-44bb-8471-815975ef4943",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1697, 156)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pe.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edfb7e8e-e530-4872-912a-ab8f2c1bcd44",
   "metadata": {},
   "source": [
    "&rarr; 1697 patients total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a1a1510c-fabd-47f2-abe1-1c68bf7ae24b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# excluding patients with missing data in the APACHE-IV sore, regarding in-hospital mortality, gender and the GCS verbal component\n",
    "df_pe = df_pe.dropna(subset=[\"gender\", \"apachescore\", \"aps_verbal\", \"hospitaldischargestatus\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "00d50364-5066-4c88-97e0-6135ebd08700",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1427, 156)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pe.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84788daa-badd-401f-9a45-68c641ed453c",
   "metadata": {},
   "source": [
    "&rarr; 270 patients excluded due to missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "636a85bc-a956-4bbf-94b0-37995da4b3f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# excluding patients with an age < 18\n",
    "df_pe = df_pe[df_pe['age'] >= 18].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "9e8b65ca-c313-41d2-97f2-321201540573",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1424, 156)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pe.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74319715-1054-4e65-a185-ae1e3ffdd2d3",
   "metadata": {},
   "source": [
    "&rarr; 3 patients excluded due to age < 18 years old"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30a8ac24-be9d-4c80-ad8f-13edb40a1382",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Further data processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a3faa40-3993-47de-8a45-094ebfddb35e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1d20c38d-03ef-4117-87b5-96e260b38254",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_dict_for_categorical_with_0(df, column, printoption=False):\n",
    "    \"\"\"\n",
    "    Takes a column from a dataframe and forms a simple 1 to n categorical dictionary from the value counts.\n",
    "\n",
    "    :param df: Dataframe\n",
    "    :param column: String - column name\n",
    "    :param printoption: Boolean - whether to print the actual dictionary with value counts\n",
    "    :return: Dictionary\n",
    "    \"\"\"\n",
    "\n",
    "    df_val_counts = pd.DataFrame((df[column].value_counts())).reset_index()\n",
    "    df_val_counts.columns = ['unique_values', 'counts']\n",
    "    df_val_counts_2 = df_val_counts[df_val_counts.unique_values != 0].copy()\n",
    "    df_val_counts_2.index = np.arange(1, len(df_val_counts_2) + 1)\n",
    "\n",
    "    dict_to_cat = dict(zip(df_val_counts_2[\"unique_values\"], df_val_counts_2.index))\n",
    "    dict_to_cat[0] = 0\n",
    "\n",
    "    if printoption == True:\n",
    "        print(dict_to_cat)\n",
    "\n",
    "    return dict_to_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "990e4d52-f7ca-47af-8254-a06b6d2a2afa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def map_pmh_cancer(x):\n",
    "    \"\"\" mapping the raw cancer string data to cancer sites and then cancer groups \"\"\"\n",
    "    # if the patient does not have cancer\n",
    "    if x == 0:\n",
    "        return 0\n",
    "    \n",
    "    # extract the specific cancer site\n",
    "    if \"Cancer-Primary Site/\" in x:\n",
    "        lst_pmh_cancer = x.split(\"|\")\n",
    "        lst_site = [i for i in lst_pmh_cancer if \"Cancer-Primary Site/\" in i]\n",
    "\n",
    "        if len(lst_site) > 1:\n",
    "            cancer_site = \"multiple\"\n",
    "\n",
    "        else:\n",
    "            site_description = lst_site[0]\n",
    "            lst_final = site_description.split(\"/\")\n",
    "            cancer_site = lst_final[1]\n",
    "\n",
    "    else:\n",
    "        cancer_site = \"other\"\n",
    "    \n",
    "    # group the cancer based on cancer site\n",
    "    # the keys of the dictionary represent all unique values for this column for this cohort\n",
    "    dict_cancer_sites = {\n",
    "        0: \"No_cancer\",\n",
    "        'other': \"other\",\n",
    "        'breast': \"Breast\",\n",
    "        'lung': \"Respiratory\",\n",
    "        'colon': \"GI\",\n",
    "        'prostate': \"Genitourinary\",\n",
    "        'uterus': \"Genitourinary\",\n",
    "        'bladder': \"Genitourinary\",\n",
    "        'pancreas - adenocarcinoma': \"GI\",\n",
    "        'melanoma': \"other\",\n",
    "        'brain': \"other\",\n",
    "        'kidney': \"Genitourinary\",\n",
    "        'ovary': \"Genitourinary\",\n",
    "        'esophagus': \"GI\",\n",
    "        'bile duct': \"GI\",\n",
    "        'liver': \"GI\",\n",
    "        'multiple': \"other\",\n",
    "        'bone': \"other\",\n",
    "        'head and neck': \"other\",\n",
    "        'sarcoma': \"other\",\n",
    "        'unknown': \"other\",\n",
    "        'testes': \"Genitourinary\",\n",
    "        'stomach': \"GI\"\n",
    "    }\n",
    "    \n",
    "    cancer_group = dict_cancer_sites[cancer_site]\n",
    "\n",
    "    return cancer_group"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd051c7-e5b1-4f30-89b7-27401d4df42a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f507ad1c-bdca-499e-8306-c2adadd51a9e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_pe.gender = df_pe.gender.map({\"Female\":0, \"Male\":1})\n",
    "df_pe = df_pe.rename(columns={\"pmh_hemolytic _anemia\": \"pmh_hemolytic_anemia\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "baece002-aee4-4ab9-9e23-4c5230dd9ac3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Binarize certain PMH columns\n",
    "lst_clms_binary = [\"pmh_HT_with_treatment\", \"pmh_MI\", \"pmh_angina\", \"pmh_strokes\", \"pmh_periph_vasc_disease\", \"pmh_CA_bypass\",\n",
    "                  \"pmh_PCI\", \"pmh_pacemaker\", \"pmh_AICD\", \"pmh_venous_thrombosis\", \"pmh_asthma\", \"pmh_hemolytic_anemia\",\n",
    "                  \"pmh_aplastic_anemia\", \"pmh_clotting_disorder\", \"pmh_hypercoagulable_condition\", \"pmh_hypothyroidism\", \"pmh_hyperthyroidism\", \n",
    "                  \"pmh_CHF\", \"pmh_restrictive_lung_disease\", \"pmh_card_valvular\", 'pmh_home_o2', 'pmh_seizures', 'pmh_dementia', 'pmh_neuromusk_disease',\n",
    "                  'pmh_intracranial_mass', 'pmh_sickle_cells', 'pmh_liver_cirrhosis', 'pmh_ITP']\n",
    "\n",
    "for i in lst_clms_binary:\n",
    "    df_pe.loc[(df_pe[i] != 0) & (df_pe[i].notna()), i] = 1\n",
    "    \n",
    "    \n",
    "dict_clms_to_binary = {\n",
    "    \"pmh_cancer\": \"pmh_cancer_binary\",\n",
    "    \"pmh_insulin_dep_DM\" : \"pmh_diabetes_binary\",\n",
    "    \"pmh_COPD\": \"pmh_COPD_binary\",\n",
    "    \"pmh_arrhythmias\": \"pmh_arrhythmias_binary\",\n",
    "    \"pmh_renal_insuff\": \"pmh_renal_insuff_binary\",\n",
    "    \"pmh_renal_failure\": \"pmh_renal_failure_binary\"   \n",
    "}\n",
    "\n",
    "for orig_clm, new_clm in dict_clms_to_binary.items():\n",
    "    df_pe[new_clm] = df_pe[orig_clm].map(lambda x: 1 if (x!=0 and x!=np.nan) else 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "bda2ca8d-8159-4a0f-8036-80eb0c7ac513",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# group the cancer column depending on the site of the cancer (for details see function above)\n",
    "df_pe[\"pmh_cancer_grouped\"] = df_pe[\"pmh_cancer\"].map(lambda x: map_pmh_cancer(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a000a3e5-cb2f-42ba-b161-7ed38d9152bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# grouping the diabetes column depending on the type of diabetes (insulin dependent, only medication dependent and without any medication)\n",
    "def map_pmh_diabetes(x):\n",
    "    \"\"\" process the raw string data of the pmh_insulin_dep_DM column \"\"\"\n",
    "    if x == 0:\n",
    "        return 0\n",
    "\n",
    "    if \"non-medication\" in x:\n",
    "        return \"dm_without_treatment\"\n",
    "\n",
    "    if x == \"medication dependent\":\n",
    "        return \"medication_only\"\n",
    "\n",
    "    if \"insulin\" in x:\n",
    "        return \"including_Insulin\"\n",
    "\n",
    "df_pe[\"pmh_diabetes\"] = df_pe[\"pmh_insulin_dep_DM\"].map(lambda x: map_pmh_diabetes(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "358b57a9-8cc9-430c-afd4-8d7804140816",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# grouping the COPD column depending on the severity of the COPD\n",
    "# the keys of the dictionary represent all unique values for this column for this cohort\n",
    "dict_pmhCOPD = {\n",
    "    0: 0,\n",
    "    \"COPD  - moderate\": \"COPD_moderate\",\n",
    "    \"COPD  - no limitations\": \"COPD_mild\",\n",
    "    \"COPD  - severe\": \"COPD_severe\",\n",
    "    \"COPD  - moderate|COPD  - severe\": \"COPD_severe\"\n",
    "}\n",
    "\n",
    "df_pe[\"pmh_COPD\"] = df_pe[\"pmh_COPD\"].map(dict_pmhCOPD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b40b5a86-0d79-470a-9030-d059875df42e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# grouping the cardiac arrythmias column depending on whether the recorded arrythmias included atrial fibrillation or not\n",
    "def map_pmh_arrhythmias(x):\n",
    "    if x == 0:\n",
    "        return 0\n",
    "\n",
    "    if \"atrial fibrillation\" in x:\n",
    "        return \"Afib_orwith\"\n",
    "\n",
    "    else:\n",
    "        return \"other_arrhythmia\"\n",
    "\n",
    "\n",
    "df_pe[\"pmh_arrhythmias\"] = df_pe[\"pmh_arrhythmias\"].map(lambda x: map_pmh_arrhythmias(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "52bb9449-8cef-4f82-8e4f-d86a10fe63f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# grouping the COPD column depending on whether the patients were on dialysis or not\n",
    "# the keys of the dictionary represent all unique values for this column for this cohort\n",
    "dict_renal_failure = {\n",
    "    0: 0,\n",
    "    \"renal failure - hemodialysis\": \"renal_fail_w_dialysis\",\n",
    "    \"renal failure- not currently dialyzed\": \"renal_fail_no_dialysis\",\n",
    "    \"renal failure - peritoneal dialysis\": \"renal_fail_w_dialysis\"\n",
    "}\n",
    "\n",
    "df_pe[\"pmh_renal_failure\"] = df_pe[\"pmh_renal_failure\"].map(dict_renal_failure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "6087e833-fcb1-4d4a-a210-28144c7f38cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# grouping the previous PE column depending on whether it was a single or multiple previous PE\n",
    "def map_pmh_PE(x):\n",
    "    if x == 0:\n",
    "        return 0\n",
    "\n",
    "    if \"multiple\" in x:\n",
    "        return \"multiple_PE\"\n",
    "\n",
    "    else:\n",
    "        return \"single_PE\"\n",
    "\n",
    "df_pe[\"pmh_PE\"] = df_pe[\"pmh_PE\"].map(lambda x: map_pmh_PE(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "81def123-fb3e-417d-a994-789034c76df9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### grouping other comorbidities\n",
    "# Coronary artery disease and other large vessel disease: myocardial infarction, angina, strokes, peripheral vascular disease, \n",
    "# coronary artery bypass, percutaneous coronary intervention\n",
    "df_pe[\"pmh_CAD_and_other_large_vessel\"] = df_pe.apply(lambda x: 1 if x.pmh_MI == 1 or x.pmh_angina == 1 or x.pmh_strokes == 1 or x.pmh_periph_vasc_disease == 1 \n",
    "                                                      or x.pmh_CA_bypass == 1 or x.pmh_PCI == 1 else 0, axis=1)\n",
    "\n",
    "# pacemaker: either a normal pacemaker or an AICD\n",
    "df_pe[\"pmh_any_pacemaker\"] = df_pe.apply(lambda x: 1 if x.pmh_pacemaker == 1 or x.pmh_AICD == 1 else 0, axis=1)\n",
    "\n",
    "# Venous thomboses & PE\n",
    "df_pe[\"pmh_venous_thromb_and_PE\"] = df_pe.apply(lambda x: 1 if x.pmh_venous_thrombosis == 1 or (x.pmh_PE!=0 and x.pmh_PE!=np.nan) else 0, axis=1)\n",
    "\n",
    "# obstructive lung disease: COPD and asthma\n",
    "df_pe[\"pmh_obstructive_LD\"] = df_pe.apply(lambda x: 1 if (x.pmh_COPD!=0 and x.pmh_COPD!=np.nan) or x.pmh_asthma == 1 else 0, axis=1)\n",
    "\n",
    "# anemias\n",
    "df_pe[\"pmh_anemias\"] = df_pe.apply(lambda x: 1 if x.pmh_hemolytic_anemia == 1 or x.pmh_aplastic_anemia == 1 else 0, axis=1)\n",
    "\n",
    "# thyroid diseases (bother hyper- and hpoythyroidism)\n",
    "df_pe[\"pmh_thyroid_disease\"] = df_pe.apply(lambda x: 1 if x.pmh_hypothyroidism == 1 or x.pmh_hyperthyroidism == 1 else 0, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "5aaffeee-4e47-4248-b9ea-a0448112d444",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating age categories for a better overview over the distribution of that variable\n",
    "def get_age_cat_for_table(x):\n",
    "    if x>=81: return \">80\"\n",
    "    if x>=71: return \"71-80\"\n",
    "    if x>=61: return \"61-70\"\n",
    "    else: return \"<60\"\n",
    "\n",
    "df_pe[\"age_categories\"] = df_pe.age.map(lambda x: get_age_cat_for_table(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67276847-6d8d-438d-9d6b-2a6f7aeda5e5",
   "metadata": {},
   "source": [
    "# Export \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "7ab50430-8e37-4ff4-8668-fe8c669ecea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pe.to_excel(\"PE_data/PE_DATA_FINAL_review.xlsx\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
